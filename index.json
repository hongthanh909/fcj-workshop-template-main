[{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.01-workshop-overview/","title":"Workshop Overview","tags":[],"description":"","content":"EveryoneCook Architecture EveryoneCook is a modern social cooking platform built entirely on AWS serverless technologies. The architecture follows best practices for scalability, security, and cost optimization, with a focus on Vietnamese ingredient support and AI-powered recipe suggestions.\nKey Components Frontend: Next.js 15 application with Flowbite React components hosted on AWS Amplify Backend: Serverless API using API Gateway with API Router pattern and 6 Lambda modules Database: DynamoDB Single Table Design with username-based PK and 5 GSI indexes Storage: S3 buckets with Intelligent-Tiering and CloudFront CDN with OAC Authentication: Cognito User Pool with Lambda triggers for custom flows AI Integration: Amazon Bedrock (Claude 3 Haiku - anthropic.claude-3-haiku-20240307-v1:0) for ingredient translation, nutrition lookup, and recipe generation Security: WAF for API Gateway, Shield Standard for CloudFront, KMS encryption Monitoring: CloudWatch dashboards, alarms, and X-Ray distributed tracing Architecture Diagram Workshop Flow This workshop follows a practical application development workflow:\nSetup Environment - Install tools (Node.js, AWS CLI, CDK CLI) CDK Bootstrap - Prepare AWS account for CDK deployments Configure Stacks - Set up infrastructure configuration (DNS, Certificate, Core, Auth, Backend, Observability) Deploy Infrastructure - Deploy all CDK stacks to AWS Configure API \u0026amp; Lambda - Set up API Gateway routes and Lambda functions Deploy Backend - Deploy API and Lambda code Test Endpoints - Verify all endpoints work end-to-end Push to GitLab - Version control and CI/CD setup Deploy to Amplify - Deploy frontend to AWS Amplify Monitor \u0026amp; Maintain - Use CloudWatch and X-Ray for monitoring What You\u0026rsquo;ll Learn Infrastructure as Code with AWS CDK (TypeScript) Serverless architecture with API Router pattern DynamoDB Single Table Design with PROVISIONED billing mode CloudFront CDN with Origin Access Control (OAC) - PriceClass 200 Cognito authentication with Lambda triggers Lambda function modular organization (6 modules: API Router, Auth/User, Social, Recipe/AI, Admin, Upload) SQS-based async processing with 4 queues and workers Bedrock AI integration (Claude 3 Haiku) with dictionary-first caching strategy WAF security for API Gateway (REGIONAL scope) CloudWatch monitoring with structured logging (X-Ray disabled for cost optimization) Cost optimization strategies for low-traffic scenarios Realistic Cost Estimate (Low Traffic Scenarios) Scenario 1: 100-500 Active Users/Day (2 hours usage)\nMonthly Active Users: ~3,000-15,000 Daily Requests: ~5,000-25,000 API calls Estimated Monthly Cost: $12-18/month ($0.40-0.60/day) Scenario 2: 1,000 Active Users/Day (2 hours usage)\nMonthly Active Users: ~30,000 Daily Requests: ~50,000 API calls Estimated Monthly Cost: $25-35/month ($0.83-1.17/day) Key Cost Factors:\nDynamoDB: PROVISIONED mode (2 RCU/WCU) with auto-scaling → $1.25/month base + $0.50-3/month scaling Lambda: 6 functions (512MB-1GB memory) → $2-8/month (first 1M requests free) CloudFront: PriceClass 200 (Asia/US/Europe) → $1-5/month (first 1TB free, then $0.085/GB) API Gateway: Regional endpoint → $1-3/month (first 1M free, then $3.50/million) Cognito: Standard security (no Advanced Security Mode) → $0-1.50/month (first 50K MAU free) S3: Intelligent-Tiering → $0.50-2/month (first 50GB free) Bedrock AI: Claude 3 Haiku ($0.25/1M input tokens) → $2-8/month with 99% dictionary cache hit rate SQS: 4 queues (AI, Image, Analytics, Notification) → $0-0.40/month (first 1M requests free) CloudWatch Logs: 3-day retention → $0.50-2/month WAF: API Gateway only (no CloudFront WAF) → $5/month base + $0.60/million requests Cost Optimization Applied:\nX-Ray tracing disabled (saves $5-10/month) CloudFront WAF removed, using Shield Standard (saves $6/month) DynamoDB PROVISIONED mode with low baseline (2 RCU/WCU) instead of ON_DEMAND CloudWatch log retention reduced to 3 days for dev (saves $2-5/month) API Gateway caching disabled for dev (saves $14.60/month) Bedrock dictionary-first strategy (99% cache hit rate, reduces AI costs by 70%) Lambda Shared Dependencies Layer (reduces deployment size 90%, faster cold starts) Key Features Vietnamese Support: Vietnamese analyzer for ingredient search AI-Powered: Bedrock Claude 3 Haiku for recipe generation Dictionary-First Translation: 80% coverage target with intelligent caching Social Platform: Posts, comments, reactions, friends, notifications Field-Level Privacy: Granular control over profile visibility Content Moderation: Automated and manual moderation workflows Advanced Search: Full-text search with Vietnamese normalization Cost Optimized: Intelligent-Tiering, caching, and resource optimization "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.1-week1/","title":"Week 1 Worklog","tags":[],"description":"","content":" Week 1 Objectives: Set up AWS account with MFA, IAM users, and budget management. Understand AWS infrastructure (Regions, AZs, Edge Locations) and VPC fundamentals. Learn VPC security (Security Groups, NACLs, Flow Logs) and VPN/Direct Connect connectivity. Tasks for the Week Day Task Start Date Completion Date Reference Material 1 - AWS infrastructure\n- AWS Services\n- Create an AWS account - Create Budget - Account authentication support 09/11/2025 09/11/2025 2 - What is a VPC 09/12/2025 09/12/2025 AWS VPC Module 02-01 3 - VPC Security \u0026amp; Multi-VPC features 09/13/2025 09/13/2025 cont 4 - VPN 09/14/2025 09/15/2025 AWS VPN Basics 6 - Weekly knowledge summary 09/15/2025 09/15/2025 cont Achievements 1. AWS Infrastructure Region: Cluster of data centers. Availability Zones (AZs): Independent DCs within a region for fault tolerance. Edge Locations: Used for caching and latency reduction. 2. AWS Services \u0026amp; Access Management Tools: AWS Management Console, AWS CLI. Authentication: Access Key \u0026amp; Secret Key. Account Setup: Created AWS account. Enabled MFA devices. Created Admin Group \u0026amp; User. 3. Cost \u0026amp; Budget Management Cost Budgets Usage Budgets Reserved Instance (RI) Budgets Savings Plans Budgets Budget cleanup 4. Virtual Private Cloud (VPC) Concepts: Introduction to AWS Networking, Amazon VPC. Core Components: Subnets (Public \u0026amp; Private). Availability Zones for high availability. Route Tables \u0026amp; Gateways. Connectivity Options: VPC Peering \u0026amp; Transit Gateway. VPN \u0026amp; Direct Connect. Additional Features: Elastic Load Balancing (ELB). Elastic Network Interfaces (ENI). VPC Endpoints. Key Takeaway: VPC is the foundation for secure, scalable, and flexible networking in AWS. 5. VPC Security \u0026amp; Multi-VPC Features Security Group (SG): Controls inbound/outbound traffic at instance level. Network ACL (NACL): Controls traffic at subnet level. VPC Flow Logs: Capture IP traffic for monitoring and troubleshooting. Multi-VPC Connectivity: VPC Peering. Transit Gateway. 6. VPN \u0026amp; Extra Resources VPN Types: Site-to-Site VPN. Client-to-Site VPN. Direct Connect: Dedicated private connection to AWS. Elastic Load Balancing (ELB): Health Check. Sticky Sessions (Session Affinity). Application Load Balancer (ALB). Gateway Load Balancer (GLB). "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/3-blogstranslated/3.1-blog1/","title":"Blog 1","tags":[],"description":"","content":"How to SAN Boot Enterprise Amazon EC2 Environments from Amazon FSx for NetApp ONTAP Author: Randy Seamans Published: June 13, 2025 Source: Advanced (300), Amazon EC2, Amazon Elastic Block Store (Amazon EBS), Amazon FSx for NetApp ONTAP, AWS Partner Network, Migration, Storage, Thought Leadership\nIntroduction Traditionally, many enterprises and organizations using on-premises infrastructure have deployed boot-from-SAN (Storage Area Network) instead of using locally attached storage. Booting from SAN provides centralized management and backup of boot volumes, supports high availability through multipathing, and offers greater flexibility by allowing systems to boot from pre-configured OS images stored on shared storage arrays to reduce costs.\nAmazon FSx for NetApp ONTAP brings these benefits to the cloud. As a fully managed service by Amazon Web Services (AWS), FSx for ONTAP provides an enterprise-grade virtual storage array supporting features such as high-throughput I/O, deduplication, compression, compaction, replication, and block-level access through iSCSI and NVMe/TCP.\nMost importantly for SAN boot is the thin cloning capability. FSx for ONTAP allows a thinly provisioned LUN to act as a base \u0026ldquo;golden image\u0026rdquo; for the operating system (OS). Read-write snapshot clones of this LUN can be rapidly provisioned and distributed to hundreds of servers as separate boot volumes. Each clone only stores the minimal differences to identify each server, significantly reducing total storage capacity requirements.\nFurthermore, FSx for ONTAP is aware of shared data regions, allowing frequently accessed blocks to be cached in memory once and served to all clones, effectively extending cache efficiency and improving overall performance. Since FSx for ONTAP also provides high availability (HA) and disaster recovery (DR) through advanced replication mechanisms, boot volumes can be integrated into HA/DR workflows. This ensures OS state remains consistent across environments without manual intervention.\nBackground on Boot Devices in AWS AWS instances typically boot from Amazon Elastic Block Store (Amazon EBS) volumes, which are tightly integrated with Amazon Elastic Compute Cloud (Amazon EC2). This integration enables fast and stable boot times through features like EBS Fast Snapshot Restore and EBS Provisioned IOPS for volume initialization.\nAmazon EBS also provides enhanced security with customer-managed key (CMK) encryption, high reliability through independently operating boot volumes, and time-based AMI copies for efficient and consistent distribution across Regions. Designed for both general-purpose and high-performance workloads, Amazon EBS is the default boot device for Amazon EC2.\nIn this article, I will demonstrate how you can boot from iSCSI LUNs stored on FSx for ONTAP file systems in either Single-Availability Zone (AZ) or Multi-AZ configurations. These LUNs can be thin provisioned, space-efficient, and replicated between AZs or different AWS Regions.\nWhen properly configured, SAN booting from FSx for ONTAP can help reduce storage costs at scale while simplifying HA/DR operations.\nTwo Primary Use Cases for SAN Boot with FSx for ONTAP 1. Reducing Boot Volume Costs In on-premises environments, SAN boot is commonly used to reduce costs when deploying hundreds of servers with nearly identical boot volumes. This principle also applies in the cloud when using iSCSI boot with FSx for ONTAP.\nBy leveraging thin provisioning and snapshot-based cloning, the storage requirements for 100 to 200 boot volumes are only marginally higher than a single boot volume. Each server only consumes capacity for its unique differences from the golden image, dramatically reducing overall storage usage.\nFurthermore, by following the best practices mentioned later in this article, you can avoid provisioning dedicated IOPS for boot volumes thanks to FSx for ONTAP\u0026rsquo;s performance pooling capability. The result is significant cost savings while maintaining consistent performance.\n2. Simplifying HA/DR and OS Lifecycle Management OS updates and configuration changes are frequent requirements in enterprise workloads. Using SAN boot optimizes HA/DR workflows by replicating boot volumes across multiple Availability Zones (AZs) and remote AWS Regions.\nFSx for ONTAP supports both multi-AZ replication and long-distance replication, so any changes to the OS or boot volume are automatically synchronized and always in a highly available state. This significantly reduces the manual steps required for recovery during incidents while limiting the risk of human error, making it easier to meet stringent recovery time objectives (RTO).\nAdditionally, updates can be deployed first on a clone of the golden image, thoroughly tested, and only promoted to production once validated, streamlining the OS update process and minimizing disruption.\nHow SAN Boot from FSx for ONTAP Volumes Works To perform SAN boot from FSx for ONTAP, we use the concept of a network-based chain-loader boot device, sometimes called \u0026ldquo;jumpboot.\u0026rdquo;\nInitially, the EC2 instance quickly boots a compact, locked-down OS from a 1 GB EBS volume containing the Preboot eXecution Environment (iPXE). iPXE then chain-boots to a volume storing the actual Linux or Windows OS located on FSx for ONTAP.\nUsers can compile their own iPXE Amazon Machine Image (AMI) or use the AWS certified iPXE AMI available in every AWS Region as a community AMI. This chain-loading mechanism still allows integration with the Amazon EC2 console for operations like launch, start, stop, or using the serial console.\nHow does iPXE know which FSx for ONTAP and iSCSI volume to boot from? When launching an EC2 instance with the iPXE AMI, we pass that information in the user data script, and iPXE then chain-boots the new OS stored on the specified block volume.\nPractical Considerations and Best Practices Booting from SAN using FSx for ONTAP in AWS brings several considerations for planning and operations, similar to traditional on-premises SAN environments, with some cloud-specific best practices.\nOS Licensing Boot volumes are typically cloned, so each instance must fully comply with corresponding licensing requirements, especially for commercial operating systems like Microsoft Windows.\nStorage Placement Unless there are specific requirements otherwise, it\u0026rsquo;s best to place both boot volumes and data volumes for an EC2 instance on the same FSx for ONTAP system. This ensures optimal data locality and maintains consistent performance.\nAvoiding Boot Storms Another important best practice is avoiding concentrating too many boot volumes on a single FSx for ONTAP system. In large-scale recovery scenarios, often called \u0026ldquo;boot storms,\u0026rdquo; this can lead to boot time delays.\nFortunately, unlike traditional on-premises systems, in AWS there\u0026rsquo;s virtually no significant cost difference when distributing the same storage capacity across multiple FSx for ONTAP systems. This allows you to scale horizontally without incurring major additional costs, ensuring boot storms are avoided.\nFor example, an FSx for ONTAP system with 50 TB SSD capacity, by default and without provisioning dedicated IOPS, can achieve up to 150,000 IOPS. If this system supports SAN boot for 200 servers, during the boot phase each server would average 750 IOPS per second—more than six times faster than a typical HDD. Because applications and boot are co-located, there\u0026rsquo;s no application IO contending with the boot process during startup.\nMultipathing Configuration To prevent disruption, ensure multipathing is correctly configured and validated for all boot volumes connecting via iSCSI. Reliable path failover mechanisms are critical for maintaining both performance and fault tolerance.\nTesting HA and Failover Finally, testing HA and failover configurations before production is extremely important. You can simulate a failover event by temporarily increasing the throughput capacity of the FSx for ONTAP system. This triggers a non-disruptive controller failover, allowing you to verify multipath handling and OS stability. Once confirmed successful, you can reduce throughput back to the required level.\nGetting Started There are quite a few steps involved in setting up SAN boot OS in AWS with FSx for ONTAP. The best way to start is to explore the iPXE website page dedicated to AWS, and/or contact AWS directly if your organization needs to deploy SAN boot.\nFor large-scale migration projects to SAN boot from on-premises environments or from an existing AWS environment, Cirrus Data—an AWS Partner—provides solutions that automate the entire process, including iSCSI, multipathing configuration, provisioning, and LUN mapping, all of which are complex tasks at scale.\nIs SAN Boot from FSx for ONTAP Right for You? Booting from SAN using FSx for ONTAP block storage isn\u0026rsquo;t the choice for most AWS environments, but for organizations already accustomed to using SAN boot to simplify DR processes or orchestrate large-scale infrastructure with uniform OS images, this capability is now available on AWS.\nIf you\u0026rsquo;re managing a large fleet of EC2 instances requiring HA capability, failover between AZs, or cross-Region replication, FSx for ONTAP will help you significantly reduce boot volume costs while optimizing failover and DR workflows.\nIn summary, you can absolutely apply proven SAN boot strategies in the cloud environment with AWS\u0026rsquo;s scale and durability.\nTags Amazon EC2, Amazon FSx for NetApp ONTAP, AWS Partner Network, AWS Storage, Data Migration\nAbout the Author Randy Seamans is a veteran storage industry expert and Principal Storage Specialist \u0026amp; Advocate for AWS, specializing in High Performance Storage (HPC/AI), Enterprise Storage, and Disaster Recovery.\nFor more insights and fun about Storage, follow him at: https://www.linkedin.com/in/storageperformance\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/3-blogstranslated/3.2-blog2/","title":"Blog 2","tags":[],"description":"","content":"Querying Amazon S3 Tables from Open-Source Trino Using the Apache Iceberg REST Endpoint Authors: Aneesh Chandra PN, Aritra Gupta, Ananta Khanal, and Madhu Nagaraj\nPublication date: June 13, 2025\nSource: Advanced (300), Amazon EC2, Amazon S3 Tables, Amazon Simple Storage Service (S3), Amazon VPC, AWS CLI, AWS CloudFormation, AWS Identity and Access Management (IAM), Technical How-to\nOrganizations are increasingly focused on tackling the growing challenge of managing and analyzing massive volumes of data, while ensuring their data teams have timely access to that data so they can quickly generate insights and make decisions. Analysts and data scientists need self-service analytics capabilities to build and maintain data products, which often involve complex transformations and frequent updates. However, this creates significant operational overhead—from managing small files and delete markers, to handling ever-expanding metadata and rising storage costs for historical versions. If left unaddressed, these challenges can hurt query performance and increase infrastructure costs.\nModern data architectures have evolved to address these challenges using powerful open-source technologies such as Trino and Apache Iceberg , combined with managed services like Amazon S3 Tables . Trino excels at distributed querying across a wide variety of data sources, while Apache Iceberg provides a robust table format with ACID transactions, schema evolution, and time travel. S3 Tables complement this stack by providing automatic optimization and maintenance for Iceberg tables, delivering consistent performance without manual intervention.\nIn this post, we show how to integrate Trino with S3 Tables to create a powerful analytics platform that combines the best of both technologies. We walk through the setup process using the S3 Tables table-management APIs that are compatible with the Apache Iceberg REST catalog standard, illustrating how to configure the integration with Trino and enable key benefits such as automatic data compaction and snapshot management. By the end of the post, you’ll see how to use this powerful combination to build and maintain high-performance data products at scale.\nThis post focuses on configuration for the S3 Tables Iceberg REST endpoint. You can also use S3 Tables with the AWS Glue Iceberg REST endpoint. For unified governance across all tabular data, fine-grained access control, and centralized data management, we recommend using Amazon SageMaker Lakehouse , which supports S3 Tables as a linked catalog.\nSolution Overview The S3 Tables Iceberg REST endpoint provides a standards-based API that allows Trino to communicate directly with S3 Tables without any proprietary connector or additional middleware. This means your Trino deployments can immediately take advantage of the built-in S3 Tables optimizations for Iceberg workloads.\nThis guide will show you how to:\nDeploy a single-node Trino environment using an AWS CloudFormation template Configure the Iceberg REST connector to communicate with S3 Tables Create schemas and tables directly in S3 Tables from Trino Perform full-fidelity Iceberg read/write operations Use advanced features such as time travel and schema evolution Deployment architecture: Although Trino is typically deployed as a multi-node distributed architecture for production workloads to leverage parallel processing, this post uses a single Amazon Elastic Compute Cloud (Amazon EC2) instance so that you can quickly explore the S3 Tables–Trino integration. The Iceberg catalog configuration will be the same when you deploy on your own Trino cluster for production use cases.\nPrerequisites You need the following to complete this solution:\nAn AWS account with permissions to create resources such as EC2 instances, AWS Identity and Access Management (IAM) roles, and S3 table buckets An Amazon Virtual Private Cloud (Amazon VPC) with a public subnet (or a private subnet with VPN access) An Amazon EC2 key pair for SSH access The AWS Command Line Interface (AWS CLI) installed and configured (optional, used for manually creating the S3 table bucket) Step-by-Step Guide The following sections walk you through deploying this solution.\nPart A: Deploy Trino with S3 Tables Integration This section provides step-by-step instructions for launching a Trino environment using the supplied CloudFormation template. It also describes the resources required to build this solution. To simplify integration between Trino and S3 Tables, we’ve created a CloudFormation template that automates the entire deployment process.\n1. CloudFormation Template Overview The CloudFormation template provisions all the components required for a complete Trino environment that can read and write data to S3 Tables through the Iceberg REST endpoint:\nS3 table bucket: Creates a dedicated bucket to store your data EC2 instance: Deploys a single-node Trino server using version 475 Security group: Configures network access for SSH and the Trino web UI IAM instance profile: Grants the EC2 instance the appropriate permissions 2. Deployment Process Download the CloudFormation template. In the CloudFormation console, choose Create stack \u0026gt; With new resources (standard) as shown in the screenshot. Upload the template file and choose Next . Provide values for the template parameters: Stack name: A name for your CloudFormation stack KeyName: An existing EC2 key pair for SSH access VpcId: The VPC in which to deploy the EC2 instance SubnetId: A public subnet in your VPC S3TablesBucketName: A name for your S3 table bucket AwsRegion: The AWS Region for S3 Tables and AWS Glue TrinoInstanceType: EC2 instance size (default: t3.xlarge) Choose Next on the stack options page. Review the details, confirm that CloudFormation can create IAM resources, and then choose Create stack . Wait for stack creation to complete (about 10–15 minutes). When the stack is complete, you can find useful information in the Outputs tab:\nPublicDNS: The public DNS name of your Trino instance SSHCommand: The SSH command you can use to connect to the instance TrinoURL: The URL for the Trino web UI TableBucketName: The name of your S3 table bucket 3. What the Deployment Does The CloudFormation template performs several key tasks:\nInfrastructure provisioning: Sets up the EC2 instance, security group, and S3 table bucket Software installation: Installs Amazon Corretto Java 23 and Trino 475 Configuration: Creates the required Trino configuration files Integration setup: Configures the Iceberg REST connector for S3 Tables Part B: Connecting Trino to Amazon S3 Tables Using the Iceberg REST Endpoint The CloudFormation template automatically configures the S3 Tables catalog in Trino. In this section, we’ll look at the configuration that enables this integration.\n1. Catalog Configuration Details A catalog in Trino is a configuration that allows access to a specific data source. A single Trino cluster can be configured with multiple catalogs, providing simultaneous access to different data sources.\nIn this setup, the CloudFormation template creates a catalog properties file at:\n/home/ec2-user/trino-server-475/etc/catalog/s3tables_irc.properties\nwith the following configuration:\nconnector.name=iceberg iceberg.catalog.type=rest iceberg.rest-catalog.uri=https://s3tables.${AwsRegion}.amazonaws.com/iceberg iceberg.rest-catalog.warehouse=arn:aws:s3tables:${AwsRegion}:${AWS::AccountId}:bucket/${S3TablesBucketName} iceberg.rest-catalog.sigv4-enabled=true iceberg.rest-catalog.signing-name=s3tables iceberg.rest-catalog.view-endpoints-enabled=false fs.hadoop.enabled=false fs.native-s3.enabled=true s3.iam-role=\u0026lt;ARN of the IAM ROLE with permissions to S3 Tables\u0026gt; s3.region=${AwsRegion} 2. S3 Tables Iceberg REST Endpoint Configuration Properties The table below lists the key properties in the Trino catalog configuration:\nProperty Description iceberg.rest-catalog.uri REST server API endpoint URI (required ) —https://s3tables.${AwsRegion}.amazonaws.com/iceberg iceberg.rest-catalog.warehouse Warehouse identifier/location for the catalog (required ). For S3 Tables, this is the ARN of the S3 table bucket, as shown in the example above. iceberg.rest-catalog.sigv4-enabled Must be set to true( required ) iceberg.rest-catalog.signing-name Must be set to s3tables( required ) iceberg.rest-catalog.view-endpoints-enabled Must be set to false( required ) fs.hadoop.enabled Must be set to false fs.native-s3.enabled Must be set to true s3.iam-role Amazon Resource Name (ARN) of the IAM role with permissions to S3 Tables. In this post, we use the same role attached to the EC2 instance. s3.region AWS Region, for example us-east-1 This configuration establishes the connection between Trino and the S3 Tables REST endpoint. You can register multiple catalogs, each mapped to a different S3 table bucket, identified by the iceberg.rest-catalog.warehouse property.\n3. Working with S3 Tables in Trino After you’ve set up and configured Trino to work with S3 Tables, you can start exploring the integration.\n3.1. Connecting to Trino Add your desired IP or subnet to the inbound rules of the Trino security group to allow SSH access (port 22).\nConnect to the EC2 instance using the SSH command provided in the CloudFormation stack outputs:\nssh -i your-key.pem ec2-user@your-instance-public-dns Once connected, use the Trino CLI, which the CloudFormation template installed automatically:\ncd /home/ec2-user ./trino-cli --catalog s3tables_irc This command connects you to the Trino server using the S3 Tables catalog configuration you set up.\n3.2. Example: Creating and Querying a Table In this section, you’ll run a few example queries to demonstrate how the system works.\n3.2.1. Create a Namespace First, create a namespace (schema) in S3 Tables. A namespace in S3 Tables is a logical container or organizational unit that groups related tables and objects.\nCREATE SCHEMA blog_namespace; USE blog_namespace; 3.2.2. Create a Table Create a table with a variety of data types. You don’t need to specify the table type as Iceberg because you’re connecting to an Iceberg catalog. You can use all standard Iceberg capabilities such as partitioning and sorting.\nIn addition, several important Iceberg table properties that support table maintenance operations are configured with default values. You can also modify these settings using the S3 Tables maintenance APIs .\nCREATE TABLE IF NOT EXISTS customers ( customer_sk INT, customer_id VARCHAR, salutation VARCHAR, first_name VARCHAR, last_name VARCHAR, preferred_cust_flag VARCHAR, birth_day INT, birth_month INT, birth_year INT, birth_country VARCHAR, login VARCHAR ) WITH ( format = \u0026#39;PARQUET\u0026#39;, sorted_by = ARRAY[\u0026#39;customer_id\u0026#39;] ); SHOW TABLES; DESCRIBE customers; 3.3.3. Insert Data You can insert some sample data into the table. You can also use an existing table in any catalog already configured in Trino and populate an S3 Table using an INSERT INTO .. SELECT statement.\nINSERT INTO customers VALUES (1, \u0026#39;AAAAA\u0026#39;, \u0026#39;Mrs\u0026#39;, \u0026#39;Amanda\u0026#39;, \u0026#39;Olson\u0026#39;, \u0026#39;Y\u0026#39;, 8, 4, 1984, \u0026#39;US\u0026#39;, \u0026#39;aolson\u0026#39; ), (2, \u0026#39;AAAAB\u0026#39;, \u0026#39;Mr\u0026#39;, \u0026#39;Leonard\u0026#39;, \u0026#39;Eads\u0026#39;, \u0026#39;N\u0026#39;, 22, 6, 2001, \u0026#39;US\u0026#39;, \u0026#39;leads\u0026#39; ), (3, \u0026#39;BAAAA\u0026#39;, \u0026#39;Mr\u0026#39;, \u0026#39;David\u0026#39;, \u0026#39;White\u0026#39;, \u0026#39;Y\u0026#39;, 16, 2, 1999, \u0026#39;US\u0026#39;, \u0026#39;dwhite\u0026#39; ), (4, \u0026#39;BBAAA\u0026#39;, \u0026#39;Mr\u0026#39;, \u0026#39;Melvin\u0026#39;, \u0026#39;Lee\u0026#39;, \u0026#39;N\u0026#39;, 30, 3, 1973, \u0026#39;US\u0026#39;, \u0026#39;mlee\u0026#39; ), (5, \u0026#39;AACAA\u0026#39;, \u0026#39;Mr\u0026#39;, \u0026#39;Donald\u0026#39;, \u0026#39;Holt\u0026#39;, \u0026#39;N\u0026#39;, 2, 6, 1982, \u0026#39;CA\u0026#39;, \u0026#39;dholt\u0026#39;), (6, \u0026#39;ABAAA\u0026#39;, \u0026#39;Mrs\u0026#39;, \u0026#39;Jacqueline\u0026#39;, \u0026#39;Harvey\u0026#39;, \u0026#39;N\u0026#39;, 5, 12, 1988, \u0026#39;US\u0026#39;, \u0026#39;jharvey\u0026#39;), (7, \u0026#39;BBAAA\u0026#39;, \u0026#39;Ms\u0026#39;, \u0026#39;Debbie\u0026#39;, \u0026#39;Ward\u0026#39;, \u0026#39;N\u0026#39;, 6, 1, 2006, \u0026#39;MX\u0026#39;, \u0026#39;dward\u0026#39;), (8, \u0026#39;ACAAA\u0026#39;, \u0026#39;Mr\u0026#39;, \u0026#39;Tim\u0026#39;, \u0026#39;Strong\u0026#39;, \u0026#39;N\u0026#39;, 15, 7, 1976, \u0026#39;US\u0026#39;, \u0026#39;tstrong\u0026#39; ); 3.3.4. Query the Data You can query the data you just inserted with:\nSELECT * FROM customers LIMIT 10; Create Table As Select (CTAS) Trino also supports creating a table from the result of a query. In this example, you create a copy of the previous table:\nCREATE TABLE trino_customers WITH ( format = \u0026#39;PARQUET\u0026#39; ) AS SELECT * FROM customers; SELECT * FROM trino_customers LIMIT 10; Altering a Table One of the benefits of using Iceberg is schema evolution . You can add a new column and then populate it. Each transaction from Trino (such as an ALTER DDL statement) creates a new Iceberg table snapshot.\nALTER TABLE trino_customers ADD COLUMN updated_at TIMESTAMP; DESCRIBE trino_customers; UPDATE trino_customers SET updated_at = current_timestamp; SELECT * FROM trino_customers LIMIT 10; 3.4. Advanced Iceberg Features Trino provides access to Iceberg’s metadata, allowing you to inspect information about the objects stored in S3 Tables. This makes it easier to understand how data is organized and what’s associated with each table transaction.\n3.4.1. Querying Table Metadata -- View snapshot information SELECT * FROM \u0026#34;trino_customers$snapshots\u0026#34;; -- View data file information SELECT * FROM \u0026#34;trino_customers$files\u0026#34;; 3.4.2. Time Travel Time travel is a powerful feature of the Apache Iceberg table format that lets you query data as of a specific point in the past. This is especially useful for analytics, auditing, and reproducing historical results.\nTrino supports time travel using the FOR VERSION AS OF syntax, where you can provide a snapshot ID or a timestamp, as shown below:\n-- Time travel using a snapshot ID (replace \u0026lt;snapshot ID\u0026gt; with an actual ID from the snapshots query above) SELECT * FROM trino_customers FOR VERSION AS OF \u0026lt;snapshot ID\u0026gt;; -- Time travel using a timestamp SELECT * FROM trino_customers FOR TIMESTAMP AS OF TIMESTAMP \u0026#39;2025-03-13 08:00:00.000 UTC\u0026#39;; 3.4.3. Viewing History and Rolling Back Iceberg’s history and rollback features provide powerful data-versioning capabilities. You can view the full history of operations on a table and easily revert to a previous state using a timestamp or snapshot ID, which helps ensure data recovery and auditing in your data lake.\n-- Delete a record DELETE FROM trino_customers WHERE customer_sk = 8; -- View the table history SELECT * FROM \u0026#34;trino_customers$history\u0026#34;; -- Roll back to a previous snapshot (replace \u0026lt;snapshot ID\u0026gt; with the ID from before the delete) ALTER TABLE trino_customers EXECUTE rollback_to_snapshot(\u0026lt;snapshot ID\u0026gt;); Now for the fun part—we’ve run several transactions with the example queries above and seen how Iceberg creates a snapshot for each transaction (or table operation). In real-world scenarios, you may need to update data frequently, or continuously load small batches of data into a table every few seconds or minutes. These operations often create many small files, which can degrade performance, cause duplicated data across multiple snapshots, and leave behind expired data (older versions of records that have been updated or deleted).\nS3 Tables provide maintenance operations such as data compaction , snapshot management , and orphan-file cleanup to keep tables optimized and reduce storage costs by removing unnecessary files. These options are enabled by default for all tables with preconfigured properties, and you can also customize them at the individual table level based on your requirements. You can learn more about S3 Tables maintenance in the documentation.\nCleanup To clean up resources, complete the following steps:\nDelete data and tables (you can do this directly from the Trino CLI, avoiding the need for the AWS CLI). In the AWS console, go to CloudFormation and delete the stack you created. Conclusion In this post, we demonstrated seamless integration between Trino and Amazon S3 Tables using the Iceberg REST endpoint. This powerful combination lets you use Trino’s distributed query engine to perform interactive analytics on data stored in S3 Tables, while benefiting from Iceberg features such as transactional support, schema evolution, and time travel—along with the built-in Iceberg optimizations provided by S3 Tables.\nThis solution delivers a flexible, high-performance platform for modern data analytics on AWS. By automating deployment with CloudFormation and leveraging the standard Iceberg REST interface, you can quickly set up this integration and start extracting value from your data. Whether you’re building a new data platform or extending an existing system, the combination of Trino and S3 Tables offers a solid foundation for analytical workloads at scale.\nTo learn more, see:\nThe guides for using S3, Trino, and the Apache Iceberg usage and configuration documentation Additional S3 Tables posts on the AWS Storage Blog Keywords: Amazon Elastic Compute Cloud (Amazon EC2), Amazon Simple Storage Service (Amazon S3), Amazon VPC, AWS Cloud Storage, AWS CloudFormation, AWS Command Line Interface (AWS CLI), AWS Identity and Access Management (IAM)\nAbout the Authors Aneesh Chandra PN\nAneesh Chandra PN is a Principal Analytics Solutions Architect at AWS working with Strategic customers. He is passionate about leveraging technology advancements to solve customers’ data challenges. He uses his deep expertise in analytics, distributed systems, and open-source frameworks to act as a trusted technical advisor to AWS customers.\nAritra Gupta\nAritra Gupta is a Senior Technical Product Manager on the Amazon S3 team at AWS. He helps customers build and scale multi-Region architectures on Amazon S3. Based in Seattle, he enjoys playing chess and badminton in his free time.\nAnanta Khanal\nAnanta Khanal is a Senior Solutions Architect at AWS focused on data and cloud-computing solutions. He has worked in IT for more than 15 years and has held various roles across different companies. He is passionate about cloud technologies, infrastructure management, IT strategy, and data management.\nMadhu Nagaraj\nMadhu is a Senior Technical Account Manager (TAM) at Amazon Web Services (AWS) with more than 20 years of experience in IT, including software engineering, cloud operations, and automation. Since joining AWS in 2021, he has been passionate about helping enterprise customers navigate and adopt emerging technologies. He currently focuses on helping customers innovate with Generative AI and AI Agents, combining strong technical capabilities with cost optimization and operational efficiency. Outside of work, Madhu enjoys spending time with his family and hiking.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/3-blogstranslated/3.3-blog3/","title":"Blog 3","tags":[],"description":"","content":"SMS Onboarding for SaaS, ISVs, and Multi-Tenant Applications with AWS End User Messaging Author: Tyler Holmes\nPublication date: May 13, 2025\nSource: AWS End User Messaging, Messaging, SaaS\nIntroduction SMS messaging remains one of the most reliable and effective communication channels. However, for software-as-a-service (SaaS) companies, independent software vendors (ISVs), and multi-tenant solution providers that want to integrate SMS capabilities into their products, the journey can become complex and challenging.\nThis guide is designed specifically for technology providers—whether you are a SaaS company, an ISV, or any platform that allows your customers to send SMS messages to end users. Throughout this article, we use the following terms:\nProvider: An organization that offers SMS capabilities as part of its product or service. Customer: The entities that use the Provider’s technology to send SMS messages. End User: The recipients who have agreed to receive SMS messages from the Customer. Implementing SMS can be complicated, with regulations that vary by country, registration processes that can take weeks or even months, multiple originator types (long codes, short codes, sender IDs, etc.) with different capabilities, and diverse needs across Customers and End Users. These challenges are even more pronounced when you, as a Provider, are offering SMS as a service to your own Customers, who in turn serve End Users.\nBy the end of this guide, you will understand:\nHow opt-in flows affect your architecture. Options for structuring your SMS service for Customers. Strategies to reduce complexity during SMS implementation. Let’s dive in.\nThe Registration Dilemma: Who Owns the Relationship? One of the most important decisions when registering an SMS originator is determining whose information will be used in the registration. The biggest mistake AWS often sees Providers make is not understanding how their relationship with Customers and Customers’ End Users will impact the system architecture and how they complete the required registration steps.\nMobile network operators want to know who will be sending SMS messages to their subscribers, how that entity collects opt-ins, and what content will be sent. When registering an originator—especially in the United States—you must clearly explain how End Users will opt in and confirm that their data will not be shared with any third parties. Your architecture must ensure:\nA clear opt-in process with a well-defined responsible entity. A privacy policy that accurately reflects how data is shared. Compliance with third-party data-sharing regulations. (A deeper analysis of opt-in and registration flows can be found here. Sample clauses for privacy policies can be found here.)\nAWS frequently sees Providers register themselves as the originator even though they have no direct relationship with the Customer’s End Users. The decision about whose information to use in registration mainly comes down to one basic question:\nWho does the End User believe they are forming a relationship with when they provide their phone number?\nThe most common scenarios are described below.\nScenario 1: End Users Interact Only with the Customer’s Brand In most cases, End Users are completely unaware of your existence as the Provider. They believe they are opting in to receive messages directly from your Customer. In this scenario:\nRegistration should be done using the Customer’s information. There are many ways you can support this process, and later in this article we’ll discuss several methods to reduce common friction points. Messages must appear to be sent from the Customer, not from the Provider, and the name of your service should not appear in the message content. Scenario 2: End Users Opt In Directly Through the Provider’s Application In some cases, End Users understand clearly that they are opting in to receive messages through your technology platform, on behalf of your Customers. Opt-in data is not shared with the Customer, and your brand as the Provider is the entity named in all outgoing SMS messages.\nThis can happen in several ways:\nEnd Users may opt in using a widget you build that Customers install on their websites or apps. A paper form or phone script you provide, which clearly identifies you as the Provider. AWS often sees this scenario with Providers that offer:\nThird-party payment processing Shipping and logistics support Customer service platforms One-time-password (OTP) capabilities In this scenario, your company name will typically appear in the messages, and registration will use your company’s information.\nNOTE: There are exceptions to these two scenarios and implementations can be complex. If you are a Provider and feel that you don’t fit neatly into either scenario, contact your account manager, open a support case, or talk to an expert before implementing anything.\nArchitectural Models for Implementing SMS Let’s explore different architectural models for building an SMS service based on your business needs and your relationship with Customers. Each model has its own characteristics:\n1. “Bring Your Own AWS Account” Model Who performs registration and configuration?\nThe Customer connects their own AWS account, so registration and configuration happen within the Customer’s account. The information used in registration in this scenario is typically the Customer’s, because it is their account.\nCustomer responsibilities:\nPerform all required registration and configuration steps. Integrate their account with the Provider’s service. Manage message sending, opt-out lists, etc. Pay the AWS bill. Provider responsibilities:\nProvide a user-friendly interface that calls AWS End User Messaging Service APIs using the Customer’s credentials. The level of service the Provider offers can vary depending on needs. Best suited for:\nTechnical Customers who want full control and are already familiar with AWS; Providers who want to avoid the complexity of registration and configuration.\n2. “Provider Account – Manual Registration and Configuration” Model Who performs registration and configuration?\nThe Provider owns the AWS account and does not give Customers a way to enter their own information, so the Provider enters it on their behalf.\nCustomer information is collected manually. The Provider handles registration and configuration complexity via the console. Customer responsibilities:\nProvide the necessary information to the Provider for registration. Provider responsibilities:\nManually collect registration information from Customers. Manage complexity on the Customer’s behalf. This model can be implemented in two ways: using a separate AWS account for each Customer, or using a multi-tenant architecture within a single account.\nBest suited for:\nProviders with a small number of high-value Customers who need hands-on support throughout SMS onboarding.\nYou did an excellent job consolidating all of the SMS deployment models (“Architectural Models for Implementing SMS”) into a complete article that follows the AWS Storage Blog format.\nBelow is a suggested, fully written-out version in Vietnamese, split into sections with headings, paragraphs, and bullet points like in the example you provided:\n(This meta paragraph is commentary to the reader in Vietnamese; if you don’t need it in English in your final article, you can remove it.)\n3. “Semi-Automated – Customer Submits” Model Who performs registration and configuration?\nThe Provider builds mechanisms for Customers to submit registration information, and then programmatically forwards this data to carriers/regulators.\nCustomer responsibilities\nYour platform manages technical configuration and sending capabilities, but Customers remain responsible for compliance. Provider responsibilities\nProvide convenient ways for Customers to submit information (webhooks, forms, APIs). Automatically send registration data to regulators. Manage technical configuration and sending capabilities. Best suited for:\nProviders with moderate technical capabilities who want to reduce friction while preserving clear separation of legal responsibility.\n4. “Fully Automated – Provider Sends” Model Who performs registration and configuration?\nCustomer information is used in registration, but the Provider fully automates the registration process.\nCustomer responsibilities\nFocus solely on message-level compliance; all technical aspects are handled by the Provider. Provider responsibilities\nProvide ready-to-use, customizable terms of service and privacy policies. Provide compliant opt-in channels (web forms, phone scripts, etc.). Handle all technical aspects of registration. Best suited for:\nLarger Providers serving many Customers with varying levels of technical sophistication.\n5. “Fully Automated Messaging Constrained by Templates” Model Who performs registration and configuration?\nCustomer information is used for registration, but the Provider processes it automatically.\nCustomer responsibilities\nCentralized compliance: they are only allowed to personalize fields within pre-approved message templates. Provider responsibilities\nProvide a set of pre-approved message templates. Centrally manage compliance. Simplify registration because content is tightly controlled. Best suited for:\nPredictable messaging scenarios such as appointment reminders, delivery notifications, or OTP messages.\n6. “Fully Managed Program” Model Who performs registration and configuration?\nCustomers authorize the Provider to send messages on their behalf, meaning the Provider owns the relationship with the End User.\nCustomer responsibilities\nProvide only the information necessary to personalize messages (for example, a tracking number). Provider responsibilities\nManage the entire relationship with End Users. Control the entire messaging experience, including collecting opt-ins. Example: A delivery notification service might send:\n“ShipTrack: Your order from ACME Corp will arrive tomorrow. Track it at [link].”\nBest suited for:\nSpecialized scenarios where your platform delivers significant value as a clearly identified intermediary.\nShaping Your SMS Service: Strategic Factors to Consider Pricing Strategy When integrating SMS into your product, one of the first factors to consider is how to structure pricing. Unlike many digital services with predictable costs, SMS pricing varies significantly by destination country, originator type, and message volume.\nAWS End User Messaging Service charges based on the volume of messages sent to each country, with a different rate per country. Pricing is determined by the country code of the recipient’s device, not their physical location. This means that even if you primarily serve customers in the United States, you may still need to account for international costs when recipients use non-US phone numbers.\nThere are also one-time and recurring fees to consider. Registrations often incur one-time processing fees, and number providers may charge monthly rental fees ranging from free to over USD 1,000 per month for short codes in some countries. Make sure you consider whether and how these costs will be passed on to your Customers.\nWhen designing your pricing model, consider these common volume-based approaches:\nSMS Credits: Create a standardized credit system where Customers buy credits regardless of destination country. You manage the internal conversion between credits and actual cost. Dollar-Based Allocation: Give Customers a monetary budget that is consumed based on the actual cost of each message. Country-Tiered Pricing: Group countries into tiers (for example, Tier 1 for North America, Tier 2 for Western Europe) and charge different prices for each tier. Bundled Messaging: Include a certain number of messages in your base package, with additional charges for overage. Each approach has trade-offs in simplicity, transparency, and risk management. Your choice should align with your overall business model and customer expectations.\nGeographic Considerations Different countries have different regulatory requirements for SMS messaging, including:\nOriginator support: Not all countries support all originator types. (See details here.) Originator selection: When multiple originator types are supported, how will you help Customers choose the right one for each use case? (Read this guide to help decide which originator type fits your use case.) Registration: Increasingly, countries require registration before you are allowed to send. Quiet hours: Many countries restrict when promotional messages can be sent. Content restrictions: Certain content types (gambling, alcohol, adult content, etc.) may be prohibited or heavily regulated. (A more complete list can be found here.) Template requirements: Some jurisdictions require pre-approval of message templates. Sender ID regulations: Rules about who can use alphanumeric Sender IDs vary widely. As a Provider, you must decide which countries you will support and how you’ll maintain compliance across markets. This decision impacts not only pricing, but your entire product architecture—especially if you serve global Customers.\nStrategies to Reduce Friction During Implementation Implementing SMS can be complex for your Customers. Below are several strategies that can simplify and/or streamline the process. Many of these can be combined and can also be offered as value-added services, or even as paid services, for your Customers:\nProvider-Hosted Privacy Policy and/or Terms \u0026amp; Conditions Create compliant, customizable templates for privacy policies and terms \u0026amp; conditions that your Customers can use. This ensures SMS activities are fully disclosed without requiring Customers to update their own legal documents.\nOnline Registration Forms and Flows Develop user-friendly online forms that collect all required registration information in a guided process. These forms can significantly simplify complex procedures such as brand and campaign registration\nPre-Approved Opt-In Widgets Create embeddable widgets—like Figures 1–3 above—that your Customers can add to their websites or apps to implement compliant opt-in flows. These widgets can include all required disclosures and confirmations while remaining easy to integrate.\nTemplate Library Provide a library of pre-approved message templates for common use cases. This reduces compliance risk and simplifies sending for your Customers.\nTest Environments Create sandbox environments where Customers can test their SMS implementations before going live. This helps uncover issues with formatting, opt-in flows, or content compliance.\nDocumentation and Training Develop clear documentation and training resources specific to each originator type and use case. This helps your Customers operate more independently while reducing your support burden.\nConclusion Integrating SMS capabilities into your platform can significantly increase engagement with your Customers, but the journey can be complex. This guide has explored the key factors that will help you navigate it successfully.\nWe’ve examined multiple architectural models, each with its own trade-offs between Customer and Provider responsibilities. We’ve also looked at strategic factors such as pricing, geographic regulations, and originator types that must be carefully considered. Finally, we discussed practical strategies to reduce friction for your Customers—such as hosted compliance materials, streamlined registration flows, and pre-approved templates—to simplify integration.\nThe single most important first step is to clearly understand the relationship between you (as the Provider), your Customers, and their End Users. This determines whose information is used for originator registration and, in turn, shapes the SMS experience.\nUltimately, a successful SMS solution requires balancing technical considerations, regulatory requirements, and customer focus. By leveraging this guide, you can design and implement a service that delivers the best possible experience for both your Customers and their End Users.\nAdditional resources How to plan for SMS workloads How to build a compliant opt-in program AWS End User Messaging SMS service documentation SMS API v2 About Tyler Holmes Tyler is a Senior Specialist Solutions Architect. He has extensive experience in communications as a consultant, solutions architect, practitioner, and leader at every level from startups to Fortune 500 companies. He has more than 14 years of experience across sales, marketing, and service operations, working for vendors, consultancies, and brands, building teams and growing revenue.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/4-eventparticipated/4.1-event1/","title":"Event 1","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AI/ML, GenAI \u0026amp; Amazon Bedrock on AWS\u0026rdquo; Event Objectives Understand the AI/ML/GenAI ecosystem on AWS Learn how Bedrock, RAG, Agent Core, and Browser Tool work Apply Prompt Engineering techniques to interact effectively with LLMs Explore AI services such as Rekognition, Textract, Transcribe, Translate Connect GenAI capabilities to modern application development Speakers Lam Tuan Kiet – Generative AI \u0026amp; Prompt Engineering Techniques Dinh Le Hoang Anh – AI/ML Services \u0026amp; AWS AI Stack Danh Hoang Hieu Nghi – Amazon Bedrock Agent Core \u0026amp; Browser Tool Key Highlights Overview of AI/ML/GenAI on AWS The event provided a deep dive into the modern AI stack on AWS — from traditional machine learning to Foundation Models, combined with tools such as Titan Embeddings, RAG, Bedrock Agents, and Prompt Engineering.\nKey topics covered:\nThe role of embeddings in semantic search and RAG How Bedrock Agents perform planning and tool usage The RAG pipeline and real-world use cases Supporting AI services for vision, speech, and document processing Embeddings \u0026amp; RAG Embeddings Represent text/images as numerical vectors Used for search, similarity, clustering, face recognition, and RAG Amazon Titan Text Embedding provides 1536–3072-dimensional embeddings optimized for semantic retrieval RAG in Action User submits a query Query is converted into an embedding Vector DB is searched (FAISS, OpenSearch) Relevant context is retrieved LLM generates an answer based on the retrieved context RAG improves accuracy, reduces hallucination, and integrates enterprise-specific data.\nPrompt Engineering Techniques Techniques introduced: Zero-shot prompting – reasoning without examples Few-shot prompting – guiding the model with examples Chain of Thought – enforcing step-by-step reasoning RAG Prompting – augmenting LLM with retrieved context Instruction-style prompting – optimizing for task compliance Goal: make AI produce exactly what you intend.\nAmazon Bedrock Agents Agent Core The intelligent orchestration layer of Bedrock Agents Performs planning, reasoning, and task interpretation Automatically decides which tools to use: RAG, API calls, Code Interpreter, Browser Tool… Executes multi-step workflows with minimal backend logic Supports Memory, Runtime, and Observability Browser Tool Allows agents to browse the web and access real-time information Fetch URLs, perform web searches, extract website text Ideal for news, stock prices, public documents, online articles Key distinction:\nBrowser Tool = external online data RAG = internal enterprise knowledge AWS AI Services Overview The event also clarified the landscape of AWS AI services, which are outside Bedrock, but integrate extremely well with GenAI:\nRekognition Detect/compare faces Object detection Content moderation Used for security, FaceID, and filtering sensitive content Translate Real-time neural machine translation Supports domain customization and S3 file translation Textract Enterprise-grade OCR Extract structured forms, tables Parse ID documents for KYC workflows Transcribe Speech-to-text Speaker diarization Real-time transcription Polly Text-to-speech with natural neural voices Comprehend Classical NLP: sentiment, entity extraction, PII detection Kendra Enterprise semantic search FAQ matching \u0026amp; document ranking Personalize Real-time recommendation system used by Amazon.com Lookout Family Anomaly detection across vision, equipment telemetry, and business metrics Key Takeaways AI/GenAI Mindset Always start with the business problem, not the technology GenAI complements traditional ML — it doesn’t replace it Embeddings + RAG is the foundation for enterprise GenAI solutions Better prompts = better outcomes Technical Architecture Bedrock Agents enable automated AI workflows without heavy backend code Browser Tool extends an agent’s knowledge with real-time web information Vector DB sits at the core of retrieval-powered AI AWS AI services (Rekognition, Textract…) enhance GenAI-based systems Modernization \u0026amp; Real Applications Examples highlighted:\nTextract → RAG → Bedrock → Document chatbot Transcribe → Summary → Insight extraction Rekognition → Vision analysis with reasoning via Bedrock Personalize → Recommendation + GenAI explanations Applying to Work Build an internal knowledge assistant using RAG + Titan Embeddings Integrate Textract into automation workflows for document processing Use Bedrock Agent Core + Browser Tool to power multi-step agents Adopt prompt engineering guidelines across teams Explore Rekognition/Textract/Transcribe for operational automation Event Experience Participating in the “AI/ML \u0026amp; GenAI on AWS” workshop gave me a comprehensive understanding of how AWS builds an open, flexible, and modern AI platform.\nLearning from Experts Speakers clearly explained how to apply GenAI to real business scenarios Gained clarity on the differences between traditional ML, Foundation Models, and GenAI Understood the future potential of Bedrock Agents Hands-On Knowledge Practiced RAG pipelines and embedding generation Explored vector databases and semantic retrieval Tested multiple prompt engineering techniques Tools \u0026amp; Productivity Saw how Amazon Q Developer accelerates the entire SDLC Learned how various AI services fit into modern workflows Lessons Learned GenAI is not “one model” — it is a full system architecture Success requires data → embedding → RAG → agent → workflow design Collaboration between business and technical teams is essential Event Photos "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/4-eventparticipated/4.2-event2/","title":"Event 2","tags":[],"description":"","content":"Summary Report: “DevOps on AWS” Event Objectives Introduce the fundamentals and benefits of Infrastructure as Code (IaC) . Provide an in-depth overview of AWS CloudFormation and AWS CDK . Offer foundational knowledge on Docker , container images, and workflows. Explore AWS container services: ECR, ECS, EKS, and App Runner . Present CI/CD implementation approaches and comparisons between DevOps tools. Speakers Bao Huynh – AWS Community Builder Thinh Nguyen – AWS Community Builder Vi Tran – AWS Community Builder Key Highlights Transitioning to modern application architecture – Microservices 1. Infrastructure as Code (IaC) IaC eliminates ClickOps limitations such as slowness, inconsistency, and human errors (shown on slide 7 ). Key benefits: automation, scalability, reproducibility, and improved team collaboration. Helps maintain reliable infrastructure by avoiding manual configuration drift. 2. AWS CloudFormation AWS’s native IaC tool using YAML/JSON templates. Key concepts: Stack – a unit that groups and manages AWS resources. Template Anatomy: AWSTemplateFormatVersion Description Parameters – input values such as KeyPair Mappings – e.g., selecting AMI per region Conditions Resources – required section Outputs – values like public IP for cross-stack usage Supports Drift Detection to identify manual changes outside CloudFormation. 3. AWS CDK (Cloud Development Kit) An open-source IaC framework using programming languages (TypeScript, Python, Java, Go, C#, etc.).\nUses the constructs model:\nL1 – direct 1:1 CloudFormation mapping L2 – higher-level, developer-friendly with best practices L3 – complete architectural patterns Important CDK CLI commands:\ncdk init,\ncdk bootstrap,\ncdk synth,\ncdk deploy,\ncdk diff,\ncdk destroy,\ncdk drift,\ncdk doctor,\ncdk import.\nCDK synthesizes CloudFormation templates before deployment.\n4. Docker \u0026amp; Container Fundamentals Docker standardizes application packaging across environments. Containers vs VMs (slide 68): containers are lightweight, fast, and resource-efficient. Docker pipeline: Dockerfile → Image → Container ; images stored in registries like ECR . 5. Amazon ECR AWS’s fully managed private container registry. Key features: Image scanning Immutable tags Lifecycle policies Encryption \u0026amp; IAM control 6. Amazon ECS Fully managed container orchestration service from AWS. Two launch types: Fargate – serverless, no infrastructure management EC2 – more control and cost-optimized for long-running tasks ECS core components: Cluster Task Definition Task Service 7. Amazon EKS Fully managed Kubernetes service on AWS. Automates control plane operations, scaling, and upgrades. Can run workloads on EC2, Fargate, or Outposts. ECS vs EKS (slide 89): ECS : simpler, deeply AWS integrated, less operational overhead EKS : Kubernetes standard, more flexibility, higher complexity 8. AWS App Runner A quick and managed way to deploy web applications and APIs from GitHub or ECR. Provides automatic build, scaling, security, and HTTPS endpoint. Suitable for microservices, prototypes, and small-to-medium production workloads. Key Takeaways IaC Mindset Reduce manual console operations; fully embrace IaC for consistency and automation. IaC increases deployment reliability and minimizes configuration drift. Technical Architecture CloudFormation is ideal for precise resource definitions. CDK enables reusable patterns, faster development, and code abstraction. ECS is best for simplicity; EKS is best for teams requiring full Kubernetes capabilities. DevOps \u0026amp; Containers Standardize application packaging with Docker. Use ECR + ECS/EKS workflows for secure, scalable deployment. App Runner is great for fast deployments with minimal DevOps overhead. Applying to Work Adopt IaC across all projects using CloudFormation or CDK. Implement a container pipeline (build → push → deploy). Prevent drift by standardizing infrastructure repositories. Use ECS Fargate for microservices; adopt EKS if Kubernetes expertise is required. Test App Runner for lightweight services and rapid prototyping. Event Experience The workshop provided a clear transition path from manual operations to modern IaC practices. CDK construct levels (L1 → L2 → L3) helped visualize infrastructure abstraction and best practices. Live demos on CloudFormation and ECS made the deployment workflow easier to understand. Discussions highlighted how IaC and containerization reduce operational burden and improve scalability. Hands-on Technical Exposure (Summary) Practiced defining infrastructure using CloudFormation templates , including parameters, mappings, conditions, and outputs. Used AWS CDK CLI commands to generate, synthesize, and deploy stacks, seeing how high-level code becomes CloudFormation templates. Explored construct levels (L1–L3) through examples showing increasing abstraction and best practices. Gained practical understanding of ClickOps vs IaC and how drift detection helps maintain infrastructure consistency. Leveraging Modern Tools (Summary) Learned how AWS CDK enables infrastructure provisioning through programming languages. Explored how Amplify uses CloudFormation behind the scenes for backend deployments. Reviewed Docker workflows and worked with ECR, ECS, EKS , and App Runner for container deployments. Understood how managed services automate scaling, security, and deployment pipelines. Networking and Discussions (Summary) Discussed real-world IaC adoption challenges with AWS Community Builders and peers. Gained insights into choosing between ECS and EKS depending on operational needs and complexity. Shared experiences on migrating from manual operations to automated DevOps practices. Lessons Learned (Summary) IaC increases automation, consistency, and reproducibility , reducing human error. CloudFormation provides precise control, while CDK boosts developer productivity with higher-level constructs. Choosing the right container service (ECS, EKS, App Runner) impacts scalability and operational effort. Effective DevOps combines IaC, CI/CD, containers, and automation to build resilient cloud architectures. Event Photos "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/","title":"Internship Report","tags":[],"description":"","content":"Internship Report Student Information: Full Name: Nguyễn Thanh Hồng\nPhone Number: 0335390509\nEmail: HongNTSE183239@fpt.edu.vn\nUniversity: FPT University\nMajor: Information Technology\nClass: AWS082025\nInternship Company: Amazon Web Services Vietnam Co., Ltd.\nInternship Position: FCJ Cloud Intern\nInternship Duration: From 8/9/2025 to 9/12/2025\nReport Content Worklog Proposal Translated Blogs Events Participated Workshop Self-evaluation Sharing and Feedback "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/","title":"Worklog","tags":[],"description":"","content":"This worklog documents my 12-week journey through the AWS First Cloud Journey internship program. Each week focuses on specific AWS services, hands-on labs, and practical implementations.\nWeek 1: AWS Account Setup, VPC Fundamentals \u0026amp; VPN/Direct Connect\nWeek 2: VPC Networking, Hybrid DNS, Route 53, VPC Peering \u0026amp; Transit Gateway\nWeek 3: EC2 Basics, Storage Gateway, S3 Static Website \u0026amp; CloudFront\nWeek 4: Amazon S3, Snow Family, Storage Gateway \u0026amp; DR Strategies\nWeek 5: IAM, Cognito, AWS Organizations, SSO \u0026amp; KMS\nWeek 6: IAM Security, Encryption, S3 Security, VPC Networking \u0026amp; DR\nWeek 7: Hands-on Labs: VPC, EC2, Lambda, IAM, KMS \u0026amp; CloudTrail\nWeek 8: Database Fundamentals: Keys, Indexing, RDBMS vs NoSQL, OLTP vs OLAP\nWeek 9: Data Pipeline: VPC/EC2/RDS, DMS/SCT, S3/Glue/Athena/QuickSight, Redshift\nWeek 10: Backend Testing: Lambda, API Endpoints \u0026amp; DynamoDB\nWeek 11: Frontend Testing: Components, UI/UX \u0026amp; API Integration\nWeek 12: AI Module Testing, Bedrock Integration \u0026amp; End-to-End Testing\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.1-dns-stack/","title":"5.4.1 DNS Stack","tags":[],"description":"","content":" DNS Stack - Route 53 Hosted Zone Overview The DNS Stack is the foundation layer (Phase 1) of the EveryoneCook infrastructure. It manages the Route 53 Hosted Zone for the everyonecook.cloud domain, providing DNS infrastructure that all other stacks depend on.\nDeployment Order: This stack MUST be deployed first before any other stacks.\nKey Responsibilities Create and manage Route 53 Public Hosted Zone Export Hosted Zone ID and name for cross-stack references Provide nameservers for domain delegation from Hostinger What This Stack Does NOT Include SES Email Identity (managed by Auth Stack - Phase 3) DKIM/SPF/DMARC records (managed by Auth Stack - Phase 3) ACM Certificates (managed by Certificate Stack - Phase 1.5) Application DNS records (managed by respective stacks) Architecture ┌─────────────────────────────────────────────────────────┐ │ Hostinger Domain │ │ everyonecook.cloud │ │ │ │ ┌────────────────────────────────────────────────┐ │ │ │ Domain Registrar Settings │ │ │ │ • Update Nameservers to Route 53 NS records │ │ │ └────────────────┬───────────────────────────────┘ │ └───────────────────┼──────────────────────────────────────┘ │ DNS Delegation ▼ ┌─────────────────────────────────────────────────────────┐ │ AWS Route 53 Hosted Zone │ │ everyonecook.cloud │ │ │ │ Resources Created: │ │ • Public Hosted Zone │ │ • 4 Nameserver (NS) Records │ │ • SOA Record (automatic) │ │ │ │ Exports: │ │ • Hosted Zone ID → Used by Certificate Stack │ │ • Hosted Zone Name → Used by other stacks │ │ • Nameservers → Configure at Hostinger │ └─────────────────────────────────────────────────────────┘ Stack Configuration File Structure infrastructure/lib/stacks/ └── dns-stack.ts # DNS Stack implementation Code Implementation File: infrastructure/lib/stacks/dns-stack.ts\nimport * as cdk from \u0026#39;aws-cdk-lib\u0026#39;; import { Construct } from \u0026#39;constructs\u0026#39;; import { BaseStack, BaseStackProps } from \u0026#39;../base-stack\u0026#39;; export class DnsStack extends BaseStack { public readonly hostedZone: cdk.aws_route53.IHostedZone; constructor(scope: Construct, id: string, props: BaseStackProps) { super(scope, id, props); // Add stack-specific tags cdk.Tags.of(this).add(\u0026#39;StackType\u0026#39;, \u0026#39;DNS\u0026#39;); cdk.Tags.of(this).add(\u0026#39;Layer\u0026#39;, \u0026#39;Foundation\u0026#39;); cdk.Tags.of(this).add(\u0026#39;CostCenter\u0026#39;, `DNS-${this.config.environment}`); // Create Route 53 Hosted Zone this.hostedZone = this.createHostedZone(); // Export stack outputs this.exportOutputs(); } private createHostedZone(): cdk.aws_route53.IHostedZone { // Extract root domain from environment config const rootDomain = this.config.domains.frontend .replace(/^(dev\\.|staging\\.)/, \u0026#39;\u0026#39;); // everyonecook.cloud const hostedZone = new cdk.aws_route53.PublicHostedZone( this, \u0026#39;HostedZone\u0026#39;, { zoneName: rootDomain, comment: `Hosted Zone for Everyone Cook ${this.config.environment} environment`, } ); cdk.Tags.of(hostedZone).add(\u0026#39;Component\u0026#39;, \u0026#39;DNS\u0026#39;); cdk.Tags.of(hostedZone).add(\u0026#39;ManagedBy\u0026#39;, \u0026#39;CDK\u0026#39;); return hostedZone; } private exportOutputs(): void { // Export Hosted Zone ID new cdk.CfnOutput(this, \u0026#39;HostedZoneId\u0026#39;, { value: this.hostedZone.hostedZoneId, exportName: this.exportName(\u0026#39;HostedZoneId\u0026#39;), description: \u0026#39;Route 53 Hosted Zone ID\u0026#39;, }); // Export Hosted Zone Name new cdk.CfnOutput(this, \u0026#39;HostedZoneName\u0026#39;, { value: this.hostedZone.zoneName, exportName: this.exportName(\u0026#39;HostedZoneName\u0026#39;), description: \u0026#39;Domain name managed by Route 53\u0026#39;, }); // Export Nameservers (for Hostinger configuration) new cdk.CfnOutput(this, \u0026#39;NameServers\u0026#39;, { value: cdk.Fn.join(\u0026#39;, \u0026#39;, this.hostedZone.hostedZoneNameServers || []), description: \u0026#39;⚠️ Update these nameservers at Hostinger\u0026#39;, }); } } Key Configuration Details 1. Domain Extraction Logic The stack automatically extracts the root domain from the environment configuration:\n// Environment config: dev.everyonecook.cloud // Extracted domain: everyonecook.cloud const rootDomain = this.config.domains.frontend.replace(/^(dev\\.|staging\\.)/, \u0026#39;\u0026#39;); Environments:\nDev: dev.everyonecook.cloud → Hosted Zone: everyonecook.cloud Staging: staging.everyonecook.cloud → Hosted Zone: everyonecook.cloud Prod: everyonecook.cloud → Hosted Zone: everyonecook.cloud 2. Resource Naming Convention All resources follow a consistent naming pattern:\n// Resource name format: everyonecook-{env}-{resource} protected resourceName(name: string): string { return `everyonecook-${this.config.environment}-${name}`; } // Export name format: EveryoneCook-{Env}-{Export} protected exportName(name: string): string { return `EveryoneCook-${this.config.environment}-${name}`; } Example:\nStack name: EveryoneCook-dev-DNS Export: EveryoneCook-dev-HostedZoneId 3. Resource Tags Every resource is tagged for cost tracking and management:\n{ Stack: \u0026#39;EveryoneCook-dev-DNS\u0026#39;, Environment: \u0026#39;dev\u0026#39;, StackType: \u0026#39;DNS\u0026#39;, Layer: \u0026#39;Foundation\u0026#39;, CostCenter: \u0026#39;DNS-dev\u0026#39;, Component: \u0026#39;DNS\u0026#39;, ManagedBy: \u0026#39;CDK\u0026#39;, Project: \u0026#39;EveryoneCook\u0026#39; } Stack Outputs After deployment, the stack exports the following values:\nOutput Name Value Usage HostedZoneId Z0123456789ABCDEFGHIJ Used by Certificate Stack for DNS validation HostedZoneName everyonecook.cloud Used by other stacks to create DNS records NameServers ns-1.awsdns-01.com, ns-2.awsdns-02.org, ... Configure at Hostinger for DNS delegation Deployment Steps Step 1: Review Configuration Navigate to the infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Verify the environment configuration in config/environment.ts:\ndev: { environment: \u0026#39;dev\u0026#39;, account: \u0026#39;YOUR_AWS_ACCOUNT_ID\u0026#39;, region: \u0026#39;ap-southeast-1\u0026#39;, domains: { frontend: \u0026#39;dev.everyonecook.cloud\u0026#39;, api: \u0026#39;api-dev.everyonecook.cloud\u0026#39;, cdn: \u0026#39;cdn-dev.everyonecook.cloud\u0026#39;, }, // ... other configs } Step 2: Deploy DNS Stack Deploy the DNS stack to AWS:\n# Deploy DNS Stack only npx cdk deploy EveryoneCook-dev-DNS --context environment=dev Expected output:\n✨ Synthesis time: 5.23s EveryoneCook-dev-DNS: deploying... EveryoneCook-dev-DNS: creating CloudFormation changeset... ✅ EveryoneCook-dev-DNS ✨ Deployment time: 45.67s Outputs: EveryoneCook-dev-DNS.HostedZoneId = Z0123456789ABCDEFGHIJ EveryoneCook-dev-DNS.HostedZoneName = everyonecook.cloud EveryoneCook-dev-DNS.NameServers = ns-123.awsdns-45.com, ns-678.awsdns-90.net, ns-1234.awsdns-56.org, ns-5678.awsdns-01.co.uk Stack ARN: arn:aws:cloudformation:ap-southeast-1:123456789012:stack/EveryoneCook-dev-DNS/... Step 3: Verify in AWS Console Navigate to Route 53 in the AWS Console Go to Hosted zones Verify the hosted zone everyonecook.cloud is created Expected view:\nDomain name: everyonecook.cloud Type: Public hosted zone Records: 2 (NS and SOA records - automatically created) Location of nameserver records in Route 53 console\nStep 4: Copy Nameservers From the CloudFormation Outputs or Route 53 console, copy all 4 nameserver records:\nns-123.awsdns-45.com ns-678.awsdns-90.net ns-1234.awsdns-56.org ns-5678.awsdns-01.co.uk Route 53 Hosted Zone showing domain details, NS records (4 nameservers), and SOA record\nHostinger Configuration Critical Post-Deployment Step ⚠️ IMPORTANT: After deploying the DNS Stack, you MUST update nameservers at Hostinger to delegate DNS management to Route 53.\nUpdate Nameservers at Hostinger Login to Hostinger hPanel\nNavigate to https://hpanel.hostinger.com Login with your Hostinger credentials Access Domain Management\nGo to Domains section Select everyonecook.cloud domain Change Nameservers\nClick on DNS/Nameservers Select Change nameservers Choose Custom nameservers Enter Route 53 Nameservers\nNameserver 1: ns-123.awsdns-45.com Nameserver 2: ns-678.awsdns-90.net Nameserver 3: ns-1234.awsdns-56.org Nameserver 4: ns-5678.awsdns-01.co.uk Save Configuration\nClick Change nameservers button Wait for confirmation Hostinger hPanel showing custom nameservers configuration with Route 53 NS records\nPropagation Time Initial propagation: 15-30 minutes Full global propagation: Up to 48 hours (typically within 2-4 hours) Verify DNS Delegation After updating nameservers, verify the delegation:\n# Check nameservers for the domain nslookup -type=NS everyonecook.cloud # Or using dig (if available) dig NS everyonecook.cloud Expected output:\neveryonecook.cloud nameserver = ns-123.awsdns-45.com everyonecook.cloud nameserver = ns-678.awsdns-90.net everyonecook.cloud nameserver = ns-1234.awsdns-56.org everyonecook.cloud nameserver = ns-5678.awsdns-01.co.uk Cost Breakdown Monthly Costs Resource Cost Notes Route 53 Hosted Zone $0.50/month Fixed cost per hosted zone DNS Queries $0.40 per million queries First 1 billion queries/month Total (Estimated) ~$0.50-1.00/month Very low traffic in dev environment Cost Optimization Notes ✅ Single hosted zone for all environments (dev, staging, prod) ✅ Use subdomain prefixes to distinguish environments ✅ No additional cost for NS, SOA, or other DNS records ✅ Pay-per-query pricing is very cost-effective for low-medium traffic Cross-Stack Dependencies Exports Used By Other Stacks The DNS Stack exports values that are imported by:\nCertificate Stack (Phase 1.5)\nImports: HostedZoneId Purpose: Create DNS validation records for ACM certificates Core Stack (Phase 2)\nImports: HostedZoneId, HostedZoneName Purpose: Create CloudFront A/AAAA alias records Backend Stack (Phase 4)\nImports: HostedZoneId Purpose: Create API Gateway custom domain DNS records Dependency Flow DNS Stack (Route 53) │ ├─► Certificate Stack (ACM certificates) │ ├─► Core Stack (CloudFront DNS records) │ └─► Backend Stack (API Gateway DNS records) Validation Checklist Before proceeding to Certificate Stack deployment:\nDNS Stack successfully deployed to AWS Route 53 Hosted Zone visible in AWS Console 4 nameserver records obtained from stack outputs Nameservers updated at Hostinger hPanel DNS delegation verified with nslookup or dig Stack exports visible in CloudFormation console Tags applied correctly to all resources Next Steps After successfully deploying and configuring the DNS Stack:\n➡️ 5.4.2 Certificate Stack - Create ACM certificates with DNS validation\nThe Certificate Stack will:\nCreate ACM certificate for CloudFront (cdn.everyonecook.cloud) Create wildcard ACM certificate for API Gateway (*.everyonecook.cloud) Automatically create DNS validation records in Route 53 Must be deployed to us-east-1 region (CloudFront requirement) References Source Code: infrastructure/lib/stacks/dns-stack.ts Base Stack: infrastructure/lib/base-stack.ts Environment Config: infrastructure/config/environment.ts AWS Documentation: Route 53 Hosted Zones Hostinger Guide: How to Change Nameservers "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.02-setup-environment/","title":"Setup Environment","tags":[],"description":"","content":"Overview Trong bước này, bạn sẽ cài đặt tất cả các công cụ cần thiết để phát triển và deploy ứng dụng EveryoneCook.\nRequired Tools 1. Node.js 20.x\n# Download from https://nodejs.org/ # Or use nvm (recommended) nvm install 20 nvm use 20 # Verify installation node --version # Should be v20.x npm --version 2. AWS CLI v2\n# Windows: Download from https://aws.amazon.com/cli/ # macOS: brew install awscli # Linux: curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install # Verify installation aws --version 3. AWS CDK CLI\n# Install CDK globally npm install -g aws-cdk # Verify installation cdk --version 4. Git\n# Download from https://git-scm.com/ # Or use package manager # Verify installation git --version 5. Code Editor\nRecommended: Visual Studio Code with extensions:\nAWS Toolkit GitLab Workflow ESLint Prettier AWS Account Setup 1. Create AWS Account\nIf you don\u0026rsquo;t have an AWS account:\nGo to https://aws.amazon.com/ Click \u0026ldquo;Create an AWS Account\u0026rdquo; Follow the registration process Add payment method 2. Create IAM User\nFor security, don\u0026rsquo;t use root account\nGo to IAM Console → Users → Create user Create user and save credentials 3. Configure AWS CLI\n# Configure AWS credentials aws configure # Enter: # AWS Access Key ID: [Your Access Key] # AWS Secret Access Key: [Your Secret Key] # Default region name: us-east-1 # Default output format: json 4. Verify AWS Access\n# Test AWS credentials aws sts get-caller-identity # Should return your account ID and user ARN Domain Setup (Optional) If you want to use a custom domain:\n1. Register Domain\nBuy domain name on hpanel.hostinger Route 53 creates dns record to hostinger For this workshop, we use: everyonecook.cloud\n2. Note Domain Registrar\nYou\u0026rsquo;ll need access to domain registrar to update nameservers later.\nGitLab Setup Create GitLab Repo Screenshot: GitLab showing personal access token created\n3. Configure Git\n# Set your name and email git config --global user.name \u0026#34;Your Name\u0026#34; git config --global user.email \u0026#34;your.email@example.com\u0026#34; # Verify configuration git config --list Project Setup 1. Clone or Create Project\nOption A: Clone existing project\ngit clone https://gitlab.com/your-username/everyonecook.git cd everyonecook Option B: Create new project\nmkdir everyonecook cd everyonecook git init 2. Install Dependencies\n# Install all dependencies npm install # This installs: # - Infrastructure dependencies (CDK) # - Backend dependencies (Lambda modules) # - Shared dependencies 3. Copy Environment Variables\n# Copy example env file cp .env.example .env # Edit .env with your values # Key variables: # - AWS_REGION=us-east-1 # - AWS_ACCOUNT_ID=your-account-id # - DOMAIN_NAME=everyonecook.cloud # - GITLAB_TOKEN=your-gitlab-token Verification Check that everything is installed correctly:\n# Check Node.js node --version # v20.x # Check npm npm --version # 10.x # Check AWS CLI aws --version # aws-cli/2.x # Check CDK cdk --version # 2.x # Check Git git --version # 2.x # Check AWS credentials aws sts get-caller-identity # Check project dependencies npm list --depth=0 Troubleshooting Issue: Node.js version mismatch\n# Use nvm to switch versions nvm install 20 nvm use 20 Issue: AWS CLI not found\nRestart terminal after installation Check PATH environment variable Issue: CDK command not found\n# Reinstall CDK globally npm uninstall -g aws-cdk npm install -g aws-cdk Issue: AWS credentials invalid\n# Reconfigure AWS CLI aws configure # Enter correct credentials Cost Estimate Development Environment:\nAWS Free Tier covers most services Estimated cost: $20-55/month Main costs: DynamoDB, S3, CloudFront, Lambda Tips to minimize costs:\nUse pay-per-request for DynamoDB Enable S3 Intelligent-Tiering Disable OpenSearch in dev (enable only when needed) Delete resources when not in use Next Steps Once your environment is set up, proceed to CDK Bootstrap to prepare your AWS account for CDK deployments.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.2-week2/","title":"Week 2 Worklog","tags":[],"description":"","content":"Week 2 Objectives: Understand and practice core VPC networking components (subnets, route tables, IGW, NAT, SG, NACLs). Build hands-on experience with Hybrid DNS \u0026amp; Amazon Route 53 for cross-network name resolution. Learn how to establish VPC Peering connections and configure routing between VPCs. Explore AWS Transit Gateway to connect multiple VPCs and manage centralized routing. Complete end-to-end labs involving CloudFormation, EC2, DNS resolvers, and network connectivity testing. Summarize weekly learning to reinforce key AWS networking concepts. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 VPC (cont) 09/18/2025 09/18/2025 cont 3 Hydrid DNS \u0026amp; Route 53 09/19/2025 09/19/2025 cont 4 VPC Peering 09/20/2025 09/20/2025 cont 5 Transit Gateway 09/21/2025 09/21/2025 cont 6 Weekly knowledge summary 09/22/2025 09/22/2025 1. VPC (Lab) VPN Site-to-Site Subnet Route Table Internet Gateway (IGW) NAT Gateway Security Group Network ACLs VPC Resource Map 2. Hybrid DNS \u0026amp; Route 53 (Lab10) Set up Hybrid DNS Generate Key Pair Initialize CloudFormation Configure Security Group Connect to RDGW Set up DNS (Outbound, Resolver, Inbound) Test results Clean up resources 3. VPC Peering (Lab19) Initialize CloudFormation Create Security Group Create EC2 Instance Update NACLs Create Peering Connection Configure Route Tables Enable Cross-Peer DNS Clean up resources 4. Transit Gateway (Lab20) Set up Transit Gateway Preparation steps Create Transit Gateway Create Transit Gateway Attachments Create Transit Gateway Route Tables Add Routes to VPCs Clean up resources "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/2-proposal/","title":"Proposal","tags":[],"description":"","content":"AWS First Cloud AI Journey – Project Plan Hello World – FPT University – EveryoneCook\nDate: 30/11/2025\n📥 Download Full Proposal (DOCX)\nTABLE OF CONTENTS 1. BACKGROUND AND MOTIVATION\n1.1 Executive Summary\n1.2 Project Success Criteria\n1.3 Assumptions\n2. SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM\n2.1 Technical Architecture Diagram\n2.2 Technical Plan\n2.3 Project Plan\n2.4 Security Considerations\n3. ACTIVITIES AND DELIVERABLES\n3.1 Activities and Deliverables\n3.2 Out of Scope\n3.3 Path to Production\n4. EXPECTED AWS COST BREAKDOWN BY SERVICES\n5. TEAM\n6. RESOURCES \u0026amp; COST ESTIMATES\n7. ACCEPTANCE\n1. BACKGROUND AND MOTIVATION 1.1 Executive Summary Customer background\nThe customer is a startup focused on building a modern social network platform where users can share cooking recipes, upload food photos, exchange culinary experiences, and explore meals recommended by AI. The organization aims to deliver a highly interactive platform capable of serving a large and growing user base.\nBusiness and technical objectives \u0026ndash; drivers for moving to the AWS cloud\nEnable rapid development and deployment using AWS managed services Ensure high scalability as the user base and media storage grow Provide a reliable, low-latency environment for AI computation and content delivery Reduce upfront infrastructure cost and move toward a pay-as-you-go model Improve data security, backup, and compliance through AWS-native capabilities Use cases\nUsers upload recipes, photos, and cooking videos to the platform System recommends dishes using AI based on available ingredients provided by the user Users interact socially through liking, commenting, sharing, and following AI processes text and images to generate recipe suggestions Admins manage content, monitor platform activity, and track performance analytics To meet the customer\u0026rsquo;s objectives of building a scalable social cooking platform with AI-powered recipe recommendations, the partner will deliver a full end-to-end cloud implementation on AWS. The services provided include:\nCloud Architecture Design: Define a secure, highly scalable, serverless architecture using AWS best practices (Route 53, API Gateway, Lambda, DynamoDB, S3, CloudFront, Cognito) AI Integration: Implement AWS Bedrock (Claude 3.5 Sonnet) for intelligent recipe suggestions, image analysis, and natural language processing features Infrastructure Deployment: Build and deploy all backend, frontend, authentication, and data layers using Infrastructure as Code (IaC) with fully automated CI/CD pipelines Security \u0026amp; Compliance: Configure IAM roles, encryption (KMS), WAF, logging, monitoring, and compliance guardrails to ensure platform security Observability Setup: Enable CloudWatch dashboards, alarms, X-Ray tracing, and log centralization for real-time monitoring and performance insights DevOps \u0026amp; Automation: Implement automated build/deploy workflows via GitLab + Amplify, operational pipelines, and auto-scaling configurations Performance Optimization: Configure CDN caching, DynamoDB capacity scaling, search indexing, and asynchronous SQS-based background processing Knowledge Transfer \u0026amp; Documentation: Provide technical documentation, best practices, architectural guides, and handover training to the customer\u0026rsquo;s engineering team 1.2 Project Success Criteria System availability ≥ 99.9% uptime across all production services (API Gateway, Lambda, DynamoDB, CloudFront). Page load time \u0026lt; 2.5 seconds for the main user interface delivered through CloudFront and Amplify. API response time \u0026lt; 300 ms for 90% of all user-facing API requests under normal traffic conditions. AI processing latency \u0026lt; 5 seconds for recipe suggestions generated by AWS Bedrock. User authentication success rate ≥ 98% with Cognito handling registration, login, and email verification. Zero critical security vulnerabilities after security review and WAF rules deployment. Data durability of 99.999999999% (11 nines) ensured through S3 object storage and DynamoDB. Scalability to support 10,000+ concurrent users without degradation in performance due to serverless infrastructure. Operational cost control within target budget: monthly AWS usage not exceeding $200 for production. Image upload \u0026amp; processing success rate ≥ 99%, supported by S3, Lambda Workers, and SQS. Search performance under 1 second (if OpenSearch is enabled) for recipe/content search queries. Monitoring coverage of 100% critical services using CloudWatch dashboards, alarms, and X-Ray tracing. CI/CD deployment time \u0026lt; 5 minutes via GitHub → Amplify and IaC automation. Zero data loss events, ensured by DynamoDB PITR and S3 versioning. 1.3 Assumptions The customer will provide full access to their domain registrar (Hostinger) to configure DNS delegation to Route 53. The customer will provide valid AWS account access with Administrator privileges for deployment and configuration. All required AWS services (Amplify, API Gateway, Lambda, DynamoDB, CloudFront, Cognito, Bedrock, SES) are available and supported in the chosen region. SES will be successfully moved out of the sandbox and approved for production email sending. Third-party integrations (GitHub for CI/CD, external email clients, image upload sources) will remain available and stable. The development team will maintain source code quality and follow the architectural guidelines provided by the partner. The customer will provide timely feedback and approvals during design, testing, and deployment phases. Dependencies\nReliable internet connectivity is required for all users accessing the web application and APIs. The system depends on AWS Bedrock (Claude 3.5 Sonnet) for AI recipe generation and may experience performance fluctuations if the model becomes rate-limited. Image upload and processing workflows depend on S3, Lambda, and SQS processing reliability. If OpenSearch is enabled, search features rely on the availability of the OpenSearch domain. GitHub Actions and Amplify depend on GitHub service availability. Constraints\nThe project will be fully deployed in a single AWS region, which may impact latency for users outside the region. The solution is designed using serverless patterns; custom EC2-based workloads are outside the project scope. SES domain reputation may affect email deliverability during initial weeks. OpenSearch is deployed as a single-node cluster for cost efficiency, which means no high availability for search indexing. The system must stay within the customer\u0026rsquo;s cost target (\u0026lt; $200/month), limiting the use of large compute resources. Risks\nSES production approval may be delayed, impacting user onboarding emails and notifications. If traffic grows unexpectedly, DynamoDB provisioned capacity may throttle without timely scaling adjustments. AI model cost or latency changes by AWS may impact application performance or cost control. Misconfigured CloudFront caching could lead to higher latency or increased data transfer cost. Any incorrect IAM configuration could lead to security risks or service disruption. Customer team turnover or lack of DevOps skills may slow down future maintenance or deployments. 2. SOLUTION ARCHITECTURE / ARCHITECTURAL DIAGRAM 2.1 Technical Architecture Diagram The proposed solution architecture for the AI-powered cooking social network platform is designed using a fully serverless and scalable AWS cloud-native stack. The architecture ensures high availability,security, and seamless integration between the web frontend, backend APIs, authentication, data storage, and AI recommendation services. Below is a description of the key components and how data flows across the system: 1. Network \u0026amp; Edge Layer\nAmazon Route 53 (6\u0026ndash;7)\nProvides DNS routing for the custom domain used by the platform. Incoming HTTPS requests from users are resolved and forwarded to CloudFront. Amazon CloudFront (9)\nActs as a global CDN distributing frontend content with low latency while caching static files. AWS WAF (8)\nProtects the application from common web exploits such as SQL injection, XSS, and bot attacks. 2. Frontend Hosting \u0026amp; Deployment\nAWS Amplify Hosting (4)\nHosts and deploys the Next.js frontend application. Integrated with GitLab CI/CD (3) for automated deployments from the development workflow. 3. Application Layer\nAmazon Cognito (10)\nHandles user authentication and authorization, supporting email/password and social logins. Amazon API Gateway (11)\nServes as the main entry point for backend APIs, exposing REST endpoints used by the frontend. AWS Lambda (12, 15)\nContains the backend business logic, including: user management post and recipe operations ingredient analysis connecting to Bedrock for AI recommendations This serverless architecture ensures automatic scaling and pay-per-use cost efficiency. 4. AI Recommendation Layer\nAmazon Bedrock (16\u0026ndash;17)\nProvides generative AI capabilities to suggest recipes based on user-provided ingredients. Lambda invokes Bedrock models (e.g., Claude, Titan) to: analyze ingredient lists generate recipe suggestions classify food categories optimize cooking steps. 5. Data Storage Layer\nAmazon DynamoDB (13)\nStores structured application data such as:\nuser profiles posts/recipes likes \u0026amp; comments ingredient metadata. Amazon S3 (14)\nStores unstructured data:\nrecipe images user-uploaded food photos static content. An S3 bucket is integrated with CloudFront via OAI for secure access. 6. Observability \u0026amp; Security Layer\nAmazon CloudWatch (Logs \u0026amp; Metrics) Monitors Lambda performance, API Gateway access logs, and system metrics.\nAWS X-Ray Performs distributed tracing for API calls and debugging.\nIAM Defines permission boundaries between API, Lambda functions, Bedrock, DynamoDB, and S3.\nAmazon SES Sends verification emails, notifications, and password recovery messages.\nAmazon SNS Handles system-level alerts and asynchronous messaging.\n7. Deployment \u0026amp; Infrastructure Management\nAWS CDK (1\u0026ndash;2) Used by developers to define and provision the entire infrastructure via CloudFormation templates. Ensures consistent, reproducible, version-controlled deployments.\n2.2 Technical Plan Partner will develop Infrastructure-as-Code (IaC) automation using AWS CDK (Cloud Development Kit) with TypeScript/Python to provision the entire cloud environment. This approach ensures quick, consistent, and repeatable deployments across multiple AWS accounts and environments (dev, staging, production). All resources such as API Gateway, Lambda functions, DynamoDB tables, S3 buckets, Cognito user pools, Bedrock integration policies, and CloudFront distributions will be fully automated via IaC.\nApplication build and deployment processes for the frontend (Next.js) will be automated using AWS Amplify Hosting, integrated with GitLab pipelines. Backend components will be deployed through CDK pipelines to ensure controlled, versioned, and repeatable releases.\nSome additional configuration such as custom domain setup, Route 53 DNS changes, SSL/TLS certificate issuance, and IAM permission approvals may require customer review and approval. These changes will follow the customer's existing change management process, including scheduled maintenance windows and documented approvals from the security/compliance teams.\nAll critical paths, including authentication flows, AI recipe suggestion APIs, data persistence logic, and image upload workflows, will undergo extensive test coverage. Automated tests (unit, integration, and API-level) will be executed in CI/CD pipelines, and manual validation will be performed in the staging environment before production deployment.\n2.3 Project Plan [Partner] will adopt the Agile Scrum framework across eight 2-week sprints. Stakeholders from the team are required to participate in Sprint Reviews and Sprint Retrospectives to ensure alignment and continuous improvement.\nThe proposed team responsibilities are as follows:\nProduct Owner: Define user stories, prioritize backlog, and ensure the product meets user needs. Scrum Master**:** Facilitate Scrum ceremonies, remove blockers, and maintain team productivity. Development Team: Implement features, conduct unit testing, and collaborate on integration. AI/ML Specialist: Develop and fine-tune the AI recommendation engine that suggests recipes based on user-provided ingredients. UI/UX Designer: Design intuitive interfaces and ensure a smooth user experience on both web and mobile platforms. QA/Testers**:** Validate feature functionality, conduct regression testing, and ensure system reliability. Communication cadences will be established as follows:\nDaily Stand-ups**:** 15-minute meetings for progress updates and immediate blockers. Sprint Planning**:** At the start of each sprint to prioritize tasks. Sprint Review: At the end of each sprint to showcase completed features to stakeholders. Sprint Retrospective**:** Following each sprint review to identify improvements for the next sprint. Knowledge transfer sessions will be conducted by the senior developers and AI specialists to ensure team members understand system architecture, AI integration, and deployment procedures.\n2.4 Security Considerations Partner will implement security best practices across the following five categories to ensure the confidentiality, integrity, and availability of the platform:\nAccess Enable Multi-Factor Authentication (MFA) for all user and administrative accounts. Implement role-based access control (RBAC) to limit permissions based on user roles (e.g., admin, moderator, contributor). Enforce strong password policies and periodic password rotation. Infrastructure Deploy the application on secure, managed cloud services (e.g., AWS) following AWS security best practices. Use Virtual Private Cloud (VPC), network segmentation, and security groups to isolate resources. Regularly patch operating systems and containerized services to mitigate vulnerabilities. Data Encrypt all data at rest using AWS KMS-managed keys and data in transit using TLS/HTTPS. Implement data classification to protect sensitive user information (e.g., email, profile data, dietary preferences). Apply secure data storage and backup procedures to ensure availability and integrity. Detection Enable AWS CloudTrail and AWS Config to monitor API activity and resource configurations. Deploy logging and alerting mechanisms to detect unusual or suspicious activities in real time. Conduct periodic vulnerability scanning and penetration testing on the platform. Incident Management Establish a formal incident response plan including detection, containment, remediation, and communication. Maintain audit trails and logs to support forensic investigation if a security event occurs. Ensure [Customer] shares regulatory control validations to help [Partner] meet all compliance requirements (e.g., GDPR, local privacy regulations). By adhering to these measures, Partner ensures that the social cooking platform remains secure, compliant, and resilient against potential threats.\n3. ACTIVITIES AND DELIVERABLES 3.1 Activities and Deliverables Project Phase Timeline Activities Deliverables/Milestones Total man-day Infrastructure Setup Week 1-2 - Learn all aws service\n- Practice Lab - Worklog 2 week Project Foundation \u0026 Infrastructure Setup Week 3 - Initialize monorepo structure\n- setup development environment - Initialize Git repository and CI/CD\n- Initialize CDK project structure\n-Create environment configuration system\n-Setup CDK deployment scripts\n- Setup Git repository with CI/CD pipelines and branch protection\n- Configure local testing scripts and Git hooks for code quality\n- Set up AWS CDK project structure with proper organization for infrastructure as code\n- Implement centralized configuration management for dev, staging, and prod environments\n1 week -DNS Infrastructure (Route 53 Hosted Zone) - DNS Stack\n- Side Quest: CloudFront yêu cầu ACM certificate ở us-east-1, nhưng stack chính deploy ở ap-southeast-1\nWeek 4 ,5 - Create a Public Hosted Zone\n- Configure name server delegation\n- Architecture Design\n- Create DNS Stack in CDK project\n- Connect DNS , User Route 53 Alias targeting for AWS - managed - Request ACM certificates, Configure DNS validation in Route 53\n- Configure MX records for email , add SPF,DKIM,DMARC for email authentication\n- Create DNS structure , Validate DNS\n-npm run cdk deploy EveryoneCook-dev-Certificate - Domain \u0026 Hosted Zone Setup\n- Deploy DNS Stack\n- Route 53 Hosted Zone Status\n- Create Public Hosted Zone \u0026 NS Delegation Plan\n- ACM Certificates Automation\n- Test DNS\n- Link DNS to AWS Resources\n- Monitoring\n- Deploy Certificate Stack 2 weeks Structure Core Stack Week 6,7 - Initialize Core Stack for DynamoDB, S3, CloudFront, and OpenSearch infrastructure\n- Create DynamoDB table with Provisioned Mode and Auto-Scaling for cost optimization\n- Implement Global Secondary Indexes for diverse access patterns\n- Configure KMS encryption and security settings for DynamoDB\n- Create all 4 S3 buckets (content, logs, incoming emails, CDN logs) with Intelligent-Tiering for cost optimization\n- Configure CloudFront CDN with compression and caching optimization\n- Setup signed URLs for private content (avatars, backgrounds)\n- Create OpenSearch domain for advanced search with cost optimization\n- Create CoreStack class\n- Implement DynamoDB Single Table with cost optimization\n- Create 5 GSI indexes\n- Setup encryption and security for DynamoDB - S3 Storage, CloudFront CDN,OpenSeach Domain\n- Deploy Core Stack\n2 week Authentication Stack Week 8 - Initialize Authentication Stack for Cognito User Pool\n- Create Cognito User Pool with production-grade security settings\n- Setup SES for production email sending with Route 53 DNS automation\n- Implement Lambda triggers for Cognito lifecycle events\n- Cognito User Pool Setup\n- Implement Cognito User Pool with production settings\n- Configure SES email integration (Production mode)\n- Setup Cognito Lambda triggers\n1 week Backend Stack (API Gateway + Lambda ) Week 9,10 - Create API Gateway REST API with production settings and Cognito authorizer\n- Configure Cognito User Pool authorizer for API Gateway\n- Enable API Gateway caching for production to improve performance and reduce Lambda invocations\n- Enable request validation at API Gateway level to reject invalid requests early\n- Enable compression for API responses to reduce data transfer costs\n- Configure API Gateway custom domain for Everyone Cook project\n- Setup API Router Lambda directory structure\n- Implement routing logic for API Gateway requests\n- Deploy API Router Lambda to AWS and implement JWT validation for Cognito tokens\n- Setup Auth \u0026 User module directory structure\n- Create BackendStack class\n- Create API Gateway REST API\n- Setup Cognito Authorizer\n- Configure API Gateway caching\n- Configure API Gateway request validation\n- Enable API Gateway compression\n- Configure API Gateway custom domain\n- Create API Router Lambda structure\n- Implement API Router handler\n- Deploy API Router Lambda + Implement JWT Validation\n- Create Auth \u0026 User module structure\n- Implement authentication handlers\n- Implement user profile handlers,…\n- Social Module Lambda\n2 weeks 3.2 Out of Scope Real-time Messaging / Chat System\nPrivate or group chat Real-time messaging infrastructure (WebSocket, SignalR, Firebase Realtime DB, etc.) Message history storage \u0026amp; encryption Friends / Social Graph Management\nFriend requests, following/followers User-to-user connection graph Activity feed, notifications tied to friend actions Real-time Voice \u0026amp; Video Calling\n1-to-1 or group voice call Video call, screen sharing WebRTC signaling servers \u0026amp; TURN/STUN infrastructure Advanced Social Interaction\nIn-app messaging reactions Typing indicators, online/offline status Read receipts, presence tracking 3.3 Path to Production 1. Project Foundation \u0026amp; Infrastructure\n- Initialize project structure\n- Set up core infrastructure baseline\n- Configure Route 53 Hosted Zone (DNS Stack)\n2. Cross-Region Certificate (Side Quest)\n- Handle CloudFront requirement for ACM certificate in us-east-1\n- Sync certificate usage with main stack in ap-southeast-1\n3. Core Application Stacks\n- Core Stack: Shared resources / environment setup\n- Authentication Stack: User auth, Cognito, permissions\n- Backend Stack: API Gateway + Lambda functions\n4. Frontend Deployment\n- Deploy frontend (S3 + CloudFront)\n- Bug fixes \u0026amp; QA testing\n4. EXPECTED AWS COST BREAKDOWN BY SERVICES Target workload: 100-500 Monthly Active Users (MAU)\nAverage Lambda duration: 200ms per invocation\nDynamoDB peak activity: ~8 hours per month\nS3 to CloudFront data transfer is FREE (same region)\nAll services leverage AWS Free Tier where applicable (Lambda 1M requests, SQS 1M requests, Cognito 50K MAU, Amplify 1000 build minutes)\nAPI Gateway caching enabled at 0.5GB ($14.60/month) - can be disabled to reduce costs\nCloudFront WAF removed to optimize costs (~$9/month savings), Shield Standard provides DDoS protection\nBedrock uses on-demand pricing with Claude 3 Haiku (lowest cost Anthropic model)\nhttps://calculator.aws/#/estimate?id=7a8833402a63e273357ddc71071bfc2cdce4be2c\n5. TEAM Partner Executive Sponsor\nName Title Description Email / Contact Info Nguyen Gia Hung Director of FCJ Vietnam Training Program As the Executive Sponsor, you are responsible for the overall oversight of the FCJ internship program. Ensure the project delivers learning value and adheres to AWS technical and career goals hunggia@amazon.com Project Stakeholders\nName Title Stakeholder for Email / Contact Info Van Hoang Kha Support Teams is the Executive Assistant responsible for overall oversight of the FCJ internship program Khab9thd@gmail.com Partner Project Team\nName Title Role Email / Contact Info Pham Minh Hoang Viet Leader Project Manager vietpmhse181851@gmail.com Nguyen Van Truong Member DevOps truongnvse182034@fpt.edu.vn Huynh Duc Anh Member Cloud Engineer anhhdse183114@fpt.edu.vn Nguyen Thanh Hong Member Tester hongntse183239@fpt.edu.vn Nguyen Quy Duc Member Frontend ducnqse182087@fpt.edu.vn Project Escalation Contacts\nName Title Role Email / Contact Info Pham Minh Hoang Viet Leader Project Manager vietpmhse181851@gmail.com 6. RESOURCES \u0026amp; COST ESTIMATES Resource Responsibility Rate (USD) / Hour Solution Architects Architecture design, AWS service selection, security review, cost optimization $150 Engineers Frontend (Next.js), Backend (Lambda/Node.js), Infrastructure (CDK), Testing $100 DevOps CI/CD setup, monitoring, deployment automation $80 Project Phase Solution Architects Engineers Other\n(DevOps)\nTotal Hours Discovery \u0026 Requirements 16 24 8 48 Architecture Design 40 16 8 64 Development 16 200 40 256 Testing \u0026 QA 8 40 16 64 Deployment \u0026 Go-Live 8 24 24 56 Documentation \u0026 Training 8 16 8 32 Total Hours 96 320 104 520 Total Cost $14,400 | $32,000 $8,320 | $54,720 Monthly AWS Infrastructure Cost\nBased on AWS Pricing Calculator estimate for 100-500 MAU:\nService Monthly Cost (USD) Description Amazon DynamoDB $13.06 Single-table design, 5 GSIs, provisioned capacity Amazon S3 $0.84 2 buckets, Intelligent-Tiering Amazon CloudFront $1.44 CDN, Price Class 200 Amazon Cognito $5.00 User authentication AWS Lambda $0.00 13 functions (Free Tier) Amazon API Gateway $20.65 REST API with 0.5GB cache Amazon SQS $0.00 8 queues (Free Tier) Amazon SES $0.02 Transactional emails AWS KMS $2.00 2 customer managed keys AWS WAF $10.00 Web ACL, 5 rules Amazon CloudWatch $21.25 Metrics, dashboards, alarms, logs Amazon Route 53 $0.93 DNS hosted zone AWS Amplify $4.58 Frontend hosting (Next.js) Amazon Bedrock $64.80 Claude 3 Haiku AI Total ~$144.54 Per month Cost Summary\nCost Type Amount (USD) Notes One-time Development Cost $54,720 Resource hours × rates Monthly AWS Infrastructure ~$145 Based on 100-500 MAU Annual AWS Infrastructure ~$1,740 Monthly × 12 Year 1 Total Cost ~$56,460 Development + 12 months AWS Cost Contribution Distribution\nParty Contribution (USD) % Contribution of Total Customer $54,720 100% Partner $0 $0 AWS $0 $0 7. Acceptance Since this project is currently at the presentation stage and has not yet been formally evaluated by a customer, the following acceptance process is proposed for future delivery phases:\n7.1 Acceptance Criteria (Proposed) A deliverable will be considered acceptable when it meets the following criteria:\nFunctional features work as specified (authentication, recipe management, social features, AI functions). All APIs respond correctly and integrate with AWS services (Lambda, API Gateway, DynamoDB, S3). Security requirements are met (JWT verification, HTTPS, access control, data encryption). UI works as expected on supported devices. No critical errors appear during test execution. 7.2 Acceptance Process Review period: 8 business days for evaluation and testing. If accepted → Deliverable is signed off. If issues are found → A rejection notice will be issued with feedback. Fixes will be applied and a revised version will be resubmitted for review. If no response is received by the end of the review period → Deliverable is deemed accepted. After completing each milestone, the team submits the deliverables and documentation. "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.2-certificate-stack/","title":"5.4.2 Certificate Stack","tags":[],"description":"","content":" Certificate Stack - ACM Certificates for SSL/TLS Overview The Certificate Stack is the Phase 1.5 infrastructure layer of the EveryoneCook project. It manages AWS Certificate Manager (ACM) certificates for CloudFront CDN and API Gateway, providing SSL/TLS encryption for all HTTPS traffic.\nDeployment Order: This stack MUST be deployed after DNS Stack and before Core Stack and Backend Stack.\nCritical Region Requirement: This stack MUST be deployed in us-east-1 region because CloudFront is a global service that can only access ACM certificates from us-east-1.\nKey Responsibilities Create ACM certificate for CloudFront CDN (cdn.everyonecook.cloud or cdn-dev.everyonecook.cloud) Create wildcard ACM certificate for API Gateway (*.everyonecook.cloud) Automatic DNS validation via Route 53 Export certificate ARNs for Core Stack and Backend Stack What This Stack Does NOT Include DNS records (managed by DNS Stack - Phase 1) CloudFront distribution (managed by Core Stack - Phase 2) API Gateway custom domain (managed by Backend Stack - Phase 4) CloudFront WAF Web ACL (removed for cost optimization) Architecture ┌─────────────────────────────────────────────────────────────────┐ │ Route 53 Hosted Zone │ │ everyonecook.cloud │ │ (from DNS Stack) │ └───────────────────┬─────────────────────────────────────────────┘ │ DNS Validation ▼ ┌─────────────────────────────────────────────────────────────────┐ │ AWS Certificate Manager (us-east-1) │ │ │ │ Certificate 1: CloudFront Certificate │ │ ├─ Domain: cdn.everyonecook.cloud (or cdn-dev) │ │ ├─ Validation: DNS (Route 53) │ │ ├─ Status: Issued (5-10 minutes) │ │ └─ Export: CloudFrontCertificateArn │ │ │ │ Certificate 2: API Gateway Wildcard Certificate │ │ ├─ Domain: *.everyonecook.cloud │ │ ├─ SAN: everyonecook.cloud │ │ ├─ Covers: api.everyonecook.cloud, api-dev, api-staging │ │ ├─ Validation: DNS (Route 53) │ │ ├─ Status: Issued (5-10 minutes) │ │ └─ Export: ApiGatewayCertificateArn │ │ │ │ Cost Optimization: │ │ CloudFront WAF removed (-$9/month) │ │ Shield Standard (free, auto-enabled) │ └─────────────────────────────────────────────────────────────────┘ │ │ Certificate ARN Exports ▼ ┌───────────────────────┬ ▼ ▼ Core Stack Backend Stack (CloudFront) (API Gateway) Stack Configuration File Structure infrastructure/lib/stacks/ └── certificate-stack.ts # Certificate Stack implementation Code Implementation File: infrastructure/lib/stacks/certificate-stack.ts\nimport * as cdk from \u0026#39;aws-cdk-lib\u0026#39;; import * as acm from \u0026#39;aws-cdk-lib/aws-certificatemanager\u0026#39;; import * as route53 from \u0026#39;aws-cdk-lib/aws-route53\u0026#39;; import { Construct } from \u0026#39;constructs\u0026#39;; import { BaseStack, BaseStackProps } from \u0026#39;../base-stack\u0026#39;; /** * Certificate Stack for CloudFront and API Gateway * * This stack creates ACM certificates for CloudFront and API Gateway. * * IMPORTANT REGION REQUIREMENTS: * - CloudFront certificate: MUST be in us-east-1 (CloudFront requirement) * - API Gateway certificate: Should be in same region as API Gateway (ap-southeast-1) * * This stack is deployed in us-east-1 to handle CloudFront\u0026#39;s cross-region requirements. * For API Gateway, we use a wildcard certificate that covers api.everyonecook.cloud. * * Responsibilities: * - Create ACM certificate for CloudFront in us-east-1 * - Create ACM wildcard certificate for API Gateway in us-east-1 (works globally) * - Validate certificates via Route 53 DNS * - Export certificate ARNs for Core Stack and Backend Stack to use * * COST OPTIMIZATION NOTE: * - CloudFront WAF removed to save $9/month ($108/year) * - CloudFront still protected by Shield Standard (free, auto-enabled) * - API Gateway has full WAF protection (BackendStack) */ export class CertificateStack extends BaseStack { public readonly cloudFrontCertificate: acm.ICertificate; public readonly apiGatewayCertificate: acm.ICertificate; constructor(scope: Construct, id: string, props: BaseStackProps) { super(scope, id, props); // Add stack-specific tags cdk.Tags.of(this).add(\u0026#39;StackType\u0026#39;, \u0026#39;Certificate\u0026#39;); cdk.Tags.of(this).add(\u0026#39;Layer\u0026#39;, \u0026#39;Infrastructure\u0026#39;); cdk.Tags.of(this).add(\u0026#39;CostCenter\u0026#39;, `Certificate-${this.config.environment}`); // Import Route 53 Hosted Zone from DNS Stack // Note: Cannot use Fn.importValue or SSM Parameter for cross-region references // Hosted Zone ID is stable and doesn\u0026#39;t change, so we hardcode it // This value comes from DNS Stack output: Z018823421GWCSYG5UMHV const hostedZoneId = \u0026#39;Z018823421GWCSYG5UMHV\u0026#39;; const hostedZone = route53.HostedZone.fromHostedZoneAttributes(this, \u0026#39;HostedZone\u0026#39;, { hostedZoneId: hostedZoneId, zoneName: \u0026#39;everyonecook.cloud\u0026#39;, }); // Create ACM certificate for CloudFront // This certificate MUST be in us-east-1 for CloudFront to use it this.cloudFrontCertificate = this.createCloudFrontCertificate(hostedZone); // Create ACM wildcard certificate for API Gateway // Wildcard *.everyonecook.cloud covers api.everyonecook.cloud // This certificate in us-east-1 can be used by API Gateway in any region this.apiGatewayCertificate = this.createApiGatewayCertificate(hostedZone); // COST OPTIMIZATION: CloudFront WAF removed // CloudFront is protected by Shield Standard (free, auto-enabled) // API Gateway has full WAF protection in BackendStack // Savings: $9/month ($108/year) // Export certificate ARNs this.exportOutputs(); } /** * Create ACM certificate for CloudFront CDN * * CRITICAL: This stack MUST be deployed in us-east-1 region. * CloudFront is a global service but its control plane is in us-east-1, * so it can only access certificates from us-east-1. * * DNS validation is automatic via Route 53. * Validation typically takes 5-10 minutes. * * @param hostedZone - Route 53 Hosted Zone for DNS validation * @returns ACM Certificate for CloudFront */ private createCloudFrontCertificate(hostedZone: route53.IHostedZone): acm.Certificate { const certificate = new acm.Certificate(this, \u0026#39;CloudFrontCertificate\u0026#39;, { domainName: this.config.domains.cdn, validation: acm.CertificateValidation.fromDns(hostedZone), certificateName: `EveryoneCook-CloudFront-${this.config.environment}`, }); // Add tags cdk.Tags.of(certificate).add(\u0026#39;Component\u0026#39;, \u0026#39;CloudFront\u0026#39;); cdk.Tags.of(certificate).add(\u0026#39;Purpose\u0026#39;, \u0026#39;CDN-SSL\u0026#39;); return certificate; } /** * Create ACM wildcard certificate for API Gateway * * Creates a wildcard certificate (*.everyonecook.cloud) that covers: * - api.everyonecook.cloud (API Gateway) * - api-dev.everyonecook.cloud (API Gateway dev) * - api-staging.everyonecook.cloud (API Gateway staging) * * This certificate is created in us-east-1 but can be used by API Gateway * in any region via cross-region certificate reference. * * DNS validation is automatic via Route 53. * Validation typically takes 5-10 minutes. * * @param hostedZone - Route 53 Hosted Zone for DNS validation * @returns ACM Certificate for API Gateway */ private createApiGatewayCertificate(hostedZone: route53.IHostedZone): acm.Certificate { const certificate = new acm.Certificate(this, \u0026#39;ApiGatewayCertificate\u0026#39;, { domainName: \u0026#39;*.everyonecook.cloud\u0026#39;, // Wildcard covers api.everyonecook.cloud subjectAlternativeNames: [\u0026#39;everyonecook.cloud\u0026#39;], // Also covers root domain validation: acm.CertificateValidation.fromDns(hostedZone), certificateName: `EveryoneCook-API-${this.config.environment}`, }); // Add tags cdk.Tags.of(certificate).add(\u0026#39;Component\u0026#39;, \u0026#39;APIGateway\u0026#39;); cdk.Tags.of(certificate).add(\u0026#39;Purpose\u0026#39;, \u0026#39;API-SSL\u0026#39;); return certificate; } /** * Export stack outputs for cross-stack references * * Exports: * - CloudFrontCertificateArn: ACM Certificate ARN for CloudFront (us-east-1) * - ApiGatewayCertificateArn: ACM Certificate ARN for API Gateway (us-east-1) * * REMOVED: CloudFrontWebAclArn (cost optimization) */ private exportOutputs(): void { // Export CloudFront certificate ARN for Core Stack new cdk.CfnOutput(this, \u0026#39;CloudFrontCertificateArn\u0026#39;, { value: this.cloudFrontCertificate.certificateArn, exportName: this.exportName(\u0026#39;CloudFrontCertificateArn\u0026#39;), description: \u0026#39;ACM Certificate ARN for CloudFront (us-east-1)\u0026#39;, }); // Export CloudFront certificate domain for verification new cdk.CfnOutput(this, \u0026#39;CloudFrontCertificateDomain\u0026#39;, { value: this.config.domains.cdn, description: \u0026#39;Domain name for CloudFront certificate\u0026#39;, }); // Export API Gateway certificate ARN for Backend Stack new cdk.CfnOutput(this, \u0026#39;ApiGatewayCertificateArn\u0026#39;, { value: this.apiGatewayCertificate.certificateArn, exportName: this.exportName(\u0026#39;ApiGatewayCertificateArn\u0026#39;), description: \u0026#39;ACM Wildcard Certificate ARN for API Gateway (us-east-1)\u0026#39;, }); // Export API Gateway certificate domain for verification new cdk.CfnOutput(this, \u0026#39;ApiGatewayCertificateDomain\u0026#39;, { value: \u0026#39;*.everyonecook.cloud\u0026#39;, description: \u0026#39;Domain name for API Gateway certificate (wildcard)\u0026#39;, }); } } Key Configuration Details 1. Region Requirements Critical: This stack MUST be deployed to us-east-1:\n// In infrastructure/bin/app.ts const certificateStack = new CertificateStack(app, `${stackPrefix}-Certificate`, { env: { account: config.account, region: \u0026#39;us-east-1\u0026#39;, // MUST be us-east-1 for CloudFront }, config, description: `ACM Certificate for CloudFront (${config.environment}) - us-east-1`, }); Why us-east-1?\nCloudFront is a global service with control plane in us-east-1 CloudFront can only access ACM certificates from us-east-1 API Gateway wildcard certificate in us-east-1 works globally 2. Certificate Domains The stack creates two certificates with environment-specific domains:\nCloudFront Certificate:\n// Dev environment domainName: \u0026#39;cdn-dev.everyonecook.cloud\u0026#39; // Staging environment domainName: \u0026#39;cdn-staging.everyonecook.cloud\u0026#39; // Production environment domainName: \u0026#39;cdn.everyonecook.cloud\u0026#39; API Gateway Wildcard Certificate:\ndomainName: \u0026#39;*.everyonecook.cloud\u0026#39; // Covers all subdomains subjectAlternativeNames: [\u0026#39;everyonecook.cloud\u0026#39;] // Also covers root domain // Covers: // - api.everyonecook.cloud // - api-dev.everyonecook.cloud // - api-staging.everyonecook.cloud // - Any future *.everyonecook.cloud subdomains 3. Automatic DNS Validation ACM automatically creates DNS validation records in Route 53:\nvalidation: acm.CertificateValidation.fromDns(hostedZone) What Happens:\nACM creates CNAME record in Route 53 for validation Route 53 immediately responds with the validation record ACM verifies the record and issues the certificate Validation completes in 5-10 minutes (typically faster) 4. Cross-Region Certificate Reference The certificate created in us-east-1 is used by other stacks in ap-southeast-1:\n// In Core Stack (ap-southeast-1) - imports CloudFront certificate from us-east-1 const certificate = acm.Certificate.fromCertificateArn( this, \u0026#39;ImportedCloudFrontCertificate\u0026#39;, \u0026#39;arn:aws:acm:us-east-1:616580903213:certificate/8d53776e-0480-47d2-a6ff-4fe9b2eb6534\u0026#39; ); 5. Cost Optimization - WAF Removed Decision: CloudFront WAF Web ACL removed to save costs:\n// REMOVED: CloudFront WAF Web ACL // Previous monthly cost: $9/month = $108/year // Protection Status: // Shield Standard: DDoS protection (free, auto-enabled) // CloudFront OAC: Blocks direct S3 access // Signed URLs: Private content protection // ❌ WAF: Removed (cost optimization) Rationale:\nCloudFront serves static content only (low attack surface) Shield Standard provides Layer 3/4 DDoS protection (free) API Gateway has full WAF protection for Layer 7 attacks Savings: $9/month = $108/year Stack Outputs After deployment, the stack exports the following values:\nOutput Name Value Usage CloudFrontCertificateArn arn:aws:acm:us-east-1:616580903213:certificate/8d53776e-... Used by Core Stack for CloudFront distribution CloudFrontCertificateDomain cdn.everyonecook.cloud (or cdn-dev) Verification only ApiGatewayCertificateArn arn:aws:acm:us-east-1:616580903213:certificate/a1b2c3d4-... Used by Backend Stack for API Gateway domain ApiGatewayCertificateDomain *.everyonecook.cloud Verification only (wildcard) Deployment Steps Step 1: Verify Prerequisites Before deploying Certificate Stack, ensure:\nDNS Stack successfully deployed Route 53 Hosted Zone exists with correct nameservers DNS delegation from Hostinger completed and propagated Verify DNS is working:\nnslookup -type=NS everyonecook.cloud Step 2: Deploy Certificate Stack Navigate to infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Deploy Certificate Stack to us-east-1:\n# Deploy Certificate Stack npx cdk deploy EveryoneCook-dev-Certificate --context environment=dev Important: Notice the region is us-east-1, not ap-southeast-1.\nExpected output:\n✨ Synthesis time: 6.12s EveryoneCook-dev-Certificate: deploying... [████████████████████████████████████████] (3/3) EveryoneCook-dev-Certificate: creating CloudFormation changeset... EveryoneCook-dev-Certificate ✨ Deployment time: 125.34s Outputs: EveryoneCook-dev-Certificate.CloudFrontCertificateArn = arn:aws:acm:us-east-1:616580903213:certificate/8d53776e-0480-47d2-a6ff-4fe9b2eb6534 EveryoneCook-dev-Certificate.CloudFrontCertificateDomain = cdn-dev.everyonecook.cloud EveryoneCook-dev-Certificate.ApiGatewayCertificateArn = arn:aws:acm:us-east-1:616580903213:certificate/a1b2c3d4-5678-90ef-ghij-klmnopqrstuv EveryoneCook-dev-Certificate.ApiGatewayCertificateDomain = *.everyonecook.cloud Stack ARN: arn:aws:cloudformation:us-east-1:616580903213:stack/EveryoneCook-dev-Certificate/... Step 3: Wait for Certificate Validation ACM certificates require DNS validation. This process takes 5-10 minutes:\nACM creates CNAME validation records in Route 53 Route 53 responds with validation data ACM verifies and issues certificates Status changes from \u0026ldquo;Pending validation\u0026rdquo; to \u0026ldquo;Issued\u0026rdquo; You can monitor the validation progress in AWS Console.\nStep 4: Verify in AWS Console Navigate to ACM (us-east-1 region) Open AWS Console IMPORTANT: Switch region to N. Virginia (us-east-1) Navigate to Certificate Manager Switch AWS Console to us-east-1 region before viewing certificates\nVerify CloudFront Certificate Find certificate with domain cdn-dev.everyonecook.cloud Check status is Issued Verify DNS validation records are present ACM Certificate for CloudFront showing \u0026ldquo;Issued\u0026rdquo; status, domain name, validation method (DNS), and CNAME validation record\nVerify API Gateway Wildcard Certificate Find certificate with domain *.everyonecook.cloud Check status is Issued Verify it covers wildcard and SAN (everyonecook.cloud) ACM Wildcard Certificate for API Gateway showing domain *.everyonecook.cloud, SAN everyonecook.cloud, and validation records\nVerify DNS Validation Records in Route 53 Navigate to Route 53 \u0026gt; Hosted zones Select everyonecook.cloud hosted zone Verify CNAME validation records are created Route 53 showing CNAME validation records automatically created by ACM for certificate validation\nExpected records:\n_abc123def456.cdn-dev.everyonecook.cloud CNAME _xyz789.acm-validations.aws. _ghi789jkl012.everyonecook.cloud CNAME _mno345.acm-validations.aws. Cost Breakdown Monthly Costs Resource Cost Notes ACM Certificates $0/month Free for certificates used with AWS services DNS Validation Records $0/month Included in Route 53 hosted zone cost Certificate Renewal $0/month Automatic renewal (free) Total $0/month 100% free (no ongoing costs) Cost Optimization ACM certificates are free when used with CloudFront, API Gateway, ALB, etc. Automatic renewal (no manual intervention required) CloudFront WAF removed to save $9/month ($108/year) Shield Standard provides free DDoS protection Annual Savings from WAF Removal: $108/year\nCross-Stack Dependencies Imports from DNS Stack The Certificate Stack imports from DNS Stack:\n// Hardcoded Hosted Zone ID (stable, doesn\u0026#39;t change) const hostedZoneId = \u0026#39;Z018823421GWCSYG5UMHV\u0026#39;; const hostedZone = route53.HostedZone.fromHostedZoneAttributes(this, \u0026#39;HostedZone\u0026#39;, { hostedZoneId: hostedZoneId, zoneName: \u0026#39;everyonecook.cloud\u0026#39;, }); Why Hardcoded?\nCannot use Fn.importValue for cross-region references (us-east-1 ← ap-southeast-1) Hosted Zone ID is stable and never changes Alternative: Use SSM Parameter Store (more complex, same result) Exports Used By Other Stacks The Certificate Stack exports are used by:\nCore Stack (Phase 2)\nImports: CloudFrontCertificateArn Purpose: Attach SSL certificate to CloudFront distribution Region: ap-southeast-1 (cross-region import) Backend Stack (Phase 4)\nImports: ApiGatewayCertificateArn Purpose: Create API Gateway custom domain with SSL Region: ap-southeast-1 (cross-region import) Dependency Flow DNS Stack (ap-southeast-1) │ ├─ Hosted Zone ID: Z018823421GWCSYG5UMHV │ ▼ Certificate Stack (us-east-1) ← MUST be us-east-1 │ ├─ CloudFront Certificate ARN │ └─► Core Stack (ap-southeast-1) │ └─ API Gateway Certificate ARN └─► Backend Stack (ap-southeast-1) Validation Checklist Before proceeding to Core Stack deployment:\nCertificate Stack deployed to us-east-1 region CloudFront certificate status is Issued API Gateway wildcard certificate status is Issued DNS validation CNAME records visible in Route 53 Certificate ARNs exported in CloudFormation outputs Region confirmed as us-east-1 in AWS Console Tags applied correctly to all resources Next Steps After successfully deploying the Certificate Stack:\n➡️ 5.4.3 Core Stack - Create DynamoDB, S3, and CloudFront infrastructure\nThe Core Stack will:\nCreate DynamoDB Single Table with encryption Create S3 buckets for content and CDN logs Create CloudFront distribution with SSL certificate Import CloudFrontCertificateArn from this stack Configure custom domain cdn.everyonecook.cloud References Source Code: infrastructure/lib/stacks/certificate-stack.ts Base Stack: infrastructure/lib/base-stack.ts App Configuration: infrastructure/bin/app.ts AWS Documentation: ACM Certificates DNS Validation CloudFront with ACM Cross-Region References: CloudFormation Cross-Region References "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.03-cdk-bootstrap/","title":"CDK Bootstrap","tags":[],"description":"","content":"Overview AWS CDK Bootstrap prepares your AWS account for deploying CDK applications by creating essential infrastructure resources. This is a one-time setup process per AWS account/region combination that establishes the foundation for all CDK deployments.\nWhat CDK Bootstrap Creates The bootstrap process provisions the following AWS resources in your account:\n1. S3 Bucket (CDK Assets Bucket)\nStores Lambda function deployment packages Stores CloudFormation templates Stores file assets referenced by your CDK stacks Naming pattern: cdk-hnb659fds-assets-{ACCOUNT-ID}-{REGION} Versioning enabled for rollback support 2. CloudFormation Stack (CDKToolkit)\nMain infrastructure stack containing all bootstrap resources Stack name: CDKToolkit Manages lifecycle of bootstrap resources 3. IAM Roles\ncdk-hnb659fds-cfn-exec-role: CloudFormation execution role for deploying stacks cdk-hnb659fds-deploy-role: Role used by CDK CLI during deployment cdk-hnb659fds-file-publishing-role: Role for uploading assets to S3 cdk-hnb659fds-lookup-role: Role for reading environment context 4. SSM Parameters\n/cdk-bootstrap/hnb659fds/version: Stores bootstrap version number Used for compatibility checking Infrastructure Stacks Overview After bootstrapping, our project will deploy multiple CDK stacks defined in D:\\Project_AWS\\everyonecook\\infrastructure\\lib\\stacks:\nauth-stack.ts: Authentication and authorization infrastructure (Cognito) backend-stack.ts: Core backend services and Lambda functions certificate-stack.ts: SSL/TLS certificates management core-stack.ts: Core infrastructure resources dns-stack.ts: Route 53 DNS configuration observability-stack.ts: Monitoring, logging, and observability These stacks depend on the bootstrap infrastructure to deploy successfully.\nLab Instructions: Bootstrap Your AWS Account Prerequisites Before beginning this lab, ensure you have:\nAWS CLI installed and configured (see section 5.1) AWS CDK CLI installed (see section 5.2) Valid AWS credentials configured IAM user with AdministratorAccess permissions or equivalent Terminal/PowerShell access to the project directory Step 3: Verify on AWS Console Confirm resources in the AWS Management Console. 3.1. Verify CloudFormation Stack\nOpen CloudFormation Console Look for stack named CDKToolkit Status should be CREATE_COMPLETE Click on Resources tab to view created resources ** Screenshot Required:** 3.2. Verify S3 Bucket\nOpen S3 Console Find bucket: cdk-hnb659fds-assets-{ACCOUNT-ID}-us-east-1 Verify bucket properties: Versioning: Enabled ** Screenshot Required:** 3.3. Verify IAM Roles\nOpen IAM Roles Console Search for: cdk-hnb659fds Verify the following roles exist: cdk-hnb659fds-cfn-exec-role-{ACCOUNT-ID}-us-east-1 cdk-hnb659fds-deploy-role-{ACCOUNT-ID}-us-east-1 cdk-hnb659fds-file-publishing-role-{ACCOUNT-ID}-us-east-1 cdk-hnb659fds-lookup-role-{ACCOUNT-ID}-us-east-1 Understanding Bootstrap Resources S3 Bucket Details The CDK assets bucket serves as a central repository for all deployment artifacts:\nPurpose: Stores CloudFormation templates, Lambda deployment packages, and static assets Lifecycle: Persists across deployments, enabling rollback capabilities Security: Encrypted at rest, bucket policies restrict access to authorized roles Naming: Deterministic naming based on account ID and region 1. CloudFormation Execution Role (cfn-exec-role)\nUsed by CloudFormation to create/update/delete stack resources Has broad permissions to manage AWS resources Trust relationship with CloudFormation service 2. Deploy Role (deploy-role)\nUsed by CDK CLI during cdk deploy operations Can assume the CloudFormation execution role Has permissions to upload assets and initiate deployments 3. File Publishing Role (file-publishing-role)\n4. Image Publishing Role (image-publishing-role)\n5. Lookup Role (lookup-role)\nReads environment context (VPCs, subnets, etc.) Read-only permissions for resource lookups Used during synthesis for context queries Cost Analysis Bootstrap Resources Cost One-time Setup:\nCloudFormation stack creation: Free IAM roles creation: Free SSM parameters: Free Ongoing Monthly Costs:\nResource Usage Cost (Estimated) S3 Storage \u0026lt; 1 GB (typical) $0.023/GB = ~$0.02/month S3 Requests Minimal (GET/PUT) ~$0.01/month IAM Roles No charge $0.00 Total Estimated Cost: ~$0.03/month (negligible)\nNote: For serverless applications, costs remain minimal as we only store Lambda deployment packages in S3.\nLab Completion Checklist Ensure you have completed all steps and captured required screenshots:\nStep 1: Bootstrap command execution and success - [IMAGE HERE: bootstrap-success.png] Step 2: CLI verification results - [IMAGE HERE: bootstrap-verification-cli.png] Step 3.1: CloudFormation console - [IMAGE HERE: cloudformation-cdktoolkit.png] Step 3.2: S3 bucket console - [IMAGE HERE: s3-bucket-console.png] Step 3.3: IAM roles console - [IMAGE HERE: iam-roles-console.png] Verified AWS account bootstrap status Retrieved your AWS account ID Executed CDK bootstrap command Created CDKToolkit CloudFormation stack Provisioned CDK assets S3 bucket Created necessary IAM roles for CDK deployments Verified bootstrap version in SSM Parameter Store Understood the purpose and cost of each bootstrap resource In this lab, you successfully: Executed CDK bootstrap command for your AWS account Created CDKToolkit CloudFormation stack Provisioned CDK assets S3 bucket for storing Lambda packages Created necessary IAM roles for CDK deployments Verified all resources via CLI and AWS Console Your AWS account is now ready to deploy serverless CDK applications, including the infrastructure stacks for the EveryoneCook project.\nPrepare for infrastructure deployment "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.3-week3/","title":"Week 3 Worklog","tags":[],"description":"","content":"Week 3 Objectives: Understand EC2 basics: instance types, AMI, snapshots, storage (EBS, Instance Store). Practice hands-on labs with EC2, Storage Gateway, S3 static website, and CloudFront. Learn Auto Scaling, EFS, FSx, and VM migration services. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Compute VM on AWS 09/25/2025 09/25/2025 VM on AWS 3 EC2 Introduction 09/26/2025 09/26/2025 EC2 4 EC2 (Lab)\n- EC2 \u0026amp; Infrastructure\n- Storage Gateway 09/27/2025 09/27/2025 cont 5 Lab (cons)\n-S3 \u0026amp; Static Website\n-S3 Security \u0026amp; CloudFront 09/28/2025 09/28/2025 S3 6 Weekly knowledge summary 09/29/2025 09/29/2025 Week 3 Objectives:1. EC2 Basics Virtual servers on AWS. Fast launch, flexible config, lower cost over time. Elasticity: scale up/down with demand. 2. Instance Types \u0026amp; CPU Intel: high perf, costly. AMD: ~10% cheaper. Graviton (ARM): up to 40% cheaper, great perf/price (Linux). 3. AMI Template for EC2. Includes: OS (root vol), permissions, block device mapping. Types: AWS, Marketplace, Custom (Golden Image). 4. Snapshot \u0026amp; Backup First = full, later = incremental. Stored in S3. 5. Key Pair Linux: SSH with private key. Windows: decrypt password via AWS Console → RDP. 6. Storage EBS: persistent, replicated (SSD/HDD), supports Multi-Attach. Instance Store: NVMe, ultra-fast but ephemeral (cache, logs, swap). 7. User Data Script runs once at launch. Auto config (install apps, start services). 8. Meta Data Instance info via: 9. Other Services Auto Scaling → adjust instances by demand. EFS → shared file system. FSx → managed Windows/Lustre storage. Lightsail → simple VPS. MGN → migration service. EC2 (Lab) 1. EC2 \u0026amp; Infrastructure Lab13-02.1 – Create S3 Bucket (chuẩn bị hạ tầng lưu trữ). Lab13-02.2 – Deploy infrastructure. Lab13-03 – Create Backup plan. Lab13-05 – Test Restore. Lab13-06 – Clean up resources. 2. Storage Gateway Lab24-01.2 – Create EC2 for Storage Gateway. Lab24-02.1 – Create Storage Gateway. Lab24-02.2 – Create File Shares. 3. S3 \u0026amp; Static Website Lab57-02.1 – Create S3 bucket. Lab57-02.2 – Load data. Lab57-03 – Enable static website feature. Lab57-04 – Configuring public access. Lab57-05 – Configuring public objects. Lab57-06 – Test website. 4. S3 Security \u0026amp; CloudFront Lab57-07.1 – Block all public access. Lab57-07.2 – Configure Amazon CloudFront. Lab57-07.3 – Test Amazon CloudFront. Lab57-08 – Bucket Versioning. Lab57-09 – Move objects. Lab57-10 – Replication Object multi-region. Lab57-11 – Clean up resources. "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/4-eventparticipated/4.3-event3/","title":"Event 3","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AI-Driven Development Life Cycle\u0026rdquo; Event Objectives Explore how generative AI transforms the software development lifecycle Learn about Amazon Q Developer capabilities and use cases Understand Kiro AI Assistant features and productivity gains Apply AI tools to improve development workflow Event Information Event Name: AI-Driven Development Life Cycle\nDate \u0026amp; Time: Friday, October 3, 2024 | 2:00 PM – 4:30 PM\nLocation: AWS Event Hall, L26 Bitexco Tower, HCMC\nRole: Attendee\nSpeakers Toan Huynh – Amazon Q Developer My Nguyen – Kiro AI Assistant Coordinators Diem My Dai Truong Dinh Nguyen Agenda Time Topic Speaker 2:15 – 3:30 PM Amazon Q Developer Toan Huynh 3:45 – 4:30 PM Kiro AI Assistant My Nguyen Key Highlights Amazon Q Developer (2:15 – 3:30 PM) AI-Driven Development Lifecycle Planning \u0026amp; Architecture: AI-assisted design Development: Code generation from natural language Testing: Automated test generation Deployment: Infrastructure as Code (IaC) generation Maintenance: Documentation and modernization Key Capabilities Code generation with context awareness Code explanation and documentation Debugging assistance AWS integration: Lambda CloudFormation CDK Live Demos REST API endpoint generation Algorithm explanation Unit test creation Code refactoring AWS infrastructure code generation Kiro AI Assistant (3:45 – 4:30 PM) Core Features Intelligent code completion Multi-file understanding Project-level intelligence Automated refactoring Documentation generation Productivity Gains Metric Improvement Code writing speed 40% faster Boilerplate reduction 60% less Documentation time 50% less Initial bugs 30% fewer Live Demos Smart code completion Multi-file refactoring Bug detection and fixing Test generation Documentation automation Key Takeaways AI-Driven Development AI transforms every phase of the development lifecycle Automation frees developers for more creative work Productivity gains are substantial and measurable Code quality improves through consistent patterns Amazon Q Developer Powerful for AWS-centric development Natural language to code is highly effective Security and best practices are built-in Supports multiple programming languages Kiro Excels at project-level understanding Strong context awareness improves suggestions Multi-file operations save significant time Customizable to team standards Best Practices Provide clear context in prompts Always review and understand generated code Iterate and refine AI suggestions Maintain strong security awareness Use AI tools for learning and skill development Applying to Work Install Amazon Q Developer and Kiro Integrate both tools into daily development workflow Measure productivity improvements over time Share learnings and best practices with the team Event Experience Participating in the \u0026ldquo;AI-Driven Development Life Cycle\u0026rdquo; workshop provided valuable insights into how AI is revolutionizing software development. The hands-on demos of Amazon Q Developer and Kiro showed practical applications that can immediately improve productivity.\nThe session highlighted that AI tools are not replacing developers but empowering them to focus on higher-level problem-solving while automating repetitive tasks.\nEvent Photos "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/3-blogstranslated/","title":"Translated Blogs","tags":[],"description":"","content":"This section contains AWS blog posts that I have translated from English to Vietnamese during the internship program.\nBlog 1 - How to SAN Boot Enterprise Amazon EC2 Environments from Amazon FSx for NetApp ONTAP This blog explains how to implement SAN boot for Amazon EC2 instances using Amazon FSx for NetApp ONTAP. You will learn about the benefits of boot-from-SAN including centralized management, thin cloning with golden images, cost reduction through snapshot-based cloning, and simplified HA/DR workflows. The article covers the technical boot process using iPXE chain-loading and best practices for production deployments.\nBlog 2 - Querying Amazon S3 Tables from Open-Source Trino Using the Apache Iceberg REST Endpoint This blog demonstrates how to integrate Trino with Amazon S3 Tables using the Iceberg REST endpoint. You will learn how to deploy a Trino environment using CloudFormation, configure the Iceberg REST connector, create schemas and tables, perform read/write operations, and use advanced features like time travel and schema evolution. The solution provides a powerful analytics platform combining Trino\u0026rsquo;s distributed query engine with S3 Tables\u0026rsquo; built-in optimizations.\nBlog 3 - SMS Onboarding for SaaS, ISVs, and Multi-Tenant Applications with AWS End User Messaging This blog provides a comprehensive guide for technology providers integrating SMS capabilities into their products. You will learn about opt-in flows, architectural models for implementing SMS services (from \u0026ldquo;Bring Your Own AWS Account\u0026rdquo; to \u0026ldquo;Fully Managed Program\u0026rdquo;), pricing strategies, geographic considerations, and best practices to reduce friction during implementation. The article helps SaaS companies, ISVs, and multi-tenant solution providers navigate the complex SMS landscape.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.3-core-stack/","title":"5.4.3 Core Stack","tags":[],"description":"","content":" Core Stack - Data Layer Infrastructure Overview The Core Stack is the Phase 2 foundational data layer of the EveryoneCook project. It creates the core infrastructure for data storage, content delivery, and encryption that all other services depend on.\nDeployment Order: This stack MUST be deployed after Certificate Stack and before Auth Stack and Backend Stack.\nKey Responsibilities Create DynamoDB Single Table with 5 GSI indexes for username-based queries Create S3 buckets with Intelligent-Tiering for cost optimization (57% savings) Create CloudFront CDN distribution with compression and caching Create KMS encryption keys for DynamoDB and S3 Configure Origin Access Control (OAC) for S3 security Setup custom domain with SSL certificate for CDN What This Stack Includes Storage:\nDynamoDB Single Table with encryption at rest S3 Content Bucket (avatars, posts, recipes, backgrounds) S3 CDN Logs Bucket for CloudFront access logs CDN \u0026amp; Caching:\nCloudFront Distribution with custom domain Compression enabled (Gzip + Brotli, 70-80% size reduction) Cache policies (24h default, 7 days max) Origin Access Control (OAC) for S3 security Security:\nKMS Customer Managed Keys for encryption Automatic key rotation (yearly) Security headers (HSTS, X-Frame-Options, etc.) Cost Optimization:\nS3 Intelligent-Tiering (57% cost reduction) CloudFront Price Class 200 (45% cost reduction) Pay-per-request billing for dev environment Architecture ┌─────────────────────────────────────────────────────────────────┐ │ Core Stack (Phase 2) │ │ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ KMS Encryption Layer │ │ │ │ ├─ DynamoDB Key (automatic rotation) │ │ │ │ └─ S3 Key (automatic rotation) │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ DynamoDB Single Table │ │ │ │ ├─ PK: USER#{username} │ │ │ │ ├─ SK: PROFILE|RECIPE#{id}|POST#{id} │ │ │ │ ├─ 5 GSI indexes for queries │ │ │ │ ├─ Billing: PAY_PER_REQUEST (dev) │ │ │ │ ├─ Encryption: Customer Managed KMS │ │ │ │ └─ Streams: Enabled (NEW_AND_OLD_IMAGES) │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ S3 Content Bucket │ │ │ │ ├─ Folders: avatars/, posts/, recipes/, backgrounds/ │ │ │ │ ├─ Intelligent-Tiering (57% savings) │ │ │ │ │ └─ Archive: 90 days, Deep Archive: 180 days │ │ │ │ ├─ Encryption: S3 Managed Keys │ │ │ │ ├─ Versioning: Enabled (prod) │ │ │ │ ├─ CORS: Configured for frontend │ │ │ │ └─ OAC: CloudFront access only │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ CloudFront CDN Distribution │ │ │ │ ├─ Custom Domain: cdn.everyonecook.cloud │ │ │ │ ├─ Certificate: ACM (us-east-1) │ │ │ │ ├─ Compression: Gzip + Brotli (70-80% reduction) │ │ │ │ ├─ Cache TTL: 24h default, 7 days max │ │ │ │ ├─ Price Class: 200 (US, EU, Asia - 45% savings) │ │ │ │ ├─ Security: HTTPS redirect, Security headers │ │ │ │ ├─ Protection: Shield Standard (free DDoS) │ │ │ │ └─ Logs: S3 CDN Logs Bucket │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Route 53 DNS Record (from DNS Stack) │ │ │ │ cdn.everyonecook.cloud → CloudFront (A + AAAA Alias) │ │ │ └──────────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────────┘ │ │ Exports ▼ ┌─────────────────┴────────────────┐ ▼ ▼ Auth Stack Backend Stack (Cognito) (API Gateway, Lambda) Stack Configuration File Structure infrastructure/lib/stacks/ └── core-stack.ts # Core Stack implementation (1545 lines) Code Implementation Highlights File: infrastructure/lib/stacks/core-stack.ts\n1. KMS Keys Creation /** * Create KMS key for DynamoDB encryption */ private createDynamoDBKey(): cdk.aws_kms.Key { const key = new cdk.aws_kms.Key(this, \u0026#39;DynamoDBKey\u0026#39;, { alias: `everyonecook-dynamodb-${this.config.environment}`, description: `KMS key for DynamoDB encryption in ${this.config.environment} environment`, // Enable automatic key rotation (yearly) enableKeyRotation: true, // Deletion protection for production pendingWindow: this.config.environment === \u0026#39;prod\u0026#39; ? cdk.Duration.days(30) : cdk.Duration.days(7), // Removal policy: RETAIN for prod, DESTROY for dev/staging removalPolicy: this.config.environment === \u0026#39;prod\u0026#39; ? cdk.RemovalPolicy.RETAIN : cdk.RemovalPolicy.DESTROY, }); // Add key policy for DynamoDB service key.addToResourcePolicy( new cdk.aws_iam.PolicyStatement({ sid: \u0026#39;Allow DynamoDB to use the key\u0026#39;, effect: cdk.aws_iam.Effect.ALLOW, principals: [new cdk.aws_iam.ServicePrincipal(\u0026#39;dynamodb.amazonaws.com\u0026#39;)], actions: [\u0026#39;kms:Decrypt\u0026#39;, \u0026#39;kms:DescribeKey\u0026#39;, \u0026#39;kms:CreateGrant\u0026#39;], resources: [\u0026#39;*\u0026#39;], conditions: { StringEquals: { \u0026#39;kms:ViaService\u0026#39;: `dynamodb.${this.region}.amazonaws.com`, }, }, }) ); return key; } 2. DynamoDB Single Table /** * Create DynamoDB Single Table with cost optimization */ private createDynamoDBTable(): cdk.aws_dynamodb.Table { const tableName = `EveryoneCook-${this.config.environment}-v2`; const dbConfig = this.config.dynamodb; const table = new cdk.aws_dynamodb.Table(this, \u0026#39;EveryoneCookTable\u0026#39;, { tableName, partitionKey: { name: \u0026#39;PK\u0026#39;, type: cdk.aws_dynamodb.AttributeType.STRING }, sortKey: { name: \u0026#39;SK\u0026#39;, type: cdk.aws_dynamodb.AttributeType.STRING }, // Billing mode: PROVISIONED for prod/staging, PAY_PER_REQUEST for dev billingMode: dbConfig.billingMode === \u0026#39;PROVISIONED\u0026#39; ? cdk.aws_dynamodb.BillingMode.PROVISIONED : cdk.aws_dynamodb.BillingMode.PAY_PER_REQUEST, // Point-in-time recovery for prod/staging pointInTimeRecoverySpecification: { pointInTimeRecoveryEnabled: dbConfig.pointInTimeRecovery, }, // Deletion protection for production deletionProtection: dbConfig.deletionProtection, // Enable DynamoDB Streams stream: dbConfig.streamEnabled ? cdk.aws_dynamodb.StreamViewType.NEW_AND_OLD_IMAGES : undefined, // TTL attribute for automatic cleanup timeToLiveAttribute: \u0026#39;ttl\u0026#39;, // Encryption with customer managed KMS key encryption: cdk.aws_dynamodb.TableEncryption.CUSTOMER_MANAGED, encryptionKey: this.dynamoDbKey, // Removal policy removalPolicy: this.config.environment === \u0026#39;prod\u0026#39; ? cdk.RemovalPolicy.RETAIN : cdk.RemovalPolicy.DESTROY, }); // Add 5 GSI indexes (code continues...) return table; } 3. S3 Bucket with Intelligent-Tiering /** * Create S3 bucket with Intelligent-Tiering for 57% cost savings */ private createContentBucket(): cdk.aws_s3.Bucket { const bucketName = `everyonecook-content-${this.config.environment}`; const s3Config = this.config.s3; const bucket = new cdk.aws_s3.Bucket(this, \u0026#39;ContentBucket\u0026#39;, { bucketName, // Block ALL public access (private bucket) blockPublicAccess: cdk.aws_s3.BlockPublicAccess.BLOCK_ALL, // Enable versioning for production versioned: s3Config.versioning, // S3-managed encryption encryption: cdk.aws_s3.BucketEncryption.S3_MANAGED, // Intelligent-Tiering configuration intelligentTieringConfigurations: [{ name: \u0026#39;EntireBucket\u0026#39;, archiveAccessTierTime: cdk.Duration.days(90), // Archive tier deepArchiveAccessTierTime: cdk.Duration.days(180), // Deep Archive }], // Lifecycle rules lifecycleRules: [ { id: \u0026#39;DeleteOldVersions\u0026#39;, enabled: s3Config.versioning, noncurrentVersionExpiration: cdk.Duration.days(30), }, { id: \u0026#39;DeleteTempUploads\u0026#39;, enabled: true, prefix: \u0026#39;posts/temp/\u0026#39;, expiration: cdk.Duration.days(1), // Clean up temp files after 24h }, ], // CORS for frontend access cors: [{ allowedOrigins: [ `https://${this.config.domain.frontend}`, ...(this.config.environment === \u0026#39;dev\u0026#39; ? [\u0026#39;http://localhost:3000\u0026#39;] : []), ], allowedMethods: [ cdk.aws_s3.HttpMethods.GET, cdk.aws_s3.HttpMethods.PUT, cdk.aws_s3.HttpMethods.POST, cdk.aws_s3.HttpMethods.DELETE, ], allowedHeaders: [\u0026#39;*\u0026#39;], exposedHeaders: [\u0026#39;ETag\u0026#39;], maxAge: 3000, }], removalPolicy: this.config.environment === \u0026#39;prod\u0026#39; ? cdk.RemovalPolicy.RETAIN : cdk.RemovalPolicy.DESTROY, }); return bucket; } 4. CloudFront Distribution /** * Create CloudFront distribution with compression and caching */ private createCloudFrontDistribution(): cdk.aws_cloudfront.Distribution { // Import Route 53 Hosted Zone const hostedZone = cdk.aws_route53.HostedZone.fromHostedZoneAttributes( this, \u0026#39;HostedZone\u0026#39;, { hostedZoneId: cdk.Fn.importValue(this.exportName(\u0026#39;HostedZoneId\u0026#39;)), zoneName: \u0026#39;everyonecook.cloud\u0026#39;, } ); // Import ACM certificate from Certificate Stack (us-east-1) const certificate = cdk.aws_certificatemanager.Certificate.fromCertificateArn( this, \u0026#39;ImportedCloudFrontCertificate\u0026#39;, \u0026#39;arn:aws:acm:us-east-1:616580903213:certificate/8d53776e-0480-47d2-a6ff-4fe9b2eb6534\u0026#39; ); // Create cache policy with compression const publicCachePolicy = new cdk.aws_cloudfront.CachePolicy( this, \u0026#39;PublicCachePolicy\u0026#39;, { cachePolicyName: `EveryoneCook-Public-${this.config.environment}`, defaultTtl: cdk.Duration.hours(24), // 24h default maxTtl: cdk.Duration.days(7), // 7 days max minTtl: cdk.Duration.seconds(0), // Enable compression (Gzip + Brotli) enableAcceptEncodingGzip: true, enableAcceptEncodingBrotli: true, queryStringBehavior: cdk.aws_cloudfront.CacheQueryStringBehavior.all(), headerBehavior: cdk.aws_cloudfront.CacheHeaderBehavior.allowList( \u0026#39;CloudFront-Viewer-Country\u0026#39; ), cookieBehavior: cdk.aws_cloudfront.CacheCookieBehavior.none(), } ); // Create CloudFront distribution const distribution = new cdk.aws_cloudfront.Distribution( this, \u0026#39;CDNDistribution\u0026#39;, { comment: `Everyone Cook CDN - ${this.config.environment}`, // Default behavior with OAC defaultBehavior: { origin: origins.S3BucketOrigin.withOriginAccessControl(this.contentBucket), viewerProtocolPolicy: cdk.aws_cloudfront.ViewerProtocolPolicy.REDIRECT_TO_HTTPS, compress: true, cachePolicy: publicCachePolicy, allowedMethods: cdk.aws_cloudfront.AllowedMethods.ALLOW_GET_HEAD_OPTIONS, }, // Price Class 200 (US, Europe, Asia - 45% cost savings) priceClass: cdk.aws_cloudfront.PriceClass.PRICE_CLASS_200, // Custom domain with SSL domainNames: [this.config.domains.cdn], certificate: certificate, // CloudFront access logs enableLogging: true, logBucket: this.cdnLogsBucket, logFilePrefix: \u0026#39;cdn-access-logs/\u0026#39;, // Enable IPv6 enableIpv6: true, // HTTP/2 + HTTP/3 httpVersion: cdk.aws_cloudfront.HttpVersion.HTTP2_AND_3, // TLS 1.2 minimum minimumProtocolVersion: cdk.aws_cloudfront.SecurityPolicyProtocol.TLS_V1_2_2021, } ); // Create Route 53 A record (Alias to CloudFront) new cdk.aws_route53.ARecord(this, \u0026#39;CloudFrontAliasRecord\u0026#39;, { zone: hostedZone, recordName: this.config.domains.cdn, target: cdk.aws_route53.RecordTarget.fromAlias( new targets.CloudFrontTarget(distribution) ), }); return distribution; } Key Configuration Details 1. DynamoDB Single Table Design Table Structure:\nPK: USER#{username} SK: PROFILE | RECIPE#{recipeId} | POST#{postId} | COMMENT#{commentId} GSI1: username-recipeDate (user\u0026#39;s recipes by date) GSI2: username-postDate (user\u0026#39;s posts by date) GSI3: recipeId-index (recipe lookup) GSI4: postId-index (post lookup) GSI5: email-index (email lookup) Billing Modes:\nDev: PAY_PER_REQUEST (no provisioned capacity, pay per request) Staging: PROVISIONED (5 RCU, 5 WCU with auto-scaling) Prod: PROVISIONED (10 RCU, 10 WCU with auto-scaling) 2. S3 Intelligent-Tiering Cost Savings Cost Comparison (100GB content):\nTier Cost per GB 100GB Cost Timeline Frequent Access $0.023 $2.30/month Default Infrequent Access $0.0125 $1.25/month After 30 days Archive Instant $0.004 $0.40/month After 90 days Archive $0.0036 $0.36/month After 90 days Deep Archive $0.00099 $0.099/month After 180 days Savings: $2.30 → $0.099 = 57% cost reduction after 12 months\n3. CloudFront Compression File Size Reduction:\nText files (HTML, CSS, JS, JSON): 70-80% reduction Images (already compressed): No additional compression Videos (already compressed): No additional compression Example:\nOriginal JS bundle: 1MB → Compressed: 200KB (80% reduction) 1000 requests/day: 1GB/day → 200MB/day (saves 800MB bandwidth) 4. CloudFront Price Class 200 Cost Comparison:\nPrice Class Regions Cost per GB Savings All All regions $0.085 Baseline 200 US, EU, Asia $0.047 45% savings 100 US, EU only $0.025 71% savings (but limited coverage) Decision: Price Class 200 balances cost (45% savings) with global coverage.\nStack Outputs After deployment, the stack exports the following values:\nOutput Name Value Used By DynamoDBTableName EveryoneCook-dev-v2 Auth Stack, Backend Stack DynamoDBTableArn arn:aws:dynamodb:... Lambda IAM policies DynamoDBTableStreamArn arn:aws:dynamodb:... Event-driven processing DynamoDBKeyId KMS Key ID Encryption references DynamoDBKeyArn arn:aws:kms:... Lambda permissions S3KeyId KMS Key ID S3 encryption ContentBucketName everyonecook-content-dev Backend Stack, Lambda ContentBucketArn arn:aws:s3:... IAM policies CloudFrontDistributionId E1234567890ABC Backend Stack (WAF) CloudFrontDomainName d1234567890.cloudfront.net DNS verification Deployment Steps Step 1: Verify Prerequisites Before deploying Core Stack, ensure:\nDNS Stack successfully deployed Certificate Stack successfully deployed (us-east-1) CloudFront certificate status is Issued Route 53 DNS delegation working Step 2: Deploy Core Stack Navigate to infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Deploy Core Stack to ap-southeast-1:\n# Deploy Core Stack npx cdk deploy EveryoneCook-dev-Core --context environment=dev Expected output:\n✨ Synthesis time: 8.45s EveryoneCook-dev-Core: deploying... [████████████████████████████████████████] (12/12) EveryoneCook-dev-Core: creating CloudFormation changeset... EveryoneCook-dev-Core ✨ Deployment time: 450.23s Outputs: EveryoneCook-dev-Core.DynamoDBTableName = EveryoneCook-dev-v2 EveryoneCook-dev-Core.ContentBucketName = everyonecook-content-dev EveryoneCook-dev-Core.CloudFrontDistributionId = E2ABCDEFGHIJKL EveryoneCook-dev-Core.CloudFrontDomainName = d1a2b3c4d5e6f7.cloudfront.net EveryoneCook-dev-Core.StackInfo = Core Stack for dev environment Stack ARN: arn:aws:cloudformation:ap-southeast-1:616580903213:stack/EveryoneCook-dev-Core/... Step 3: Wait for CloudFront Distribution CloudFront distribution deployment takes 15-20 minutes. You can monitor progress:\n# Check CloudFront distribution status aws cloudfront get-distribution --id E2ABCDEFGHIJKL --query \u0026#39;Distribution.Status\u0026#39; Status progression:\nInProgress (0-15 minutes) Deployed (ready to use) Step 4: Verify in AWS Console Navigate to DynamoDB Open AWS Console → ap-southeast-1 region Go to DynamoDB \u0026gt; Tables Find table EveryoneCook-dev-v2 DynamoDB table showing partitionKey (PK), sortKey (SK), 5 GSI indexes, billing mode (PAY_PER_REQUEST), encryption (KMS), and streams enabled\nVerify:\nPartition key: PK (String) Sort key: SK (String) 5 GSI indexes visible Billing mode: PAY_PER_REQUEST (dev) Encryption: Customer managed KMS Streams: Enabled (NEW_AND_OLD_IMAGES) Navigate to S3 Go to S3 \u0026gt; Buckets Find buckets: everyonecook-content-dev everyonecook-cdn-logs-dev S3 content bucket showing folder structure (avatars/, posts/, recipes/, backgrounds/), Intelligent-Tiering configuration, versioning, CORS, and encryption settings\nVerify Content Bucket:\nBlock all public access: On Versioning: Enabled (prod) / Disabled (dev) Intelligent-Tiering: Configured Encryption: S3-managed keys CORS: Configured Lifecycle rules: 2 rules S3 Intelligent-Tiering configuration showing Archive Access Tier (90 days) and Deep Archive Access Tier (180 days)\nNavigate to CloudFront Go to CloudFront \u0026gt; Distributions Find distribution with domain cdn-dev.everyonecook.cloud CloudFront distribution showing custom domain, origin (S3 with OAC), cache behaviors, compression enabled, Price Class 200, SSL certificate, and status (Deployed)\nVerify:\nStatus: Deployed Domain: cdn-dev.everyonecook.cloud Origin: S3 bucket with OAC Compression: Enabled Price Class: 200 SSL Certificate: Valid HTTPS: Redirect CloudFront Origin Access Control (OAC) configuration showing S3 origin with OAC policy automatically created\nNavigate to KMS Go to KMS \u0026gt; Customer managed keys Find keys: everyonecook-dynamodb-dev everyonecook-s3-dev KMS customer managed keys showing key aliases, key rotation enabled (yearly), key policies, and usage by DynamoDB and S3\nVerify:\nKey rotation: Enabled Key state: Enabled Deletion protection: Configured Key policy: DynamoDB/S3 service access Verify Route 53 DNS Record Go to Route 53 \u0026gt; Hosted zones Select everyonecook.cloud Verify A record for cdn-dev.everyonecook.cloud Route 53 A record (Alias) pointing cdn-dev.everyonecook.cloud to CloudFront distribution\nExpected:\ncdn-dev.everyonecook.cloud A Alias d1a2b3c4d5e6f7.cloudfront.net Cost Breakdown Monthly Costs (Dev Environment) Resource Configuration Monthly Cost Notes DynamoDB PAY_PER_REQUEST $1-5 Low traffic S3 Content 10GB, Intelligent-Tiering $0.23 Moves to Deep Archive S3 Logs 5GB $0.12 Access logs CloudFront 100GB transfer, Price Class 200 $4.70 45% savings vs All KMS 2 keys $2.00 $1/key/month Route 53 1 hosted zone, DNS queries $0.50 From DNS Stack Total (Estimated) ~$8-13/month Low traffic scenario Cost Optimization Strategies S3 Intelligent-Tiering: 57% savings on storage CloudFront Price Class 200: 45% savings on bandwidth DynamoDB PAY_PER_REQUEST (dev): Pay only for actual usage CloudFront WAF removed: $9/month savings Compression enabled: 70-80% bandwidth reduction Total Potential Savings: ~$20-30/month compared to non-optimized setup\nCross-Stack Dependencies Imports from Previous Stacks From DNS Stack:\nhostedZoneId: cdk.Fn.importValue(\u0026#39;EveryoneCook-dev-HostedZoneId\u0026#39;) zoneName: \u0026#39;everyonecook.cloud\u0026#39; From Certificate Stack:\ncertificateArn: \u0026#39;arn:aws:acm:us-east-1:616580903213:certificate/8d53776e-...\u0026#39; Exports Used By Other Stacks Auth Stack imports:\nDynamoDB table (for user profiles) DynamoDB key (for Lambda permissions) Backend Stack imports:\nDynamoDB table (for all data operations) S3 content bucket (for file uploads) CloudFront distribution (for WAF association) KMS keys (for encryption) Dependency Flow DNS Stack → Hosted Zone ID │ ▼ Certificate Stack (us-east-1) → Certificate ARN │ ▼ Core Stack (ap-southeast-1) │ ├─► DynamoDB Table → Auth Stack, Backend Stack ├─► S3 Buckets → Backend Stack ├─► CloudFront → Backend Stack (WAF) └─► KMS Keys → Auth Stack, Backend Stack Validation Checklist Before proceeding to Auth Stack deployment:\nCore Stack successfully deployed to ap-southeast-1 DynamoDB table exists with 5 GSI indexes S3 content bucket has Intelligent-Tiering configured S3 CORS configured for frontend domain CloudFront distribution status is Deployed CloudFront custom domain resolves: cdn-dev.everyonecook.cloud CloudFront OAC configured for S3 access KMS keys created with rotation enabled Route 53 A record created for CloudFront All stack outputs exported successfully Testing Test CloudFront Distribution Test custom domain:\ncurl -I https://cdn-dev.everyonecook.cloud Expected response:\nHTTP/2 403 server: CloudFront x-cache: Error from cloudfront (403 is expected - bucket is empty)\nTest compression:\ncurl -H \u0026#34;Accept-Encoding: gzip, br\u0026#34; -I https://cdn-dev.everyonecook.cloud Test HTTPS redirect:\ncurl -I http://cdn-dev.everyonecook.cloud Expected: Redirect to HTTPS\nTest DynamoDB Table # List tables aws dynamodb list-tables --region ap-southeast-1 # Describe table aws dynamodb describe-table --table-name EveryoneCook-dev-v2 --region ap-southeast-1 Test S3 Bucket Access # Try direct S3 access (should be blocked) curl -I https://everyonecook-content-dev.s3.ap-southeast-1.amazonaws.com # Expected: 403 Forbidden (OAC protection working) Next Steps After successfully deploying the Core Stack:\n➡️ 5.4.4 Auth Stack - Create Cognito User Pool and authentication\nThe Auth Stack will:\nCreate Cognito User Pool with advanced security Configure user attributes and password policy Setup Cognito triggers (Lambda functions) Create SES email identity for verification emails Import DynamoDB table from Core Stack References Source Code: infrastructure/lib/stacks/core-stack.ts Base Stack: infrastructure/lib/base-stack.ts Environment Config: infrastructure/config/environment.ts AWS Documentation: DynamoDB Single Table Design S3 Intelligent-Tiering CloudFront Origin Access Control KMS Key Rotation "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/","title":"Configure Infrastructure Stacks","tags":[],"description":"","content":"Configure Infrastructure Stacks EveryoneCook Project Overview Introduction EveryoneCook is a social network platform for sharing cooking recipes, built entirely on AWS Cloud. The project uses a serverless architecture, leveraging AWS managed services to ensure scalability, security, and cost optimization.\nSystem Architecture The project is designed with a 5-Stack Architecture featuring clear layers:\n┌─────────────────────────────────────────────────────────────┐ │ EveryoneCook Platform │ ├─────────────────────────────────────────────────────────────┤ │ Layer 1: DNS \u0026amp; Certificate (Foundation) │ │ ├─ DNS Stack: Route 53 Hosted Zone │ │ └─ Certificate Stack: ACM Certificates (us-east-1) │ ├─────────────────────────────────────────────────────────────┤ │ Layer 2: Data \u0026amp; Storage (Core Infrastructure) │ │ └─ Core Stack: DynamoDB, S3, CloudFront, KMS │ ├─────────────────────────────────────────────────────────────┤ │ Layer 3: Authentication \u0026amp; Security │ │ └─ Auth Stack: Cognito, Lambda Triggers, SES │ ├─────────────────────────────────────────────────────────────┤ │ Layer 4: Application \u0026amp; Business Logic │ │ └─ Backend Stack: API Gateway, Lambda, SQS, WAF │ ├─────────────────────────────────────────────────────────────┤ │ Layer 5: Monitoring \u0026amp; Observability │ │ └─ Observability Stack: CloudWatch, Alarms, Dashboards │ └─────────────────────────────────────────────────────────────┘ Technologies Used Infrastructure as Code AWS CDK (TypeScript): Infrastructure management with code CloudFormation: Underlying template engine for CDK Git: Version control for infrastructure code Backend Services API Gateway REST API: RESTful API endpoint with custom domain Lambda Functions: Serverless compute for business logic (6 main functions + 1 worker) Lambda Layers: Shared dependencies layer (reduces deployment size by 90%) DynamoDB: NoSQL database with Single Table Design + 5 GSI indexes S3: Object storage for user content (avatars, posts, recipes, backgrounds) SQS: Message queue for async processing (4 queues + 4 DLQs) Security \u0026amp; Authentication Cognito User Pool: User authentication \u0026amp; management Cognito User Pool Client: Frontend authentication config WAF (Web Application Firewall): API Gateway protection with rate limiting KMS (Key Management Service): 2 customer-managed keys (DynamoDB, S3) IAM Roles \u0026amp; Policies: Fine-grained access control for all services Content Delivery \u0026amp; Networking CloudFront: CDN with Origin Access Control (OAC) + Shield Standard Route 53: DNS management with Hosted Zone ACM (Certificate Manager): SSL/TLS certificates (2 certificates) Monitoring \u0026amp; Operations CloudWatch Logs: Centralized logging for Lambda functions CloudWatch Metrics: Performance metrics tracking CloudWatch Dashboards: 4 dashboards (Core, Auth, Backend, Overview) CloudWatch Alarms: Real-time monitoring (10+ alarms) + Composite Alarm SNS (Simple Notification Service): Email notifications for alarms Project Directory Structure everyonecook/ ├── infrastructure/ # AWS CDK Infrastructure │ ├── bin/ │ │ └── app.ts # CDK app entry point - creates all stacks │ ├── lib/ │ │ ├── base-stack.ts # Base class for all stacks │ │ ├── stacks/ # Stack definitions │ │ │ ├── dns-stack.ts # Route 53 Hosted Zone │ │ │ ├── certificate-stack.ts # ACM Certificates │ │ │ ├── core-stack.ts # DynamoDB, S3, CloudFront │ │ │ ├── auth-stack.ts # Cognito, Lambda triggers │ │ │ ├── backend-stack.ts # API Gateway, Lambda, SQS │ │ │ └── observability-stack.ts # CloudWatch, Alarms │ │ └── constructs/ # Reusable CDK constructs │ │ └── shared-layer.ts # Lambda Layer with dependencies │ ├── config/ │ │ └── environment.ts # Environment configuration (dev/staging/prod) │ ├── cdk.json # CDK configuration │ ├── package.json # Node.js dependencies │ └── tsconfig.json # TypeScript configuration ├── services/ # Lambda function source code │ ├── api-router/ # API request routing │ ├── auth-user/ # Authentication endpoints │ ├── social/ # Social features (posts, comments) │ ├── recipe-ai/ # Recipe \u0026amp; AI endpoints │ ├── admin/ # Admin management │ └── upload/ # File upload handler ├── shared/ # Shared code \u0026amp; utilities │ ├── utils/ # Common utilities │ ├── models/ # Data models │ └── middleware/ # Lambda middleware ├── frontend/ # Next.js frontend (deployed separately) │ └── ... └── layers/ # Lambda layers └── shared-dependencies/ # Common npm packages Stack Architecture Overview 1. DNS Stack (Phase 1) Purpose: Create the foundation for DNS management\nMain resources:\nRoute 53 Hosted Zone for domain everyonecook.cloud Export nameservers to configure at the domain registrar Deployment order: This stack must be deployed first\nEstimated cost: ~$0.50/month\nNote: After deploying this stack, update the nameservers at your domain registrar (e.g., Hostinger) to point to Route 53.\n2. Certificate Stack (Phase 1.5) Purpose: Create SSL/TLS certificates for CloudFront and API Gateway\nMain resources:\nACM Certificate for CloudFront: cdn.everyonecook.cloud ACM Wildcard Certificate for API Gateway: *.everyonecook.cloud DNS validation records in Route 53 Special region: MUST deploy to us-east-1 (CloudFront requirement)\nDependencies: DNS Stack (requires Hosted Zone for DNS validation)\nEstimated cost: Free (ACM certificates are free)\nImportant: CloudFront only accepts certificates from the us-east-1 region.\n3. Core Stack (Phase 2) Purpose: Create the data layer and storage infrastructure\nMain resources:\nDynamoDB Table: Single Table Design with 5 GSI indexes PK: USER#{username}, SK: PROFILE|RECIPE#{id}|POST#{id}|COMMENT#{id} Username-based primary key (immutable) GSI1-GSI5 for different query patterns: GSI1: User recipes by date GSI2: User posts by date GSI3: Post comments GSI4: Recipe search by cuisine/difficulty GSI5: Social interactions (likes, follows) Billing mode: Pay-per-request (on-demand) Encryption: Customer-managed KMS key with auto-rotation S3 Buckets (2 buckets): Content Bucket: User uploads (avatars, posts, recipes, backgrounds) Intelligent-Tiering enabled (automatically optimizes cost) Versioning enabled Lifecycle rules: Delete incomplete multipart uploads after 7 days Encryption: Customer-managed KMS key CDN Logs Bucket: CloudFront access logs Intelligent-Tiering enabled Auto-delete logs after 90 days (cost optimization) CloudFront Distribution: Origin: S3 Content Bucket Origin Access Control (OAC) to secure S3 access (replaces OAI) Custom domain: cdn.everyonecook.cloud SSL Certificate: ACM certificate from Certificate Stack Cache behaviors: Optimized for images \u0026amp; static content Compression: Gzip \u0026amp; Brotli enabled Shield Standard: DDoS protection (free, auto-enabled) NOTE: CloudFront WAF removed to save $9/month KMS Keys (2 customer-managed keys): DynamoDB Encryption Key: Auto-rotation enabled (yearly) Used by: DynamoDB table, CloudWatch Logs S3 Encryption Key: Auto-rotation enabled (yearly) Used by: S3 buckets, CloudFront signed URLs IAM Roles: CloudFront Origin Access Control role Lambda execution roles with DynamoDB \u0026amp; S3 access Dependencies: Certificate Stack (requires certificate for CloudFront)\nEstimated cost: ~$8-15/month\nCost optimization:\nS3 Intelligent-Tiering automatically moves objects to cheaper storage CloudFront WAF removed (Shield Standard provides DDoS protection) CloudWatch Logs auto-delete after retention period 4. Auth Stack (Phase 3) Purpose: Authentication and user management\nMain resources:\nCognito User Pool: Sign-in methods: Username OR Email + Password NO MFA requirement (only email + password) Password policy: Min 12 chars for prod (8 chars for dev) Require uppercase, lowercase, digits, symbols Standard attributes: email, given_name (fullName), birthdate, gender Custom attributes: account_status (for admin ban), country (ISO 3166-1) Device tracking: Enabled (NO challenge required) Email verification: Required before use Account recovery: Email-based NOTE: Advanced Security Mode OFF to save ~$5/month Lambda Triggers (5 functions with CloudWatch Logs): Pre-signup: Validate username uniqueness Check profanity/banned words Runtime: Node.js 20.x Post-confirmation: Create user profile in DynamoDB Initialize user stats Pre-authentication: Check account status (active/banned) Log login attempts Post-authentication: Update last login timestamp Track user activity Custom message: Customize verification emails Branded email templates Cognito User Pool Client: OAuth flows: Authorization code grant Token validity: Access token: 1 hour Refresh token: 30 days Read/Write attributes configured CloudWatch Log Groups: Each Lambda trigger has a dedicated log group Retention: 7 days Encryption: KMS DynamoDB key IAM Roles: Lambda execution roles Permissions: DynamoDB read/write, Cognito admin, Logs write Dependencies: Core Stack (Lambda triggers need access to DynamoDB)\nEstimated cost: ~$0-2/month (Cognito free tier: 50,000 MAU)\nSecurity:\nAdvanced Security Mode not enabled to optimize cost (would cost an extra ~$5/month) Device tracking enabled but NO MFA to improve user experience All Lambda triggers have CloudWatch logging 5. Backend Stack (Phase 4) Purpose: Application layer and business logic\nMain resources:\nAPI Gateway REST API: Custom domain: api.everyonecook.cloud SSL Certificate: Wildcard ACM certificate (*.everyonecook.cloud) Cognito Authorizer: Validate JWT tokens Request validators: Body validator: Validate request body Params validator: Validate query params \u0026amp; path params Full validator: Validate both body \u0026amp; params Deployment stage: dev/staging/prod CloudWatch Logs: Access logs + execution logs WAF Web ACL attached (API protection) Lambda Functions (6 main modules + CloudWatch Logs): API Router: Route requests to appropriate handlers Memory: 256 MB, Timeout: 30s Auth User: Login, register, forgot-password, verify-email Cognito integration Memory: 512 MB, Timeout: 30s Social: Create/edit/delete posts, comments, likes Follow/unfollow users Memory: 512 MB, Timeout: 30s Recipe AI: CRUD operations for recipes AI recipe generation (Bedrock integration) Recipe search \u0026amp; recommendations Memory: 1024 MB, Timeout: 60s Admin: User management, ban/unban Content moderation Analytics dashboard Memory: 512 MB, Timeout: 30s Upload: File upload to S3 Generate pre-signed URLs Image validation Memory: 512 MB, Timeout: 30s Runtime: Node.js 20.x Environment variables: DynamoDB table, S3 bucket, SQS queues Lambda Layer - Shared Dependencies: AWS SDK v3 clients: DynamoDB, S3, SQS, Cognito, Bedrock, Lambda Utilities: uuid, jsonwebtoken, jwks-rsa Benefit: Reduces deployment size from 8MB → 200KB per function (90% reduction) Compatible runtimes: Node.js 18.x, 20.x SQS Queues (4 main queues + 4 DLQs): AI Queue: AI recipe generation requests Visibility timeout: 120s (2 minutes) Message retention: 4 days Max receive count: 3 (then move to DLQ) Image Processing Queue: Image optimization, thumbnails Visibility timeout: 60s Message retention: 4 days Analytics Queue: User activity tracking Visibility timeout: 30s Message retention: 4 days Notification Queue: Push notifications, emails Visibility timeout: 30s Message retention: 4 days Encryption: AWS managed KMS keys Worker Lambda (1 active): AI Worker: Process AI Queue messages Call Amazon Bedrock for recipe generation Store results in DynamoDB Memory: 1024 MB, Timeout: 120s Event source: AI Queue (batch size: 10) Note: Other workers not yet implemented WAF Web ACL (API Gateway only): Rate limiting: 2000 requests / 5 minutes per IP AWS Managed Rules: AWSManagedRulesCommonRuleSet (OWASP Top 10) AWSManagedRulesKnownBadInputsRuleSet Custom rules: Block specific patterns NOTE: CloudFront WAF removed to save $9/month Shield Standard: Auto-enabled (DDoS protection - free) CloudWatch Log Groups: API Gateway access logs + execution logs Lambda function logs (per function) Retention: 7 days (cost optimization) Encryption: KMS DynamoDB key IAM Roles \u0026amp; Policies: API Gateway execution role Lambda execution roles (per function) Permissions: DynamoDB, S3, SQS, Cognito, Bedrock, Logs, KMS Shared Lambda Layer:\nAWS SDK v3 clients (DynamoDB, S3, SQS, Cognito, Bedrock) Common utilities (uuid, jsonwebtoken, jwks-rsa) Reduces deployment size: 8MB → 200KB per function Dependencies: Auth Stack (requires Cognito User Pool)\nEstimated cost: ~$10-25/month\nCost optimization:\nCloudFront WAF removed (Shield Standard provides DDoS protection) WAF only enabled for API Gateway (main attack surface) Lambda Layer reduces deployment size by 90% CloudWatch Logs auto-delete after 7 days 6. Observability Stack (Phase 7) Purpose: Monitoring, logging, and alerting\nMain resources:\nCloudWatch Dashboards (4 dashboards): Core Dashboard: DynamoDB metrics: Read/write capacity, throttling, latency S3 metrics: Request count, 4xx/5xx errors, bytes downloaded CloudFront metrics: Request count, cache hit rate, error rate KMS metrics: Key usage, encryption/decryption operations Auth Dashboard: Cognito metrics: Sign-ups, sign-ins, failed authentications Lambda trigger metrics: Invocations, errors, duration User pool analytics Backend Dashboard: API Gateway metrics: Request count, 4xx/5xx errors, latency Lambda metrics: Invocations, errors, duration, throttles, concurrent executions SQS metrics: Messages sent, received, deleted, DLQ depth WAF metrics: Blocked requests, allowed requests, rule matches Overview Dashboard: System health summary Cost tracking Composite alarm status Key metrics from all stacks CloudWatch Alarms (15+ alarms): Critical Alarms (notify immediately): API Gateway 5xx errors \u0026gt; 5% (system errors) Lambda error rate \u0026gt; 10% DynamoDB read/write throttling SQS DLQ has messages (failed processing) S3 5xx errors Cost \u0026gt; $50/month (budget exceeded) Warning Alarms (notify but not urgent): API Gateway 4xx errors \u0026gt; 10% (client errors) Lambda duration \u0026gt; 25s (approaching timeout) Lambda throttling (concurrent limit reached) DynamoDB latency high (\u0026gt; 100ms) S3 4xx errors SQS queue age \u0026gt; 15 minutes (processing lag) Cost \u0026gt; $35/month (budget warning) All alarms: Evaluation periods: 1-2 periods Datapoints to alarm: Configurable Treatment of missing data: NOT_BREACHING Composite Alarm: Name: \u0026ldquo;SystemHealth\u0026rdquo; Combines all critical alarms Alarm rule: OR logic (any critical alarm triggers) Actions: Send SNS notification Purpose: Single alarm for overall system health SNS Topic: Topic name: EveryoneCook-{env}-Alarms Email subscription: Admin email from config Delivery status logging enabled Encryption: AWS managed key CloudWatch Logs: Retention: 7 days (cost optimization) Encryption: KMS DynamoDB key Log groups: API Gateway, Lambda functions (all have logs) Cost Tracking: CloudWatch metric: EstimatedCharges Alarms: Warning ($35) + Critical ($50) Daily cost monitoring Dependencies: All other stacks (monitors the entire infrastructure)\nEstimated cost: ~$3-8/month\nBest practice:\nDeploy this stack last for complete visibility Composite alarm helps reduce alarm fatigue 7-day log retention balances debugging needs and cost Cost alarms prevent unexpected bills Stack Dependencies Flow DNS Stack (Route 53) ↓ Certificate Stack (ACM in us-east-1) ↓ Core Stack (DynamoDB, S3, CloudFront, KMS) ↓ Auth Stack (Cognito, Lambda Triggers) ↓ Backend Stack (API Gateway, Lambda, SQS, WAF) ↓ Observability Stack (CloudWatch, Alarms) Dependency explanation:\nCertificate Stack needs DNS Stack to validate certificates via Route 53 DNS Core Stack needs Certificate Stack to attach certificate to CloudFront Auth Stack needs Core Stack so Lambda triggers can access DynamoDB Backend Stack needs Auth Stack to integrate Cognito Authorizer into API Gateway Observability Stack needs all stacks to monitor all resources Total Estimated Cost Development Environment:\nService Cost/month Notes Route 53 Hosted Zone $0.50 1 hosted zone + DNS queries ACM Certificates $0 Free for public certificates DynamoDB (Pay-per-request) $3-5 Depends on usage, free tier available S3 (Intelligent-Tiering) $1-3 2 buckets, auto-tiering saves cost CloudFront $2-5 CDN distribution + data transfer Lambda $0-3 7 functions + 1 worker, free tier 1M requests Lambda Layer $0 No additional charge API Gateway $0-3 REST API, free tier 1M requests Cognito (Free tier) $0 Up to 50,000 MAU SQS $0-1 4 queues + 4 DLQs, free tier 1M requests WAF (API Gateway only) $5-8 Web ACL + rules + requests processed CloudWatch Logs $1-2 7-day retention, all services CloudWatch Dashboards $0-1 4 dashboards, first 3 free CloudWatch Alarms $0.50-1 15+ alarms, $0.10/alarm SNS $0 Email notifications, low volume KMS $2 2 customer-managed keys @ $1 each IAM $0 Roles \u0026amp; policies are free TOTAL $15-35/month Development with low traffic Note:\nThis is an estimate for the development environment with low traffic Production environment with high traffic will have significantly higher costs Free tier: Cognito (50K MAU), Lambda (1M requests), API Gateway (1M requests), SQS (1M requests) Cost optimizations applied: CloudFront WAF removed (-$9/month) S3 Intelligent-Tiering (auto cost reduction) CloudWatch Logs 7-day retention Lambda Layer reduces deployment costs authStack.addDependency(coreStack); backendStack.addDependency(authStack); observabilityStack.addDependency(backendStack);\nConfiguration Guide Step 1: Prepare Infrastructure Directory 1. Navigate to infrastructure directory\ncd D:\\Project_AWS\\everyonecook\\infrastructure 2. Install dependencies\nnpm install TODO: Take a screenshot of the terminal with the output of npm install\nStep 2: Configure Environment Settings 1. Review environment configuration\nOpen the file config/environment.ts to review the configuration:\ncode config\\environment.ts This file contains configuration for environments (dev, staging, prod):\n// Example Dev environment configuration dev: { environment: \u0026#39;dev\u0026#39;, account: \u0026#39;123456789012\u0026#39;, // Update with your AWS Account ID region: \u0026#39;ap-southeast-1\u0026#39;, // Singapore region domains: { frontend: \u0026#39;dev.everyonecook.cloud\u0026#39;, api: \u0026#39;api-dev.everyonecook.cloud\u0026#39;, cdn: \u0026#39;cdn-dev.everyonecook.cloud\u0026#39;, }, cognito: { passwordPolicy: { minLength: 8, // Dev: 8 chars, Prod: 12 chars } } } 2. Verify AWS Account ID\n# Check current AWS Account ID aws sts get-caller-identity Output will show:\n{ \u0026#34;UserId\u0026#34;: \u0026#34;AIDAXXXXXXXXXXXXXXXXX\u0026#34;, \u0026#34;Account\u0026#34;: \u0026#34;123456789012\u0026#34;, \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::123456789012:user/your-username\u0026#34; } 3. Update account ID in config (if needed)\nIf the account ID does not match, update it in config/environment.ts:\ndev: { account: \u0026#39;YOUR_ACTUAL_ACCOUNT_ID\u0026#39;, // Update here // ... other configs } Step 3: Review CDK App Structure 1. Review main CDK app file\ncode bin\\app.ts The file bin/app.ts is the entry point of the CDK application. Main content:\n#!/usr/bin/env node import * as cdk from \u0026#39;aws-cdk-lib\u0026#39;; import { getConfig } from \u0026#39;../config/environment\u0026#39;; const app = new cdk.App(); // Get environment from context (default: \u0026#39;dev\u0026#39;) const environment = app.node.tryGetContext(\u0026#39;environment\u0026#39;) || \u0026#39;dev\u0026#39;; const config = getConfig(environment); console.log(`🚀 Deploying Everyone Cook infrastructure for environment: ${environment}`); // Create stacks in dependency order const dnsStack = new DnsStack(app, `EveryoneCook-${environment}-DNS`, {...}); const certificateStack = new CertificateStack(app, `EveryoneCook-${environment}-Certificate`, {...}); const coreStack = new CoreStack(app, `EveryoneCook-${environment}-Core`, {...}); const authStack = new AuthStack(app, `EveryoneCook-${environment}-Auth`, {...}); const backendStack = new BackendStack(app, `EveryoneCook-${environment}-Backend`, {...}); const observabilityStack = new ObservabilityStack(app, `EveryoneCook-${environment}-Observability`, {...}); // Add dependencies certificateStack.addDependency(dnsStack); coreStack.addDependency(certificateStack); authStack.addDependency(coreStack); backendStack.addDependency(authStack); observabilityStack.addDependency(backendStack); // Add tags to all stacks cdk.Tags.of(app).add(\u0026#39;Project\u0026#39;, \u0026#39;EveryoneCook\u0026#39;); cdk.Tags.of(app).add(\u0026#39;Environment\u0026#39;, config.environment); cdk.Tags.of(app).add(\u0026#39;ManagedBy\u0026#39;, \u0026#39;CDK\u0026#39;); 2. Understand stack dependencies\nStacks are created in order and have explicit dependencies:\nCertificate Stack depends on DNS Stack Core Stack depends on Certificate Stack Auth Stack depends on Core Stack Backend Stack depends on Auth Stack Observability Stack depends on all other stacks Step 4: Validate Configuration 1. Compile TypeScript\n# Navigate to infrastructure directory cd D:\\Project_AWS\\everyonecook\\infrastructure # Compile TypeScript npm run build Successful output:\n\u0026gt; everyonecook-infrastructure@1.0.0 build \u0026gt; tsc # No errors - compilation successful 2. List all CDK stacks\n# List all stacks for dev environment npx cdk list --context environment=dev Output:\nEveryoneCook-dev-DNS EveryoneCook-dev-Certificate EveryoneCook-dev-Core EveryoneCook-dev-Auth EveryoneCook-dev-Backend EveryoneCook-dev-Observability 3. Synthesize CloudFormation templates\n# Generate CloudFormation templates npx cdk synth --context environment=dev Output:\nSuccessfully synthesized to D:\\Project_AWS\\everyonecook\\infrastructure\\cdk.out Supply a stack id (EveryoneCook-dev-DNS, EveryoneCook-dev-Certificate, ...) to display its template. The cdk.out/ folder is created with CloudFormation templates:\ncdk.out/ ├── EveryoneCook-dev-DNS.template.json ├── EveryoneCook-dev-Certificate.template.json ├── EveryoneCook-dev-Core.template.json ├── EveryoneCook-dev-Auth.template.json ├── EveryoneCook-dev-Backend.template.json └── EveryoneCook-dev-Observability.template.json Step 5: Review Stack Resources (Optional) If you want to see details of resources in each stack:\n1. DNS Stack Resources\n# View DNS stack template Get-Content cdk.out\\EveryoneCook-dev-DNS.template.json | ConvertFrom-Json | Select-Object -ExpandProperty Resources Resources:\nHostedZone: Route 53 Hosted Zone Outputs: Nameservers, Hosted Zone ID 2. Certificate Stack Resources\n# View Certificate stack template Get-Content cdk.out\\EveryoneCook-dev-Certificate.template.json | ConvertFrom-Json | Select-Object -ExpandProperty Resources Resources:\nCloudFrontCertificate: ACM Certificate for CloudFront (cdn.everyonecook.cloud) ApiGatewayCertificate: Wildcard ACM Certificate (*.everyonecook.cloud) ValidationRecords: Route 53 DNS validation records 3. Core Stack Resources\nResources (30+ resources):\nDynamoDB Table with 5 GSI indexes S3 Buckets (2 buckets: content, cdn-logs) CloudFront Distribution with OAC KMS Keys (2 keys: DynamoDB, S3) IAM Roles and Policies 4. Auth Stack Resources\nResources (20+ resources):\nCognito User Pool with password policy Cognito User Pool Client Lambda Functions (5 triggers) IAM Roles for Lambda functions 5. Backend Stack Resources\nResources (50+ resources):\nAPI Gateway REST API with custom domain Lambda Functions (6 modules + 1 worker) SQS Queues (4 queues + 4 DLQs) WAF Web ACL for API Gateway Lambda Layer (shared dependencies) IAM Roles and Policies 6. Observability Stack Resources\nResources (15+ resources):\nCloudWatch Dashboards (4 dashboards) CloudWatch Alarms (10+ alarms) Composite Alarm for overall health SNS Topic for notifications Step 6: Detailed Configuration for Each Stack To learn more about the configuration and resources of each stack, see the following sections:\n5.4.1 DNS Stack: Route 53 Hosted Zone configuration 5.4.2 Certificate Stack: ACM Certificates configuration 5.4.3 Core Stack: DynamoDB, S3, CloudFront configuration 5.4.4 Auth Stack: Cognito, Lambda Triggers configuration 5.4.5 Backend Stack: API Gateway, Lambda, SQS configuration 5.4.7 Observability Stack: CloudWatch, Alarms configuration Configuration Checklist Before deploying, check the following items:\nEnvironment Configuration\nAWS Account ID has been verified and updated in config/environment.ts Region is set correctly (ap-southeast-1 for dev) Domain names configured correctly Dependencies\nNode.js and npm have been installed AWS CLI has been configured with credentials AWS CDK CLI has been installed globally npm dependencies have been installed (npm install) Validation\nTypeScript compilation successful (npm run build) CDK list shows all 6 stacks CDK synth generates CloudFormation templates successfully No syntax errors in stack code Preparation for Deployment\nCDK bootstrap has been run (see 5.03 CDK Bootstrap) AWS account has sufficient permissions to create resources Domain has been registered (or ready to register) Next Steps After completing configuration and validation, continue to:\n5.05 Deploy Infrastructure - Deploy all stacks to AWS\nIn the next step, you will:\nDeploy DNS Stack and configure nameservers Deploy Certificate Stack and validate certificates Deploy Core Stack (DynamoDB, S3, CloudFront) Deploy Auth Stack (Cognito, Lambda Triggers) Deploy Backend Stack (API Gateway, Lambda Functions) Deploy Observability Stack (CloudWatch Dashboards) "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.4-week4/","title":"Week 4 Worklog","tags":[],"description":"","content":"Tasks to be carried out this week: Week 4 Objectives Understand Amazon S3 fundamentals and storage classes. Learn advanced S3 features: static hosting, versioning, Access Points, VPC Endpoints, Glacier. Explore AWS Snow Family for large-scale data migration. Understand Storage Gateway for hybrid storage setups. Learn DR strategies and use AWS Backup for automated backups. Practice through labs: S3, VM Import/Export, Storage Gateway, FSx, and S3 + CloudFront. Day Task Start Date Completion Date Reference Material 2 Amazon S3 (Simple Storage Service) 10/02/2025 10/02/2025 cont 3 Amazon S3 – Advanced Features 10/03/2025 10/03/2025 cont 4 AWS Snow Family\nAWS Storage Gateway\nDisaster Recovery on AWS\nAWS Backup 10/04/2025 10/04/2025 Snow Family - Storage Gateway - Backup 5 Lab\n(S3 \u0026amp; Backup)\nVM Import/Export\nStorage Gateway\nFSx (Windows File System)\nS3 Website \u0026amp; CloudFront 10/05/2025 10/05/2025 cont 6 Weekly Knowledge Summary 10/06/2025 10/06/2025 Week 4 Achievements: Amazon S3 (Simple Storage Service) 1. Concept Object storage (WORM: Write Once, Read Many). Update = overwrite entire object. 2. Key Features Unlimited storage, max 5TB/object. Replicated across 3 AZs → high availability. Durability: 11 nines, Availability: 4 nines. Multipart upload, event triggers (Lambda). 3. Bucket \u0026amp; Object Objects must be stored in buckets. Access via REST API (PUT, GET). Folders are logical only. 4. Access Control Use Access Points for multi-app access. Policies: Identity Policy + Resource Policy. 5. Storage Classes Standard → frequent access. Standard-IA → infrequent access. Intelligent-Tiering → auto-optimize cost. One Zone-IA → low-cost, single AZ. Glacier/Deep Archive → archival storage. 6. Lifecycle Management Auto transition objects between storage classes. Example: Standard → IA → Glacier. Amazon S3 – Advanced Features Static Website Hosting Host static sites/SPAs. Enable CORS for cross-domain access. Access Control Prefer IAM Policies over ACLs. Object \u0026amp; Scaling Flat structure, key-based. Auto-partition for scale → use random prefixes. VPC Endpoint Private traffic EC2 ↔ S3 (no Internet). Versioning Keep object history. Protects against accidental delete/overwrite. Glacier ~20x cheaper for archives. Retrieval takes minutes–hours. Object Lock = immutable storage. AWS Snow Family Snowball: ~80TB, transfer to S3/Glacier with Snowball Client. Snowball Edge: ~100TB, with local compute. Snowmobile: truck for PB–EB scale data. Use case: very large data, slow Internet, no Direct Connect. AWS Storage Gateway Hybrid storage: on-prem + AWS. File Gateway: NFS/SMB → S3 objects. Volume Gateway: block storage (Stored Volumes for DR, Cached Volumes for cost). Tape Gateway: virtual tape library → S3/Glacier. Disaster Recovery (DR) on AWS RTO = recovery time. RPO = acceptable data loss. DR Strategies: Backup \u0026amp; Restore (baseline). Pilot Light (Active-Standby). Warm Standby (low-capacity Active-Active). Multi-Site (full Active-Active). AWS Backup Centralized backup service for EC2, EBS, RDS, FSx, EFS. Features: scheduling, retention, monitoring. Important: retention config to control cost. LABS 🔹 Module 04 – Lab 13: S3 \u0026amp; Backup Lab13-02.1: Create S3 Bucket Lab13-02.2: Deploy Infrastructure Lab13-03: Create Backup Plan Lab13-04: Set up Notifications Lab13-05: Test Restore Lab13-06: Clean up Resources 🔹 Module 04 – Lab 14: VM Import/Export Lab14-01: VMware Workstation Lab14-02.1: Export VM from On-premises Lab14-02.2: Upload VM to AWS Lab14-02.3: Import VM to AWS Lab14-02.4: Deploy Instance from AMI Lab14-03.1: Setup S3 Bucket ACL Lab14-03.2: Export VM from Instance Lab14-05: Resource Cleanup 🔹 Module 04 – Lab 24: Storage Gateway Lab24-2.1: Create Storage Gateway Lab24-2.2: Create File Shares Lab24-2.3: Mount File Shares on On-prem Server Lab24-3: Clean up Resources 🔹 Module 04 – Lab 25: FSx (Windows File System) Lab25-2.2: Create SSD Multi-AZ File System Lab25-2.3: Create HDD Multi-AZ File System Lab25-3: Create New File Shares Lab25-4: Test Performance Lab25-5: Monitor Performance Lab25-6: Enable Data Deduplication Lab25-7: Enable Shadow Copies Lab25-8: Manage User Sessions \u0026amp; Open Files Lab25-9: Enable User Storage Quotas Lab25-11: Scale Throughput Capacity Lab25-12: Scale Storage Capacity Lab25-13: Delete Environment 🔹 Module 04 – Lab 57: S3 Website \u0026amp; CloudFront Lab57-2.1: Create S3 Bucket Lab57-2.2: Load Data Lab57-3: Enable Static Website Feature Lab57-4: Configure Public Access Lab57-5: Configure Public Objects Lab57-6: Test Website Lab57-7.1: Block All Public Access Lab57-7.2: Configure Amazon CloudFront Lab57-7.3: Test Amazon CloudFront Lab57-8: Bucket Versioning Lab57-9: Move Objects Lab57-10: Replication Object Multi-Region Lab57-11: Clean up Resources "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/4-eventparticipated/4.4-event4/","title":"Event 4","tags":[],"description":"","content":"Summary Report: \u0026ldquo;AWS Well-Architected Security Pillar Workshop\u0026rdquo; Event Objectives Understand the Security Pillar within the AWS Well-Architected Framework Learn the 5 core cloud security pillars with practical demonstrations Gain insights from real-world use cases and lessons learned from Vietnamese enterprises Event Information Event Name: AWS Well-Architected Security Pillar Workshop\nDate \u0026amp; Time: Friday, November 29, 2025 | 8:30 AM – 12:00 PM\nLocation: AWS Vietnam Office, Bitexco Financial Tower, 2 Hai Trieu St., District 1, HCMC\nRole: Attendee\nSpeakers Tran Toan Cong Ly – Opening \u0026amp; Security Foundations Hoang Anh – Modern IAM Architecture Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat – Continuous Monitoring \u0026amp; Threat Detection Hoang Kha – Securing Network \u0026amp; Workloads Thinh Lam, Viet Nguyen – Encryption, Key Management \u0026amp; Secrets Mende Grabski (Long), Tinh Truong – Playbooks \u0026amp; Automated Incident Response Agenda Time Topic Speaker 8:30 – 8:50 AM Opening \u0026amp; Security Foundations Tran Toan Cong Ly 8:50 – 9:30 AM Pillar 1: Identity \u0026amp; Access Management Hoang Anh 9:30 – 9:55 AM Pillar 2: Detection Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat 9:55 – 10:10 AM Coffee Break - 10:10 – 10:40 AM Pillar 3: Infrastructure Protection Hoang Kha 10:40 – 11:10 AM Pillar 4: Data Protection Thinh Lam, Viet Nguyen 11:10 – 11:40 AM Pillar 5: Incident Response Mende Grabski (Long), Tinh Truong 11:40 AM – 12:00 PM Wrap-Up \u0026amp; Q\u0026amp;A All Key Highlights Opening \u0026amp; Security Foundations (8:30 – 8:50 AM) Speaker: Tran Toan Cong Ly\nRole of the Security Pillar in the Well-Architected Framework Core principles: Least Privilege Zero Trust Defense in Depth The AWS Shared Responsibility Model Common security threats in the Vietnam cloud landscape Pillar 1 — Identity \u0026amp; Access Management (IAM) 8:50 – 9:30 AM — Modern IAM Architecture Speaker: Hoang Anh\nIAM Fundamentals Users, Roles, Policies – minimizing the use of long-term credentials IAM Identity Center: Single Sign-On (SSO) Managing permission sets Service Control Policies (SCPs) \u0026amp; permission boundaries in multi-account setups MFA, credential rotation, and using Access Analyzer Mini Demo Validate and test IAM policies Simulate different access scenarios Pillar 2 — Detection 9:30 – 9:55 AM — Continuous Monitoring \u0026amp; Threat Detection Speakers: Tran Duc Anh, Nguyen Tuan Thinh, Nguyen Do Thanh Dat\nKey Monitoring Services AWS CloudTrail: organization-level auditing and logging Amazon GuardDuty: intelligent threat detection AWS Security Hub: consolidated and normalized security findings End-to-End Logging VPC Flow Logs ALB and S3 access logs Alerts and automated workflows using EventBridge Implementing Detection-as-Code (infrastructure + detection rules) Pillar 3 — Infrastructure Protection 10:10 – 10:40 AM — Securing Network \u0026amp; Workloads Speaker: Hoang Kha\nNetwork Security VPC segmentation strategies Proper design of public and private subnets Practical use of Security Groups vs NACLs Protection Services AWS WAF (Web Application Firewall) AWS Shield (DDoS protection) AWS Network Firewall Workload Protection Foundational security best practices for EC2 Container security on ECS/EKS Pillar 4 — Data Protection 10:40 – 11:10 AM — Encryption, Key Management \u0026amp; Secrets Speakers: Thinh Lam, Viet Nguyen\nKey Management AWS KMS: key policies, grants, key rotation Encryption at rest for: S3, EBS, RDS, DynamoDB Encryption in transit using TLS/SSL Secrets Management AWS Secrets Manager AWS Systems Manager Parameter Store Recommended patterns and best practices for rotating secrets Data Governance Designing data classification strategies Defining guardrails and access policies Pillar 5 — Incident Response 11:10 – 11:40 AM — Playbooks \u0026amp; Automated Incident Response Speakers: Mende Grabski (Long), Tinh Truong\nIncident Response Lifecycle Preparation Detection \u0026amp; Analysis Containment Eradication \u0026amp; Recovery Post-Incident Review and improvement Sample IR Playbooks Responding to compromised IAM access keys Remediating unintended public S3 bucket exposure Handling malware detection on EC2 instances Automation Automated snapshots and evidence collection Standardized instance isolation workflows Auto-response patterns using Lambda / Step Functions Wrap-Up \u0026amp; Q\u0026amp;A (11:40 AM – 12:00 PM) Recap of the 5 Security Pillars Identity \u0026amp; Access Management Detection Infrastructure Protection Data Protection Incident Response Common Pitfalls Typical security gaps in Vietnamese organizations Case studies and key lessons from real incidents Learning Path \u0026amp; Next Steps AWS Certified Security – Specialty AWS Certified Solutions Architect – Professional Ongoing learning resources and channels for AWS security Key Takeaways Security Foundations Cloud security follows a shared responsibility between AWS and customers Architect solutions using defense in depth across multiple layers Embrace a Zero Trust mindset: Do not trust by default Grant only the minimum required access Operate under an \u0026ldquo;assume breach\u0026rdquo; model IAM Practices Avoid long-term access keys; prefer temporary credentials Enforce MFA for all human users Use IAM roles for applications and services Perform regular permission reviews with Access Analyzer Monitoring \u0026amp; Detection Enable CloudTrail at the organization level from day one Turn on GuardDuty for continuous threat monitoring Use Security Hub as the central view of security findings Automate security event handling wherever possible Infrastructure Protection Design VPCs with clear segmentation by zone, application, or sensitivity level Use Security Groups as the primary network firewall Protect web-facing workloads with AWS WAF Choose appropriate protection tools for each workload type Data Protection Always encrypt data at rest and in transit Rely on KMS for centralized key management and auditing Rotate secrets regularly via Secrets Manager Classify data and enforce matching access policies Incident Response Build and maintain IR playbooks before incidents occur Automate key steps like isolation and evidence gathering Regularly rehearse incident response processes Treat every incident as input to improve architecture and procedures Vietnamese Enterprise Context Challenges specific to Vietnam: skills, budget, and security awareness Compliance drivers (such as PDPA and local regulations) Strategies to implement strong AWS security in a cost-effective way Event Experience Participating in the \u0026ldquo;AWS Well-Architected Security Pillar Workshop\u0026rdquo; was an invaluable experience that provided a comprehensive understanding of cloud security best practices. The workshop covered all five security pillars with practical demonstrations and real-world examples from Vietnamese enterprises.\nThe hands-on demos and case studies made the concepts tangible and immediately applicable to real projects. Learning about the shared responsibility model and defense-in-depth strategies will significantly improve how I approach security in cloud architectures.\nEvent Photos "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/4-eventparticipated/","title":"Events Participated","tags":[],"description":"","content":"During my internship, I had the opportunity to participate in two valuable AWS workshops. Each event provided hands-on learning experiences, industry insights, and practical knowledge that enhanced my understanding of cloud technologies.\nEvent 1: AI/ML, GenAI \u0026amp; Amazon Bedrock on AWS Event Name: AI/ML, GenAI \u0026amp; Amazon Bedrock Workshop\nDate \u0026amp; Time: October 2025\nLocation: AWS Office, Ho Chi Minh City\nRole: Attendee\nSummary:\nThis workshop provided a comprehensive overview of the modern AI stack on AWS, covering everything from traditional machine learning to Foundation Models. Key topics included:\nEmbeddings \u0026amp; RAG: Understanding vector representations and Retrieval-Augmented Generation pipelines Prompt Engineering: Techniques like zero-shot, few-shot, and chain-of-thought prompting Amazon Bedrock Agents: Agent Core orchestration, Browser Tool for real-time web access AWS AI Services: Rekognition, Textract, Transcribe, Translate, Polly, Comprehend Key Takeaways:\nGenAI is a full system architecture, not just a single model RAG + Embeddings form the foundation for enterprise GenAI solutions Better prompts lead to better AI outcomes Event 2: DevOps on AWS Event Name: DevOps on AWS Workshop\nDate \u0026amp; Time: November 2025\nLocation: AWS Office, Ho Chi Minh City\nRole: Attendee\nSummary:\nThis workshop focused on modern DevOps practices and Infrastructure as Code (IaC) on AWS. The sessions covered:\nInfrastructure as Code: Benefits of automation, scalability, and reproducibility AWS CloudFormation: YAML/JSON templates, stacks, drift detection AWS CDK: Programming-based IaC with construct levels (L1, L2, L3) Docker \u0026amp; Containers: Dockerfile workflows, image management AWS Container Services: ECR, ECS, EKS, and App Runner Key Takeaways:\nIaC eliminates manual configuration drift and human errors CDK enables faster development with reusable patterns ECS is ideal for simplicity; EKS for full Kubernetes capabilities App Runner provides quick deployment with minimal DevOps overhead Event 3: AI-Driven Development Life Cycle Event Name: AI-Driven Development Life Cycle\nDate \u0026amp; Time: Friday, October 3, 2024 | 2:00 PM – 4:30 PM\nLocation: AWS Event Hall, L26 Bitexco Tower, HCMC\nRole: Attendee\nSummary:\nThis workshop explored how generative AI transforms the software development lifecycle through Amazon Q Developer and Kiro AI Assistant. Key topics included:\nAmazon Q Developer: Code generation, debugging assistance, AWS integration Kiro AI Assistant: Intelligent code completion, multi-file understanding, automated refactoring Productivity Gains: 40% faster code writing, 60% less boilerplate, 50% less documentation time Key Takeaways:\nAI transforms every phase of the development lifecycle Amazon Q Developer is powerful for AWS-centric development Kiro excels at project-level understanding and multi-file operations Event 4: AWS Well-Architected Security Pillar Workshop Event Name: AWS Well-Architected Security Pillar Workshop\nDate \u0026amp; Time: Friday, November 29, 2025 | 8:30 AM – 12:00 PM\nLocation: AWS Vietnam Office, Bitexco Financial Tower, District 1, HCMC\nRole: Attendee\nSummary:\nThis workshop focused on the Security Pillar within the AWS Well-Architected Framework, covering the 5 core security pillars with practical demonstrations. Key topics included:\nIdentity \u0026amp; Access Management: IAM best practices, SSO, MFA, Access Analyzer Detection: CloudTrail, GuardDuty, Security Hub, VPC Flow Logs Infrastructure Protection: VPC segmentation, WAF, Shield, Network Firewall Data Protection: KMS, encryption at rest/in transit, Secrets Manager Incident Response: IR playbooks, automated response with Lambda/Step Functions Key Takeaways:\nCloud security follows a shared responsibility model Architect solutions using defense in depth across multiple layers Build IR playbooks before incidents occur and automate response Value Gained Participating in these events helped me:\nUnderstand the AWS AI/ML ecosystem and GenAI capabilities Learn Infrastructure as Code best practices with CloudFormation and CDK Gain practical knowledge of container orchestration services Network with AWS Community Builders and industry professionals Apply modern cloud practices to real-world projects "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.4-auth-stack/","title":"5.4.4 Auth Stack","tags":[],"description":"","content":" Auth Stack - Authentication \u0026amp; User Management Overview The Auth Stack is the Phase 3 authentication layer of the EveryoneCook project. It manages user authentication, registration, and account security using AWS Cognito with custom Lambda triggers for enhanced user experience.\nDeployment Order: This stack MUST be deployed after Core Stack and before Backend Stack.\nKey Responsibilities Create Cognito User Pool with production-grade security settings Configure Cognito User Pool Client for web application Setup 5 Lambda triggers for custom authentication workflows Manage user registration, email verification, and login flows Handle user profile creation in DynamoDB (via PostConfirmation trigger) What This Stack Includes Cognito User Pool:\nSign-in: Username or email Password policy: Min 12 chars (8 for dev), uppercase, lowercase, digits, symbols Email verification required MFA: Disabled (email + password only) Device tracking: Enabled (no MFA challenge) Standard attributes: username, email, given_name (fullName) Custom attributes: account_status, country Cognito User Pool Client:\nAuth flows: USER_PASSWORD_AUTH, USER_SRP_AUTH OAuth flows: Authorization code grant (future social login) Token validity: Access/ID (1h), Refresh (30 days) Callback URLs: Environment-specific Lambda Triggers (5 triggers):\nPreSignUp: Cleanup unverified users (24h expiration) CustomMessage: Customize email templates PostConfirmation: Create user profile in DynamoDB PreAuthentication: Check if user is banned/suspended PostAuthentication: Update last login timestamp Architecture ┌─────────────────────────────────────────────────────────────────┐ │ Auth Stack (Phase 3) │ │ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Cognito User Pool │ │ │ │ ├─ Sign-in: Username or Email │ │ │ │ ├─ Password: Min 12 chars, strong policy │ │ │ │ ├─ Email Verification: Required │ │ │ │ ├─ MFA: Disabled (email + password only) │ │ │ │ ├─ Device Tracking: Enabled (no MFA) │ │ │ │ └─ Custom Attributes: account_status, country │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Lambda Triggers (Custom Workflows) │ │ │ │ │ │ │ │ 1️⃣ PreSignUp │ │ │ │ ├─ Check existing username/email │ │ │ │ ├─ Delete expired unverified users (\u0026gt;24h) │ │ │ │ └─ Allow new registration │ │ │ │ │ │ │ │ 2️⃣ CustomMessage │ │ │ │ ├─ Customize email verification template │ │ │ │ ├─ Customize password reset template │ │ │ │ └─ Add styling and branding │ │ │ │ │ │ │ │ 3️⃣ PostConfirmation │ │ │ │ ├─ Create DynamoDB entities: │ │ │ │ │ ├─ Core Profile (PK=USER#{userId}, SK=PROFILE) │ │ │ │ │ ├─ Privacy Settings (SK=PRIVACY_SETTINGS) │ │ │ │ │ └─ AI Preferences (SK=AI_PREFERENCES) │ │ │ │ └─ Initialize user data │ │ │ │ │ │ │ │ 4️⃣ PreAuthentication │ │ │ │ ├─ Check user account status │ │ │ │ ├─ Reject if banned/suspended │ │ │ │ └─ Allow login if active │ │ │ │ │ │ │ │ 5️⃣ PostAuthentication │ │ │ │ ├─ Update lastLoginAt timestamp │ │ │ │ └─ Track user activity │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Cognito User Pool Client │ │ │ │ ├─ Client Type: Web (no secret) │ │ │ │ ├─ Auth Flows: Password, SRP │ │ │ │ ├─ OAuth: Authorization code grant │ │ │ │ ├─ Tokens: 1h access, 1h ID, 30d refresh │ │ │ │ ├─ Callback: https://{env}.everyonecook.cloud │ │ │ │ └─ Security: Token revocation, user enum protection │ │ │ └──────────────────────────────────────────────────────────┘ │ └─────────────────────────────────────────────────────────────────┘ │ │ Exports ▼ Backend Stack (API Gateway Cognito Authorizer) Stack Configuration File Structure infrastructure/lib/stacks/ └── auth-stack.ts # Auth Stack (865 lines) services/auth-module/triggers/ ├── pre-signup.ts # PreSignUp trigger ├── custom-message.ts # CustomMessage trigger ├── post-confirmation.ts # PostConfirmation trigger ├── pre-authentication.ts # PreAuthentication trigger └── post-authentication.ts # PostAuthentication trigger Code Implementation Highlights File: infrastructure/lib/stacks/auth-stack.ts\n1. Cognito User Pool Creation /** * Create Cognito User Pool with production-grade security */ private createUserPool(): cdk.aws_cognito.UserPool { const cognitoConfig = this.config.cognito; const userPool = new cdk.aws_cognito.UserPool(this, \u0026#39;UserPool\u0026#39;, { userPoolName: `EveryoneCook-${this.config.environment}`, // Sign-in configuration signInAliases: { username: true, email: true, }, // Self sign-up enabled selfSignUpEnabled: true, // Standard attributes standardAttributes: { email: { required: true, mutable: false, // Email cannot be changed }, givenName: { required: true, // fullName stored in given_name mutable: true, }, birthdate: { required: false, mutable: true }, gender: { required: false, mutable: true }, }, // Custom attributes customAttributes: { account_status: new cdk.aws_cognito.StringAttribute({ mutable: true, minLen: 1, maxLen: 20, }), country: new cdk.aws_cognito.StringAttribute({ mutable: true, minLen: 2, maxLen: 2, // ISO 3166-1 alpha-2 }), }, // Password policy passwordPolicy: { minLength: 12, // 8 for dev requireLowercase: true, requireUppercase: true, requireDigits: true, requireSymbols: true, tempPasswordValidity: cdk.Duration.days(7), }, // Account recovery accountRecovery: cdk.aws_cognito.AccountRecovery.EMAIL_ONLY, // Email configuration (Cognito default) email: cdk.aws_cognito.UserPoolEmail.withCognito(), // Auto-verify email autoVerify: { email: true }, // MFA: Disabled mfa: cdk.aws_cognito.Mfa.OFF, // Device tracking (no MFA challenge) deviceTracking: { challengeRequiredOnNewDevice: false, deviceOnlyRememberedOnUserPrompt: true, }, // Email templates userVerification: { emailSubject: \u0026#39;🍳 Verify your Everyone Cook account\u0026#39;, emailBody: \u0026#39;Hello {username}, your verification code is: {####}\u0026#39;, emailStyle: cdk.aws_cognito.VerificationEmailStyle.CODE, }, // Deletion protection for production deletionProtection: this.config.environment === \u0026#39;prod\u0026#39;, }); return userPool; } 2. Lambda Triggers /** * Create PostConfirmation Lambda Trigger * * Creates 3 DynamoDB entities after email verification: * 1. Core Profile (PK=USER#{userId}, SK=PROFILE) * 2. Privacy Settings (SK=PRIVACY_SETTINGS) * 3. AI Preferences (SK=AI_PREFERENCES) */ private createPostConfirmationTrigger( dynamoTable: cdk.aws_dynamodb.ITable ): cdk.aws_lambda.Function { const trigger = new cdk.aws_lambda.Function(this, \u0026#39;PostConfirmationTrigger\u0026#39;, { functionName: `EveryoneCook-${this.config.environment}-PostConfirmation`, runtime: cdk.aws_lambda.Runtime.NODEJS_20_X, handler: \u0026#39;post-confirmation.handler\u0026#39;, code: cdk.aws_lambda.Code.fromAsset( path.join(__dirname, \u0026#39;../../../services/auth-module/triggers/dist\u0026#39;) ), memorySize: 512, timeout: cdk.Duration.seconds(30), environment: { DYNAMODB_TABLE_NAME: dynamoTable.tableName, ENVIRONMENT: this.config.environment, }, }); // Grant DynamoDB write permissions dynamoTable.grantReadWriteData(trigger); return trigger; } /** * Create PreSignUp Lambda Trigger * * Handles cleanup of unverified users: * - If user exists and UNCONFIRMED \u0026gt;24h → delete and allow new signup * - If user exists and UNCONFIRMED \u0026lt;24h → reject with \u0026#34;wait 24h\u0026#34; message * - If user doesn\u0026#39;t exist → allow signup */ private createPreSignUpTrigger(): cdk.aws_lambda.Function { const trigger = new cdk.aws_lambda.Function(this, \u0026#39;PreSignUpTrigger\u0026#39;, { functionName: `EveryoneCook-${this.config.environment}-PreSignUp`, runtime: cdk.aws_lambda.Runtime.NODEJS_20_X, handler: \u0026#39;pre-signup.handler\u0026#39;, code: cdk.aws_lambda.Code.fromAsset( path.join(__dirname, \u0026#39;../../../services/auth-module/triggers/dist\u0026#39;) ), memorySize: 256, timeout: cdk.Duration.seconds(10), }); // Grant Cognito permissions trigger.addToRolePolicy( new cdk.aws_iam.PolicyStatement({ effect: cdk.aws_iam.Effect.ALLOW, actions: [\u0026#39;cognito-idp:ListUsers\u0026#39;, \u0026#39;cognito-idp:AdminDeleteUser\u0026#39;], resources: [`arn:aws:cognito-idp:${this.region}:${this.account}:userpool/*`], }) ); return trigger; } 3. User Pool Client /** * Create Cognito User Pool Client for web application */ private createUserPoolClient(): cdk.aws_cognito.UserPoolClient { const callbackUrls = this.getCallbackUrls(); const logoutUrls = this.getLogoutUrls(); const userPoolClient = new cdk.aws_cognito.UserPoolClient( this, \u0026#39;UserPoolClient\u0026#39;, { userPoolClientName: `EveryoneCook-Web-Client-${this.config.environment}`, userPool: this.userPool, // Auth flows authFlows: { userPassword: true, // USER_PASSWORD_AUTH userSrp: true, // USER_SRP_AUTH (Secure Remote Password) custom: false, adminUserPassword: false, }, // OAuth configuration (future social login) oAuth: { flows: { authorizationCodeGrant: true, implicitCodeGrant: false, clientCredentials: false, }, scopes: [ cdk.aws_cognito.OAuthScope.EMAIL, cdk.aws_cognito.OAuthScope.OPENID, cdk.aws_cognito.OAuthScope.PROFILE, ], callbackUrls: callbackUrls, logoutUrls: logoutUrls, }, // Token validity accessTokenValidity: cdk.Duration.hours(1), idTokenValidity: cdk.Duration.hours(1), refreshTokenValidity: cdk.Duration.days(30), // Read attributes readAttributes: new cdk.aws_cognito.ClientAttributes() .withStandardAttributes({ email: true, emailVerified: true, givenName: true, }) .withCustomAttributes(\u0026#39;account_status\u0026#39;, \u0026#39;country\u0026#39;), // Security settings preventUserExistenceErrors: true, // Prevent enumeration attacks enableTokenRevocation: true, // Allow token revocation generateSecret: false, // No secret for web apps } ); return userPoolClient; } Key Configuration Details 1. User Registration Flow Registration Process:\n1. User signs up → PreSignUp trigger ├─ Check if username/email exists ├─ If UNCONFIRMED \u0026gt;24h: Delete old user ├─ If UNCONFIRMED \u0026lt;24h: Reject with \u0026#34;wait 24h\u0026#34; └─ Allow registration 2. User receives verification email → CustomMessage trigger ├─ Customize email template └─ Send verification code 3. User verifies email → PostConfirmation trigger ├─ Create DynamoDB entities: │ ├─ Core Profile (username, email, fullName, etc.) │ ├─ Privacy Settings (default: private) │ └─ AI Preferences (default settings) └─ User account ready 4. User logs in → PreAuthentication trigger ├─ Check account_status ├─ If banned/suspended: Reject login └─ Allow login 5. Login successful → PostAuthentication trigger └─ Update lastLoginAt timestamp 2. Password Policy Environments:\nEnvironment Min Length Requirements Dev 8 chars Uppercase, lowercase, digits, symbols Staging 12 chars Uppercase, lowercase, digits, symbols Prod 12 chars Uppercase, lowercase, digits, symbols Example Valid Passwords:\nMyP@ssw0rd123 (12 chars) Str0ng!Pass (11 chars, invalid for prod/staging) 3. Token Validity Token Type Validity Purpose Access Token 1 hour API authorization ID Token 1 hour User identity claims Refresh Token 30 days Renew access/ID tokens Token Refresh Flow:\nAccess token expires (1h) → Use refresh token → Get new access/ID tokens Refresh token expires (30d) → User must login again 4. Lambda Trigger Details PreSignUp Trigger Purpose: Prevent \u0026ldquo;username already taken\u0026rdquo; errors for unverified users\nLogic:\nif (userExists \u0026amp;\u0026amp; userStatus === \u0026#39;UNCONFIRMED\u0026#39;) { const hoursSinceCreation = (now - userCreationDate) / (1000 * 60 * 60); if (hoursSinceCreation \u0026gt; 24) { // Delete expired unverified user await deleteUser(username); return allowSignUp(); } else { // User still has time to verify return rejectSignUp(`Please wait ${24 - hoursSinceCreation}h to register again`); } } else { return allowSignUp(); } PostConfirmation Trigger DynamoDB Entities Created:\n// 1. Core Profile { PK: \u0026#34;USER#{userId}\u0026#34;, SK: \u0026#34;PROFILE\u0026#34;, username: \u0026#34;john_doe\u0026#34;, email: \u0026#34;john@example.com\u0026#34;, fullName: \u0026#34;John Doe\u0026#34;, account_status: \u0026#34;active\u0026#34;, createdAt: \u0026#34;2025-01-01T00:00:00Z\u0026#34;, // ... other fields } // 2. Privacy Settings { PK: \u0026#34;USER#{userId}\u0026#34;, SK: \u0026#34;PRIVACY_SETTINGS\u0026#34;, profileVisibility: \u0026#34;private\u0026#34;, showEmail: false, allowMessages: \u0026#34;friends\u0026#34;, // ... other settings } // 3. AI Preferences { PK: \u0026#34;USER#{userId}\u0026#34;, SK: \u0026#34;AI_PREFERENCES\u0026#34;, aiEnabled: true, preferredLanguage: \u0026#34;en\u0026#34;, dietaryRestrictions: [], // ... other preferences } Stack Outputs After deployment, the stack exports the following values:\nOutput Name Value Used By UserPoolId ap-southeast-1_XXXXXXXXX Backend Stack (Authorizer) UserPoolArn arn:aws:cognito-idp:... Lambda IAM policies UserPoolClientId 1234567890abcdef Frontend (Amplify config) CustomMessageFunctionArn arn:aws:lambda:... Monitoring PostConfirmationFunctionArn arn:aws:lambda:... Monitoring PreAuthenticationFunctionArn arn:aws:lambda:... Monitoring PostAuthenticationFunctionArn arn:aws:lambda:... Monitoring Deployment Steps Step 1: Build Lambda Triggers Before deploying, compile Lambda triggers to JavaScript:\ncd D:\\Project_AWS\\everyonecook\\services\\auth-module\\triggers # Install dependencies npm install # Build TypeScript to JavaScript npm run build Expected output:\n\u0026gt; auth-module-triggers@1.0.0 build \u0026gt; tsc Compiled successfully to dist/ Step 2: Verify Prerequisites Core Stack successfully deployed DynamoDB table exists Lambda triggers built to dist/ folder Step 3: Deploy Auth Stack Navigate to infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Deploy Auth Stack to ap-southeast-1:\n# Deploy Auth Stack npx cdk deploy EveryoneCook-dev-Auth --context environment=dev Expected output:\n✨ Synthesis time: 7.23s EveryoneCook-dev-Auth: deploying... [████████████████████████████████████████] (9/9) EveryoneCook-dev-Auth: creating CloudFormation changeset... EveryoneCook-dev-Auth ✨ Deployment time: 180.45s Outputs: EveryoneCook-dev-Auth.UserPoolId = ap-southeast-1_a1B2c3D4e EveryoneCook-dev-Auth.UserPoolClientId = 1a2b3c4d5e6f7g8h9i0j EveryoneCook-dev-Auth.UserPoolArn = arn:aws:cognito-idp:ap-southeast-1:616580903213:userpool/... EveryoneCook-dev-Auth.PostConfirmationFunctionArn = arn:aws:lambda:ap-southeast-1:... EveryoneCook-dev-Auth.PreAuthenticationFunctionArn = arn:aws:lambda:ap-southeast-1:... Stack ARN: arn:aws:cloudformation:ap-southeast-1:616580903213:stack/EveryoneCook-dev-Auth/... Step 4: Verify in AWS Console Navigate to Cognito User Pool Open AWS Console → ap-southeast-1 region Go to Amazon Cognito \u0026gt; User pools Find EveryoneCook-dev Cognito User Pool showing sign-in options (username/email), MFA disabled, password policy, and deletion protection\nVerify:\nSign-in: Username or Email MFA: Disabled Password policy: Configured Email verification: Required Verify User Pool Configuration Click on the User Pool to view details:\nUser Pool configuration showing authentication settings, attributes, password policy, and security features\nCheck:\nSign-in experience: Username and Email enabled User attributes: email, given_name (required), birthdate, gender (optional) Custom attributes: account_status, country Password policy: Min 12 chars, requires uppercase, lowercase, digits, symbols MFA: Off Device tracking: Enabled Verify Lambda Triggers Go to User pool properties \u0026gt; Lambda triggers:\nLambda triggers configured for Pre sign-up, Custom message, Post confirmation, Pre authentication, and Post authentication\nVerify 5 triggers:\nPre sign-up: EveryoneCook-dev-PreSignUp Custom message: EveryoneCook-dev-CustomMessage Post confirmation: EveryoneCook-dev-PostConfirmation Pre authentication: EveryoneCook-dev-PreAuthentication Post authentication: EveryoneCook-dev-PostAuthentication Verify User Pool Client Go to App integration \u0026gt; App clients:\nUser Pool Client showing auth flows, OAuth settings, token validity, callback URLs, and security settings\nVerify:\nClient type: Public (no secret) Auth flows: USER_PASSWORD_AUTH, USER_SRP_AUTH OAuth flows: Authorization code grant Callback URLs: Environment-specific Token validity: 1h access, 1h ID, 30d refresh Navigate to Lambda Functions Go to Lambda \u0026gt; Functions, find Auth triggers:\nLambda functions showing all 5 Cognito triggers with runtime Node.js 20.x, memory 256-512 MB, and timeout 10-30s\nVerify:\nAll 5 Lambda functions created Runtime: Node.js 20.x Environment variables configured CloudWatch log groups created Check Lambda Permissions Click on a Lambda function → Configuration \u0026gt; Permissions:\nLambda execution role showing permissions for DynamoDB (PostConfirmation), Cognito (PreSignUp), and CloudWatch Logs\nExpected permissions:\nPostConfirmation: DynamoDB read/write PreAuthentication: DynamoDB read PostAuthentication: DynamoDB read/write PreSignUp: Cognito ListUsers, AdminDeleteUser All triggers: CloudWatch Logs write Cost Breakdown Monthly Costs (Dev Environment) Resource Configuration Monthly Cost Notes Cognito User Pool \u0026lt;50 MAU $0 First 50K MAU free Lambda Triggers 5 functions, low invocations $0-1 Free tier covers most CloudWatch Logs 7-day retention, 5 log groups $0.50 ~1GB logs Total (Estimated) ~$0.50-1.50/month Very low for dev Cost Notes Cognito: First 50,000 MAU free, then $0.0055/MAU Lambda: 1M requests/month free, then $0.20 per 1M CloudWatch Logs: $0.50/GB ingested, $0.03/GB stored No MFA charges: MFA disabled saves $0.05/MAU Production Estimate (1000 MAU):\nCognito: 1000 MAU × $0.0055 = $5.50/month Lambda triggers: ~5000 invocations/month = $0 (free tier) CloudWatch Logs: $1-2/month Total: ~$7-8/month Cross-Stack Dependencies Imports from Previous Stacks From Core Stack:\ndynamoTable: cdk.Fn.importValue(\u0026#39;EveryoneCook-dev-DynamoDBTableName\u0026#39;) Exports Used By Other Stacks Backend Stack imports:\nUser Pool ID (for Cognito Authorizer) User Pool ARN (for API Gateway) User Pool Client ID (for frontend config) Dependency Flow Core Stack → DynamoDB Table │ ▼ Auth Stack (creates Cognito + Lambda triggers) │ ├─► User Pool ID → Backend Stack (API Gateway Authorizer) ├─► User Pool Client ID → Frontend (Amplify config) └─► Lambda triggers → User management workflows Validation Checklist Before proceeding to Backend Stack deployment:\nAuth Stack successfully deployed to ap-southeast-1 Cognito User Pool exists with correct settings 5 Lambda triggers configured and attached User Pool Client created with OAuth settings Lambda functions have correct IAM permissions CloudWatch log groups created (7-day retention) Stack outputs exported successfully Lambda trigger code built to dist/ folder Testing Test User Registration Flow Test sign-up with Cognito console:\nGo to Cognito \u0026gt; User pools \u0026gt; EveryoneCook-dev \u0026gt; Users \u0026gt; Create user\nCreate a test user:\nUsername: testuser01 Email: your-email@example.com Full Name: Test User Temporary Password: TempP@ss123 Verify email sent:\nCheck your email for verification code.\nCheck Lambda logs:\n# View PostConfirmation logs aws logs tail /aws/lambda/EveryoneCook-dev-PostConfirmation --follow --region ap-southeast-1 Verify DynamoDB entries:\n# Query user profile aws dynamodb query \\ --table-name EveryoneCook-dev-v2 \\ --key-condition-expression \u0026#34;PK = :pk\u0026#34; \\ --expression-attribute-values \u0026#39;{\u0026#34;:pk\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;USER#testuser01\u0026#34;}}\u0026#39; \\ --region ap-southeast-1 Expected: 3 items (PROFILE, PRIVACY_SETTINGS, AI_PREFERENCES)\nTest Authentication Flow Login with test user:\nUse AWS CLI to authenticate:\naws cognito-idp initiate-auth \\ --auth-flow USER_PASSWORD_AUTH \\ --client-id \u0026lt;USER_POOL_CLIENT_ID\u0026gt; \\ --auth-parameters USERNAME=testuser01,PASSWORD=\u0026lt;password\u0026gt; \\ --region ap-southeast-1 Check PreAuthentication logs:\naws logs tail /aws/lambda/EveryoneCook-dev-PreAuthentication --follow --region ap-southeast-1 Check PostAuthentication logs:\naws logs tail /aws/lambda/EveryoneCook-dev-PostAuthentication --follow --region ap-southeast-1 Test PreSignUp Cleanup Create unverified user:\nSign up a user but don\u0026rsquo;t verify email.\nWait 24 hours (or modify trigger code to 1 minute for testing)\nTry to sign up again with same username:\nPreSignUp trigger should delete old user and allow new signup.\nNext Steps After successfully deploying the Auth Stack:\n➡️ 5.4.5 Backend Stack - Create API Gateway, Lambda functions, and SQS queues\nThe Backend Stack will:\nCreate API Gateway REST API with Cognito Authorizer Create 5 Lambda functions (auth, social, recipe, AI, admin) Create 6 SQS queues for async processing Create 6 worker Lambda functions Import User Pool ID from Auth Stack Configure API Gateway custom domain References Source Code: infrastructure/lib/stacks/auth-stack.ts Lambda Triggers: services/auth-module/triggers/ Base Stack: infrastructure/lib/base-stack.ts Environment Config: infrastructure/config/environment.ts AWS Documentation: Cognito User Pools Cognito Lambda Triggers Cognito User Pool Client Password Policies "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.05-deploy-infrastructure/","title":"Deploy Infrastructure","tags":[],"description":"","content":"Overview In this step, you will deploy all infrastructure stacks to AWS in the correct dependency order. The EveryoneCook project uses a 5-Stack Architecture with AWS CDK.\n5-Stack Architecture Phase 1: DNS Stack → Route 53 Hosted Zone Phase 1.5: Certificate Stack → ACM Certificates (us-east-1) Phase 2: Core Stack → DynamoDB, S3, CloudFront, KMS Phase 3: Auth Stack → Cognito, SES, Lambda Triggers Phase 4: Backend Stack → API Gateway, Lambda, SQS, WAF Phase 5: Observability Stack → CloudWatch Dashboards \u0026amp; Alarms Stack Dependencies DNS Stack (no dependencies) ↓ Certificate Stack (depends on DNS) ↓ Core Stack (depends on Certificate) ↓ Auth Stack (depends on Core) ↓ Backend Stack (depends on Auth, Core) ↓ Observability Stack (depends on Backend) Deployment Timeline Stack Time Critical Resources DNS Stack 2-3 min Route 53 Hosted Zone Certificate Stack 5-10 min ACM Certificate (DNS validation) Core Stack 10-15 min CloudFront Distribution, DynamoDB Auth Stack 5-7 min Cognito User Pool, SES Backend Stack 8-12 min API Gateway, 7 Lambda Functions Observability Stack 3-5 min CloudWatch Dashboards Total deployment time: 35-50 minutes\nPrerequisites 1. Verify AWS Credentials # Check AWS credentials aws sts get-caller-identity # Expected output: # { # \u0026#34;UserId\u0026#34;: \u0026#34;...\u0026#34;, # \u0026#34;Account\u0026#34;: \u0026#34;616580903213\u0026#34;, # \u0026#34;Arn\u0026#34;: \u0026#34;arn:aws:iam::616580903213:user/your-username\u0026#34; # } 2. Verify Node.js \u0026amp; CDK # Check Node.js version (must be 20.x+) node -v # v20.11.0 or higher # Check CDK version cdk --version # 2.114.0 or higher 3. Navigate to Infrastructure # Navigate to infrastructure directory cd D:\\Project_AWS\\everyonecook\\infrastructure # Verify cdk.json exists Get-Item cdk.json Phase 1: Deploy DNS Stack (Route 53) DNS Stack creates Route 53 Hosted Zone for domain everyonecook.cloud. This is the first and most important stack.\nStep 1.1: Deploy DNS Stack # Deploy DNS Stack npx cdk deploy EveryoneCook-dev-DNS --context environment=dev # Review changes # Type \u0026#39;y\u0026#39; to confirm Expected output:\n✅ EveryoneCook-dev-DNS Outputs: EveryoneCook-dev-DNS.HostedZoneId = Z018823421GWCSYG5UMHV EveryoneCook-dev-DNS.HostedZoneName = everyonecook.cloud EveryoneCook-dev-DNS.NameServers = ns-1164.awsdns-17.org, ns-825.awsdns-39.net, ns-1889.awsdns-44.co.uk, ns-453.awsdns-56.com Stack ARN: arn:aws:cloudformation:ap-southeast-1:616580903213:stack/EveryoneCook-dev-DNS/... Step 1.2: Save Nameservers IMPORTANT NOTE: Save the 4 nameservers from the output!\n# Get nameservers $nameservers = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-DNS ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`NameServers`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;Nameservers: $nameservers\u0026#34; # ns-1164.awsdns-17.org, ns-825.awsdns-39.net, ns-1889.awsdns-44.co.uk, ns-453.awsdns-56.com Step 1.3: Update Domain Registrar Update nameservers at your domain registrar (Hostinger, GoDaddy, Namecheap, etc.):\nLogin to your domain registrar Find domain everyonecook.cloud Select \u0026ldquo;Custom Nameservers\u0026rdquo; or \u0026ldquo;DNS Settings\u0026rdquo; Delete old nameservers Enter the 4 nameservers from AWS: ns-1164.awsdns-17.org ns-825.awsdns-39.net ns-1889.awsdns-44.co.uk ns-453.awsdns-56.com Save changes Step 1.4: Verify DNS Propagation # Check DNS propagation (may take 5-30 minutes) nslookup -type=NS everyonecook.cloud # Or use dig (if you have WSL/Git Bash) dig NS everyonecook.cloud # Expected: See 4 nameservers from AWS Online tools to check:\nhttps://www.whatsmydns.net/ https://dnschecker.org/ ⏳ Wait for DNS to propagate before continuing (usually 5-15 minutes)\nPhase 1.5: Deploy Certificate Stack (ACM) IMPORTANT: This stack must be deployed in us-east-1 region due to CloudFront requirement.\nStep 1.5.1: Deploy Certificate Stack # Deploy Certificate Stack (us-east-1) npx cdk deploy EveryoneCook-dev-Certificate --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Stack creates 2 certificates:\nCloudFront Certificate (us-east-1): cdn-dev.everyonecook.cloud API Gateway Certificate (us-east-1): *.everyonecook.cloud (wildcard) Step 1.5.2: Wait for DNS Validation ACM will automatically:\nCreate CNAME records in Route 53 to validate domain Validate ownership Issue certificates This process takes 5-10 minutes.\n# Check certificate status aws acm list-certificates --region us-east-1 # Get certificate ARN $certArn = aws acm list-certificates --region us-east-1 ` --query \u0026#39;CertificateSummaryList[?DomainName==`cdn-dev.everyonecook.cloud`].CertificateArn\u0026#39; ` --output text # Check validation status aws acm describe-certificate --certificate-arn $certArn --region us-east-1 ` --query \u0026#39;Certificate.{Status:Status,ValidationMethod:DomainValidationOptions[0].ValidationMethod}\u0026#39; Expected output:\n{ \u0026#34;Status\u0026#34;: \u0026#34;ISSUED\u0026#34;, \u0026#34;ValidationMethod\u0026#34;: \u0026#34;DNS\u0026#34; } Step 1.5.3: Verify Certificates # List all certificates aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Certificate ` --region us-east-1 ` --query \u0026#39;Stacks[0].Outputs\u0026#39; # Expected: # CloudFrontCertificateArn = arn:aws:acm:us-east-1:...:certificate/... # ApiGatewayCertificateArn = arn:aws:acm:us-east-1:...:certificate/... ✅ Wait until both certificates have Status = ISSUED\nPhase 2: Deploy Core Stack (Foundation) Core Stack creates foundation resources: DynamoDB, S3, CloudFront, KMS.\nStep 2.1: Deploy Core Stack # Deploy Core Stack (takes 10-15 minutes) npx cdk deploy EveryoneCook-dev-Core --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Stack creates:\nDynamoDB:\nTable: EveryoneCook-dev Billing: Pay-per-request 5 GSI indexes (GSI1-GSI5) Stream enabled (for DynamoDB Streams) KMS encryption S3 Buckets (4 buckets):\neveryonecook-content-dev - User uploads (avatars, images) everyonecook-logs-dev - S3 access logs everyonecook-cdn-logs-dev - CloudFront logs everyonecook-incoming-emails-dev - SES email receiving CloudFront Distribution:\nCustom domain: cdn-dev.everyonecook.cloud Origin: S3 content bucket HTTPS only (certificate từ Certificate Stack) Compression enabled Price Class 200 (US, Europe, Asia) KMS Keys (2 keys):\nDynamoDB encryption key S3 encryption key Step 2.2: Monitor Deployment This deployment takes the longest (10-15 minutes) due to CloudFront Distribution.\n# In another terminal, monitor CloudFormation events aws cloudformation describe-stack-events ` --stack-name EveryoneCook-dev-Core ` --max-items 10 ` --query \u0026#39;StackEvents[*].{Time:Timestamp,Status:ResourceStatus,Type:ResourceType,Resource:LogicalResourceId}\u0026#39; ` --output table Step 2.3: Verify Core Resources # Check DynamoDB table aws dynamodb describe-table --table-name EveryoneCook-dev ` --query \u0026#39;Table.{Name:TableName,Status:TableStatus,Billing:BillingModeSummary.BillingMode,Stream:StreamSpecification.StreamEnabled}\u0026#39; # Expected: # { # \u0026#34;Name\u0026#34;: \u0026#34;EveryoneCook-dev\u0026#34;, # \u0026#34;Status\u0026#34;: \u0026#34;ACTIVE\u0026#34;, # \u0026#34;Billing\u0026#34;: \u0026#34;PAY_PER_REQUEST\u0026#34;, # \u0026#34;Stream\u0026#34;: true # } # Check S3 buckets aws s3 ls | Select-String \u0026#34;everyonecook\u0026#34; # Expected: # everyonecook-cdn-logs-dev # everyonecook-content-dev # everyonecook-incoming-emails-dev # everyonecook-logs-dev # Check CloudFront distribution aws cloudfront list-distributions ` --query \u0026#39;DistributionList.Items[?Comment==`EveryoneCook CDN (dev)`].{Id:Id,Domain:DomainName,Status:Status}\u0026#39; # Expected: # { # \u0026#34;Id\u0026#34;: \u0026#34;E2INNJ4XX421Q3\u0026#34;, # \u0026#34;Domain\u0026#34;: \u0026#34;d2shrpzup69rju.cloudfront.net\u0026#34;, # \u0026#34;Status\u0026#34;: \u0026#34;Deployed\u0026#34; # } Step 2.4: Get Stack Outputs # Get all Core Stack outputs aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Core ` --query \u0026#39;Stacks[0].Outputs[*].{Key:OutputKey,Value:OutputValue}\u0026#39; ` --output table Key outputs:\nDynamoDBTableName: EveryoneCook-dev ContentBucketName: everyonecook-content-dev CloudFrontDistributionId: E2INNJ4XX421Q3 CloudFrontDomainName: d2shrpzup69rju.cloudfront.net Phase 3: Deploy Auth Stack (Cognito \u0026amp; SES) Auth Stack creates authentication infrastructure with Cognito and SES.\nStep 3.1: Deploy Auth Stack # Deploy Auth Stack npx cdk deploy EveryoneCook-dev-Auth --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Stack creates:\nCognito User Pool:\nUser Pool: EveryoneCook-UserPool-dev Password policy: 12 chars min, requires symbols MFA: Optional Email verification 5 Lambda Triggers:\nPre-Signup - Validate username/email Post-Confirmation - Tạo user profile trong DynamoDB Post-Authentication - Update lastLoginAt Pre-Authentication - Check ban status Custom Message - Custom email templates SES Email Identity:\nDomain: everyonecook.cloud DKIM authentication Mail FROM domain: mail.everyonecook.cloud Production mode (can send to any email) IAM Roles:\nLambda execution roles Cognito SMS role (for MFA) Step 3.2: Verify Cognito User Pool # Get User Pool ID $userPoolId = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Auth ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;User Pool ID: $userPoolId\u0026#34; # ap-southeast-1_PKoL34PF0 # Describe User Pool aws cognito-idp describe-user-pool --user-pool-id $userPoolId ` --query \u0026#39;UserPool.{Name:Name,Status:Status,MFA:MfaConfiguration}\u0026#39; Step 3.3: Verify Lambda Triggers # Check Lambda triggers attached to User Pool aws cognito-idp describe-user-pool --user-pool-id $userPoolId ` --query \u0026#39;UserPool.LambdaConfig\u0026#39; # Expected: 5 triggers configured # { # \u0026#34;PreSignUp\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PreSignup\u0026#34;, # \u0026#34;PostConfirmation\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PostConfirmation\u0026#34;, # \u0026#34;PostAuthentication\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PostAuthentication\u0026#34;, # \u0026#34;PreAuthentication\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PreAuthentication\u0026#34;, # \u0026#34;CustomMessage\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-CustomMessage\u0026#34; # } Step 3.4: Verify SES Email Identity # Check SES identity status aws sesv2 get-email-identity --email-identity everyonecook.cloud ` --query \u0026#39;{Status:VerifiedForSendingStatus,DKIM:DkimAttributes.Status}\u0026#39; # Expected: # { # \u0026#34;Status\u0026#34;: true, # \u0026#34;DKIM\u0026#34;: \u0026#34;SUCCESS\u0026#34; # } # Check DKIM records in Route 53 aws route53 list-resource-record-sets ` --hosted-zone-id Z018823421GWCSYG5UMHV ` --query \u0026#39;ResourceRecordSets[?Type==`CNAME` \u0026amp;\u0026amp; contains(Name, `_domainkey`)]\u0026#39; ✅ SES must be in Production mode to send email to any address\nPhase 4: Deploy Backend Stack (API \u0026amp; Lambda) Backend Stack creates API Gateway and Lambda functions. Before deploying, you need to build Lambda code.\nStep 4.1: Build Lambda Code # Navigate to project root cd D:\\Project_AWS\\everyonecook # Run deployment script to build all Lambda code .\\deploy\\deploy-backend.ps1 -Environment dev -SkipBuild:$false # Or manual build: # Build all modules cd services/api-router; npm run build; cd ../.. cd services/auth-module; npm run build; cd ../.. cd services/social-module; npm run build; cd ../.. cd services/ai-module; npm run build; cd ../.. cd services/admin-module; npm run build; cd ../.. cd services/upload-module; npm run build; cd ../.. ⚠️ IMPORTANT: Lambda code must be built BEFORE deploying Backend Stack!\nStep 4.2: Deploy Backend Stack # Navigate back to infrastructure cd D:\\Project_AWS\\everyonecook\\infrastructure # Deploy Backend Stack npx cdk deploy EveryoneCook-dev-Backend --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Stack creates:\nAPI Gateway:\nREST API: EveryoneCook-API-dev Custom domain: api-dev.everyonecook.cloud Cognito Authorizer WAF Web ACL protection 7 Lambda Functions:\neveryonecook-dev-api-router - API routing (512 MB, 30s)\neveryonecook-dev-auth-user - Auth \u0026amp; User Management (512 MB, 30s)\neveryonecook-dev-social - Social features (512 MB, 30s)\neveryonecook-dev-recipe-ai - Recipes \u0026amp; AI (1024 MB, 60s)\neveryonecook-dev-ai-worker - AI processing worker (1024 MB, 300s)\neveryonecook-dev-admin - Admin dashboard (512 MB, 30s)\neveryonecook-dev-upload - File upload (256 MB, 15s)\nLambda Layer:\neveryonecook-shared-deps-dev - Shared dependencies (~15-20 MB) SQS Queues (4 queues + 4 DLQs):\nAI Queue + DLQ Image Processing Queue + DLQ Analytics Queue + DLQ Notification Queue + DLQ WAF Web ACL:\nAPI Gateway protection Rate limiting (2000 req/5min per IP) Geo blocking support Step 4.3: Verify API Gateway # Get API endpoint $apiUrl = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Backend ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiCustomDomain`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;API Endpoint: $apiUrl\u0026#34; # https://api-dev.everyonecook.cloud # Test health endpoint $response = Invoke-RestMethod -Uri \u0026#34;$apiUrl/health\u0026#34; -Method Get $response | ConvertTo-Json # Expected: # { # \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, # \u0026#34;timestamp\u0026#34;: \u0026#34;2025-12-09T...\u0026#34;, # \u0026#34;service\u0026#34;: \u0026#34;EveryoneCook API\u0026#34;, # \u0026#34;environment\u0026#34;: \u0026#34;dev\u0026#34; # } Step 4.4: Verify Lambda Functions # List all Lambda functions aws lambda list-functions ` --query \u0026#39;Functions[?contains(FunctionName, `everyonecook-dev`)].{Name:FunctionName,Runtime:Runtime,Memory:MemorySize,Timeout:Timeout}\u0026#39; ` --output table # Expected: 7 functions + 5 Cognito triggers = 12 Lambda functions total Step 4.5: Verify SQS Queues # List SQS queues aws sqs list-queues --queue-name-prefix everyonecook-dev # Expected: 8 queues (4 main + 4 DLQ) # - everyonecook-dev-ai-queue # - everyonecook-dev-ai-queue-dlq # - everyonecook-dev-image-queue # - everyonecook-dev-image-queue-dlq # - everyonecook-dev-analytics-queue # - everyonecook-dev-analytics-queue-dlq # - everyonecook-dev-notification-queue # - everyonecook-dev-notification-queue-dlq Phase 5: Deploy Observability Stack (CloudWatch) Observability Stack creates monitoring dashboards and alarms.\nStep 5.1: Deploy Observability Stack # Deploy Observability Stack npx cdk deploy EveryoneCook-dev-Observability --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Stack creates:\n4 CloudWatch Dashboards:\nCore Dashboard - DynamoDB, S3, CloudFront metrics Auth Dashboard - Cognito, SES metrics Backend Dashboard - API Gateway, Lambda metrics Overview Dashboard - High-level system health CloudWatch Alarms:\nDynamoDB throttling Lambda errors API Gateway 5xx errors CloudFront 5xx errors SNS Topic:\nAlarm notifications Email subscription support Composite Alarm:\nCritical system health alarm Aggregates multiple alarms Step 5.2: Subscribe to SNS Topic # Get SNS topic ARN $topicArn = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Observability ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`AlarmTopicArn`].OutputValue\u0026#39; ` --output text # Subscribe your email aws sns subscribe ` --topic-arn $topicArn ` --protocol email ` --notification-endpoint \u0026#34;your-email@example.com\u0026#34; Write-Host \u0026#34;Check your email and confirm subscription!\u0026#34; Step 5.3: Verify Dashboards # List CloudWatch dashboards aws cloudwatch list-dashboards ` --query \u0026#39;DashboardEntries[?contains(DashboardName, `EveryoneCook-dev`)].DashboardName\u0026#39; # Expected: # - EveryoneCook-dev-CoreDashboard # - EveryoneCook-dev-AuthDashboard # - EveryoneCook-dev-BackendDashboard # - EveryoneCook-dev-OverviewDashboard # Get dashboard URL $region = \u0026#34;ap-southeast-1\u0026#34; $dashboardName = \u0026#34;EveryoneCook-dev-OverviewDashboard\u0026#34; Write-Host \u0026#34;Dashboard URL: https://console.aws.amazon.com/cloudwatch/home?region=$region#dashboards:name=$dashboardName\u0026#34; Verify Complete Deployment Step 6.1: List All Stacks # List all deployed stacks aws cloudformation list-stacks ` --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE ` --query \u0026#39;StackSummaries[?contains(StackName, `EveryoneCook-dev`)].{Name:StackName,Status:StackStatus,Created:CreationTime}\u0026#39; ` --output table Expected stacks:\n------------------------------------------------------------ | ListStacks | +--------------------------------------------------+--------+ | Name | Status | Created| +--------------------------------------------------+--------+ | EveryoneCook-dev-DNS | CREATE_COMPLETE | | EveryoneCook-dev-Certificate | CREATE_COMPLETE | | EveryoneCook-dev-Core | CREATE_COMPLETE | | EveryoneCook-dev-Auth | CREATE_COMPLETE | | EveryoneCook-dev-Backend | CREATE_COMPLETE | | EveryoneCook-dev-Observability | CREATE_COMPLETE | +--------------------------------------------------+--------+ Step 6.2: Get All Stack Outputs # Create comprehensive outputs report $stacks = @(\u0026#34;DNS\u0026#34;, \u0026#34;Certificate\u0026#34;, \u0026#34;Core\u0026#34;, \u0026#34;Auth\u0026#34;, \u0026#34;Backend\u0026#34;, \u0026#34;Observability\u0026#34;) foreach ($stack in $stacks) { Write-Host \u0026#34;`n========================================\u0026#34; -ForegroundColor Cyan Write-Host \u0026#34;EveryoneCook-dev-$stack Outputs\u0026#34; -ForegroundColor Cyan Write-Host \u0026#34;========================================\u0026#34; -ForegroundColor Cyan aws cloudformation describe-stacks ` --stack-name \u0026#34;EveryoneCook-dev-$stack\u0026#34; ` --query \u0026#39;Stacks[0].Outputs[*].{Key:OutputKey,Value:OutputValue}\u0026#39; ` --output table } Step 6.3: Save Outputs to File # Save outputs to infrastructure/outputs.json cd D:\\Project_AWS\\everyonecook\\infrastructure # Get outputs in JSON format $outputs = @{} foreach ($stack in $stacks) { $stackOutputs = aws cloudformation describe-stacks ` --stack-name \u0026#34;EveryoneCook-dev-$stack\u0026#34; ` --query \u0026#39;Stacks[0].Outputs\u0026#39; | ConvertFrom-Json $stackData = @{} foreach ($output in $stackOutputs) { $stackData[$output.OutputKey] = $output.OutputValue } $outputs[\u0026#34;EveryoneCook-dev-$stack\u0026#34;] = $stackData } # Save to file $outputs | ConvertTo-Json -Depth 5 | Out-File -FilePath \u0026#34;outputs.json\u0026#34; -Encoding utf8 Write-Host \u0026#34;Outputs saved to outputs.json\u0026#34; -ForegroundColor Green Step 6.4: Verify Key Resources # Comprehensive resource verification Write-Host \u0026#34;`n===== RESOURCE VERIFICATION =====\u0026#34; -ForegroundColor Yellow # DynamoDB Write-Host \u0026#34;`nDynamoDB Table:\u0026#34; -ForegroundColor Cyan aws dynamodb describe-table --table-name EveryoneCook-dev ` --query \u0026#39;Table.{Name:TableName,Status:TableStatus,ItemCount:ItemCount,Size:TableSizeBytes}\u0026#39; ` --output table # S3 Buckets Write-Host \u0026#34;`nS3 Buckets:\u0026#34; -ForegroundColor Cyan aws s3 ls | Select-String \u0026#34;everyonecook\u0026#34; # CloudFront Write-Host \u0026#34;`nCloudFront Distribution:\u0026#34; -ForegroundColor Cyan aws cloudfront list-distributions ` --query \u0026#39;DistributionList.Items[?Comment==`EveryoneCook CDN (dev)`].{Id:Id,Status:Status,Domain:DomainName}\u0026#39; ` --output table # Lambda Functions Write-Host \u0026#34;`nLambda Functions:\u0026#34; -ForegroundColor Cyan aws lambda list-functions ` --query \u0026#39;Functions[?contains(FunctionName, `everyonecook-dev`)].FunctionName\u0026#39; ` --output table # Cognito User Pool Write-Host \u0026#34;`nCognito User Pool:\u0026#34; -ForegroundColor Cyan aws cognito-idp list-user-pools --max-results 10 ` --query \u0026#39;UserPools[?Name==`EveryoneCook-UserPool-dev`].{Name:Name,Id:Id,Status:Status}\u0026#39; ` --output table # API Gateway Write-Host \u0026#34;`nAPI Gateway:\u0026#34; -ForegroundColor Cyan aws apigateway get-rest-apis ` --query \u0026#39;items[?name==`EveryoneCook-API-dev`].{Name:name,Id:id}\u0026#39; ` --output table # SQS Queues Write-Host \u0026#34;`nSQS Queues:\u0026#34; -ForegroundColor Cyan aws sqs list-queues --queue-name-prefix everyonecook-dev ` --query \u0026#39;QueueUrls\u0026#39; --output table Write-Host \u0026#34;`n===== VERIFICATION COMPLETE =====\u0026#34; -ForegroundColor Green Deployment Summary Deployed Resources Count Category Count Resources Networking 5 Route 53 Hosted Zone, 2 ACM Certificates, CloudFront Distribution, WAF Web ACL Storage 6 DynamoDB Table (5 GSI), 4 S3 Buckets, 2 KMS Keys Compute 12 7 Lambda Functions, 5 Cognito Triggers Integration 8 API Gateway, 4 SQS Queues, 4 DLQ Security 8 Cognito User Pool, SES Identity, IAM Roles (6) Monitoring 15 4 Dashboards, 10+ Alarms, SNS Topic Total Resources: ~100+ AWS resources\nStack-by-Stack Breakdown DNS Stack:\n✅ Route 53 Hosted Zone Certificate Stack:\n✅ 2 ACM Certificates (us-east-1) Core Stack:\n✅ DynamoDB Table + 5 GSIs + Stream ✅ 4 S3 Buckets ✅ CloudFront Distribution ✅ 2 KMS Keys Auth Stack:\n✅ Cognito User Pool + Client ✅ 5 Lambda Triggers ✅ SES Email Identity ✅ IAM Roles Backend Stack:\n✅ API Gateway REST API ✅ 7 Lambda Functions ✅ Lambda Layer ✅ 4 SQS Queues + 4 DLQs ✅ WAF Web ACL Observability Stack:\n✅ 4 CloudWatch Dashboards ✅ 10+ CloudWatch Alarms ✅ SNS Topic ✅ Composite Alarm Troubleshooting Issue 1: Stack Deployment Failed # Check CloudFormation events for errors aws cloudformation describe-stack-events ` --stack-name EveryoneCook-dev-STACKNAME ` --max-items 20 ` --query \u0026#39;StackEvents[?ResourceStatus==`CREATE_FAILED` || ResourceStatus==`ROLLBACK_IN_PROGRESS`].{Time:Timestamp,Status:ResourceStatus,Reason:ResourceStatusReason,Resource:LogicalResourceId}\u0026#39; ` --output table # Common causes: # - Missing dependencies (check dependency order) # - Insufficient permissions # - Resource limits exceeded # - Naming conflicts Issue 2: Certificate Validation Stuck # Check certificate status $certArn = \u0026#34;arn:aws:acm:us-east-1:...:certificate/...\u0026#34; aws acm describe-certificate --certificate-arn $certArn --region us-east-1 ` --query \u0026#39;Certificate.DomainValidationOptions[0].{Domain:DomainName,Status:ValidationStatus,Method:ValidationMethod}\u0026#39; # Check DNS records aws route53 list-resource-record-sets ` --hosted-zone-id Z018823421GWCSYG5UMHV ` --query \u0026#39;ResourceRecordSets[?Type==`CNAME`]\u0026#39; # Solutions: # - Verify nameservers updated at registrar # - Wait for DNS propagation (up to 48h, usually 15min) # - Check validation CNAME records exist in Route 53 Issue 3: Lambda Deployment Failed # Check if dist folder exists Get-ChildItem D:\\Project_AWS\\everyonecook\\services\\*\\dist # If missing, rebuild cd D:\\Project_AWS\\everyonecook .\\deploy\\deploy-backend.ps1 -Environment dev # Check Lambda package size Get-ChildItem D:\\Project_AWS\\everyonecook\\services\\*\\lambda.zip | Select-Object Name, @{Name=\u0026#34;Size(MB)\u0026#34;;Expression={[math]::Round($_.Length/1MB,2)}} # Lambda limits: # - Deployment package: 50 MB (zipped) # - Unzipped: 250 MB Issue 4: CloudFront Distribution Failed # Check certificate region (must be us-east-1) aws acm list-certificates --region us-east-1 ` --query \u0026#39;CertificateSummaryList[?DomainName==`cdn-dev.everyonecook.cloud`]\u0026#39; # Check S3 bucket exists aws s3 ls everyonecook-content-dev # Solutions: # - Ensure Certificate Stack deployed first # - Certificate must be in us-east-1 # - S3 bucket must exist before CloudFront Issue 5: Insufficient IAM Permissions # Check current user/role aws sts get-caller-identity # Required permissions: # - cloudformation:* (all CloudFormation operations) # - iam:* (create roles, policies) # - lambda:* (create functions) # - apigateway:* (create API) # - cognito-idp:* (create user pools) # - s3:* (create buckets) # - dynamodb:* (create tables) # - route53:* (create hosted zones) # - acm:* (create certificates) # - cloudfront:* (create distributions) # - wafv2:* (create web ACLs) # - logs:* (create log groups) # - sns:* (create topics) # - sqs:* (create queues) # Recommended: AdministratorAccess policy (for first deployment) Issue 6: Stack Rollback # If stack rolls back, check reason aws cloudformation describe-stack-events ` --stack-name EveryoneCook-dev-STACKNAME ` --query \u0026#39;StackEvents[?ResourceStatus==`CREATE_FAILED`].[Timestamp,ResourceStatusReason]\u0026#39; ` --output table # Delete failed stack before retry aws cloudformation delete-stack --stack-name EveryoneCook-dev-STACKNAME # Wait for deletion aws cloudformation wait stack-delete-complete --stack-name EveryoneCook-dev-STACKNAME # Redeploy npx cdk deploy EveryoneCook-dev-STACKNAME --context environment=dev Cost Estimation Monthly Cost Breakdown (Dev Environment) Service Usage Cost DynamoDB Pay-per-request, low usage $2-5 S3 10 GB storage + requests $1-2 CloudFront 10 GB transfer $1-2 Lambda 1M requests, 512 MB $3-5 API Gateway 100K requests $0.35 Cognito 100 MAU $0-5 SES 100 emails $0.01 CloudWatch Logs + metrics $2-3 WAF Basic rules $5 Route 53 1 hosted zone $0.50 SQS 100K requests $0.04 KMS 2 keys $2 Total Estimated Monthly Cost: $20-35 (without OpenSearch)\nWith OpenSearch (if enabled): $70-135/month\nCost Tracking # Check current month costs $startDate = (Get-Date -Day 1).ToString(\u0026#34;yyyy-MM-dd\u0026#34;) $endDate = (Get-Date).AddDays(1).ToString(\u0026#34;yyyy-MM-dd\u0026#34;) aws ce get-cost-and-usage ` --time-period Start=$startDate,End=$endDate ` --granularity DAILY ` --metrics BlendedCost ` --group-by Type=SERVICE ` --output table Next Steps Infrastructure deployment complete! Next steps:\n✅ Verify All Stacks: All 6 stacks deployed successfully 🔧 Configure API: Setup API routes và Lambda integration → 5.06 - Configure API \u0026amp; Lambda 🚀 Deploy Backend Code: Build và deploy Lambda code → 5.07 - Deploy Backend ✅ Test Endpoints: Verify API functionality → 5.08 - Test Endpoints Current Status:\nInfrastructure: ✅ Complete Lambda Code: ⏳ Needs deployment Testing: ⏳ Pending Proceed to: 5.06 - Configure API \u0026amp; Lambda\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/","title":"Workshop","tags":[],"description":"","content":"Building EveryoneCook: A Full-Stack AWS Infrastructure Workshop Overview In this comprehensive workshop, you will learn how to build a production-ready, full-stack social cooking application infrastructure on AWS using Infrastructure as Code (IaC) with AWS CDK. The EveryoneCook platform demonstrates modern cloud architecture patterns, including serverless computing, content delivery, AI-powered features, advanced search with OpenSearch, and comprehensive observability.\nYou will deploy seven interconnected CDK stacks that work together to create a scalable, secure, and cost-optimized application:\nDNS Stack - Route 53 hosted zone for domain management Certificate Stack - ACM certificates for CloudFront and API Gateway (us-east-1) CoreStack - DynamoDB Single Table, S3 buckets, CloudFront CDN, KMS encryption, and OpenSearch AuthStack - Cognito User Pool with Lambda triggers and SES email integration BackendStack - API Gateway, Lambda functions (6 modules), SQS queues, and WAF protection FrontendStack - AWS Amplify hosting for Next.js 15 application (optional) ObservabilityStack - CloudWatch dashboards, alarms, and X-Ray distributed tracing Content Workshop Overview Setup Environment CDK Bootstrap Configure Infrastructure Stacks Deploy Infrastructure Configure API \u0026amp; Lambda Deploy Backend Services Test Endpoints End-to-End Push to GitLab Deploy to Amplify Clean up "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.5-week5/","title":"Week 5 Worklog","tags":[],"description":"","content":"Tasks to be carried out this week: Week 5 Objectives Understand IAM basics: users, roles, and permission policies. Learn how Amazon Cognito handles app user authentication. Get familiar with AWS Organizations for multi-account management. Use AWS Identity Center (SSO) for centralized access control. Understand KMS for encryption key management. Distinguish responsibility levels across AWS services. Grasp the Shared Responsibility Model and the shift toward managed services. Day Task Start Date Completion Date Reference Material 2 Share Responsibility Model 10/09/2025 10/09/2025 YouTube Video 3 IAM 10/10/2025 10/10/2025 cont 4 Cognito 10/11/2025 10/11/2025 cont 5 AWS Organizations, SSO 10/12/2025 10/12/2025 cont 6 KMS, ECS, EKS 10/13/2025 10/13/2025 cont Understood what AWS is and mastered the basic service groups: AWS Identity and Access Management (IAM) Amazon Cognito – User Authentication for Applications AWS Organizations – Multi-Account Management AWS Identity Center (AWS SSO) AWS Key Management Service (KMS) – Encryption Key Management Service Responsibility Levels: Infrastructure / Container / Fully Managed Summary of Shared Responsibility and Trend Toward Managed Services AWS Identity and Access Management (IAM) Controls identities and permissions for users, groups, and roles. Core principle: Least Privilege – grant only the needed permissions. Avoid using the root account ; use IAM roles/users instead. Permissions are defined through IAM policies (managed, custom, inline). Amazon Cognito – User Authentication for Applications Provides user sign-up, sign-in, and identity management for web/mobile apps. Supports MFA, OAuth2, SAML, and OpenID Connect. Helps offload authentication so you don’t build it from scratch. AWS Organizations – Multi-Account Management Centralized management for multiple AWS accounts. Enables cost control, consolidated billing, and security boundaries. Uses Service Control Policies (SCPs) to enforce organization-wide permissions. AWS Identity Center (AWS SSO) Simplifies login with single sign-on across accounts and applications. Allows assignment of roles to users from internal or external directories. Reduces reliance on IAM users and long-term access keys. AWS Key Management Service (KMS) Creates and manages encryption keys for AWS services. Integrates with S3, EBS, RDS, DynamoDB, Lambda. Provides auditing via CloudTrail for key usage. Supports both AWS-managed and customer-managed keys. Service Responsibility Levels Infrastructure services ( EC2): Customer manages OS, patching, network config. Container services (ECS/EKS): AWS manages infra; customer manages containers. Fully managed services (S3, DynamoDB, Lambda): AWS handles almost everything; customer focuses on data. "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.5-backend-stack/","title":"5.4.5 Backend Stack","tags":[],"description":"","content":" Backend Stack - Application Layer Overview The Backend Stack is the Phase 4 application layer of the EveryoneCook infrastructure. It consolidates the API Gateway, Lambda functions, SQS queues, and WAF security into a unified backend architecture.\nDeployment Order: This stack MUST be deployed after Core Stack and Auth Stack.\n⚠️ Environment Note: This guide focuses on Development (dev) environment deployment. For staging/production deployments, see Environment Differences section.\nKey Responsibilities Create API Gateway REST API with custom domain Deploy 6 Lambda functions (API Router + 5 business modules) Configure 2 active SQS queues for async processing (AI, Image queues with DLQs) Deploy 2 worker Lambda functions for event processing (AI Worker, Image Worker) Setup WAF Web ACL for API Gateway protection Configure CloudWatch monitoring and alarms What\u0026rsquo;s Actually Running:\n8 Lambda Functions (6 business + 2 workers) 4 SQS Queues deployed (AI + Image queues with their DLQs) 1 WAF Web ACL with 5 security rules CloudWatch Logs and Alarms What This Stack Includes API Gateway (Dev Environment):\nCustom domain: api-dev.everyonecook.cloud ACM certificate for HTTPS (Regional - ap-southeast-1) Cognito authorizer for JWT validation Caching: Disabled (enabled only in production) Compression: Enabled (gzip/deflate for responses \u0026gt;1KB) Rate limiting: 10K req/sec, burst 5K Request validation: Body, parameters, headers Data trace logging: Enabled (disabled in production) Lambda Functions (6 functions - Dev Environment):\nAPI Router (everyonecook-dev-api-router): Routes requests to target Lambda functions Auth \u0026amp; User (everyonecook-dev-auth-user): Authentication, user profiles, privacy settings Social (everyonecook-dev-social): Posts, comments, reactions, friends, notifications Recipe \u0026amp; AI (everyonecook-dev-recipe-ai): Recipe CRUD, AI generation, search, trending Admin (everyonecook-dev-admin): Content moderation, user management, appeals Upload (everyonecook-dev-upload): S3 presigned URLs, file uploads Source Code: All functions located in services/ directory\nSQS Queues (2 active queues + 2 DLQs):\nAI Queue (everyonecook-dev-ai-queue): Bedrock AI recipe generation (2-minute timeout) → AI Worker Image Queue (everyonecook-dev-image-queue): S3 image optimization (60-second timeout) → Image Worker Note: Analytics and Notification queues are defined in code but NOT deployed. Notifications are handled directly in Social Module.\nWorker Lambda Functions (2 workers actively deployed):\nAI Worker (ai-module/workers/): Processes AI generation jobs from AI Queue using Bedrock Claude 3 Haiku Image Worker (image-worker/): Processes image optimization from Image Queue (resize, compress, watermark) WAF Web ACL:\nRate limiting: 2000 req/5min per IP SQL injection protection (AWS Managed) XSS protection (AWS Managed) Known bad inputs (AWS Managed) Request size limit: 10MB max Architecture ┌──────────────────────────────────────────────────────────────────────┐ │ Backend Stack (Phase 4 - Dev Environment) │ │ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ WAF Web ACL (REGIONAL) - API Gateway Protection │ │ │ │ ├─ Rate Limiting: 2000 req/5min per IP │ │ │ │ ├─ SQL Injection Protection (AWS Managed) │ │ │ │ ├─ XSS Protection (AWS Managed) │ │ │ │ ├─ Known Bad Inputs (AWS Managed) │ │ │ │ └─ Request Size Limit: 10MB max │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ API Gateway REST API │ │ │ │ ├─ Custom Domain: api.everyonecook.cloud │ │ │ │ ├─ ACM Certificate (Regional - ap-southeast-1) │ │ │ │ ├─ Cognito Authorizer (JWT validation) │ │ │ │ ├─ Caching: 0.5GB, 5-min TTL (prod only) │ │ │ │ ├─ Compression: gzip/deflate (\u0026gt;1KB) │ │ │ │ ├─ Rate Limiting: 10K req/sec, burst 5K │ │ │ │ └─ Request Validation: Body, params, headers │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ Lambda Function: API Router (512MB, 30s timeout) │ │ │ │ ├─ JWT Validation \u0026amp; User Context Extraction │ │ │ │ ├─ Request Routing to Target Lambda Functions │ │ │ │ └─ Error Handling \u0026amp; Response Formatting │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ │ ┌────────────────┼────────────────┬──────────────────┐ │ │ ▼ ▼ ▼ ▼ │ │ ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐ │ │ │ Auth \u0026amp; │ │ Social │ │ Recipe │ │ Admin │ │ │ │ User │ │ Module │ │ \u0026amp; AI │ │ Module │ │ │ │ Lambda │ │ Lambda │ │ Lambda │ │ Lambda │ │ │ │ (512MB) │ │ (512MB) │ │ (512MB) │ │ (512MB) │ │ │ └─────────┘ └─────────┘ └─────────┘ └─────────┘ │ │ │ │ │ │ ▼ ▼ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ SQS Queues + Worker Lambdas │ │ │ │ │ │ │ │ 1️⃣ AI Queue → AI Worker (1024MB, 60s) │ │ │ │ ├─ Bedrock Claude 3 Haiku (us-east-1) │ │ │ │ ├─ Recipe generation from ingredients │ │ │ │ └─ Visibility timeout: 2 minutes │ │ │ │ │ │ │ │ 2️⃣ Image Queue → Image Worker (512MB, 60s) │ │ │ │ ├─ S3 image optimization │ │ │ │ ├─ Resize, compress, watermark │ │ │ │ └─ Visibility timeout: 60 seconds │ │ │ │ │ │ │ │ 📌 Only 2 queues actively used (AI \u0026amp; Image) │ │ │ │ 📌 Analytics \u0026amp; Notification queues exist but no workers │ │ │ │ 📌 All queues have DLQ (14-day retention) │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ Dependencies from Other Stacks: │ │ ├─ DynamoDB Table (Core Stack) │ │ ├─ S3 Content Bucket (Core Stack) │ │ ├─ CloudFront Distribution (Core Stack) │ │ ├─ Cognito User Pool (Auth Stack) │ │ └─ Cognito User Pool Client (Auth Stack) │ └──────────────────────────────────────────────────────────────────────┘ Stack Configuration File Structure infrastructure/lib/stacks/ └── backend-stack.ts # Backend Stack implementation (2965 lines) ├─ API Gateway configuration ├─ Lambda function definitions (6 functions) ├─ SQS queue configuration (4 queues + 4 DLQs) ├─ Worker Lambda definitions (2 active workers) └─ WAF Web ACL configuration services/ # Lambda function source code ├── api-router/ # API Router Lambda ├── auth-module/ # Auth \u0026amp; User Lambda ├── social-module/ # Social Lambda ├── recipe-module/ # Recipe \u0026amp; AI Lambda ├── admin-module/ # Admin Lambda ├── upload-module/ # Upload Lambda ├── ai-module/ # AI Worker Lambda │ └── workers/ ├── image-worker/ # Image Worker Lambda ├── websocket-module/ # WebSocket (separate stack, not in Backend) └── shared/ # Shared utilities Code Implementation File: infrastructure/lib/stacks/backend-stack.ts\n1. Stack Interface \u0026amp; Constructor export interface BackendStackProps extends BaseStackProps { dynamoTable: cdk.aws_dynamodb.ITable; contentBucket: cdk.aws_s3.IBucket; distribution: cdk.aws_cloudfront.IDistribution; userPool: cdk.aws_cognito.IUserPool; userPoolClient: cdk.aws_cognito.IUserPoolClient; } export class BackendStack extends BaseStack { // Lambda Layer public readonly sharedLayer: SharedDependenciesLayer; // API Gateway public readonly api: cdk.aws_apigateway.RestApi; public readonly cognitoAuthorizer: cdk.aws_apigateway.CognitoUserPoolsAuthorizer; public readonly apiDomainName: cdk.aws_apigateway.DomainName; // Request Validators public readonly bodyValidator: cdk.aws_apigateway.RequestValidator; public readonly paramsValidator: cdk.aws_apigateway.RequestValidator; public readonly fullValidator: cdk.aws_apigateway.RequestValidator; // Lambda Functions (6 business functions) public readonly apiRouterFunction: cdk.aws_lambda.Function; // services/api-router public readonly authUserFunction: cdk.aws_lambda.Function; // services/auth-module public readonly socialFunction: cdk.aws_lambda.Function; // services/social-module public readonly recipeAIFunction: cdk.aws_lambda.Function; // services/recipe-module public readonly adminFunction: cdk.aws_lambda.Function; // services/admin-module public readonly uploadFunction: cdk.aws_lambda.Function; // services/upload-module // SQS Queues (4 queues + 4 DLQs) public readonly aiQueue: cdk.aws_sqs.Queue; public readonly imageProcessingQueue: cdk.aws_sqs.Queue; public readonly analyticsQueue: cdk.aws_sqs.Queue; public readonly notificationQueue: cdk.aws_sqs.Queue; // Worker Lambdas (2 active workers) public readonly aiWorker: cdk.aws_lambda.Function; // services/ai-module/workers public readonly imageWorker?: cdk.aws_lambda.Function; // services/image-worker // Note: analyticsWorker \u0026amp; notificationWorker exist in code but NOT deployed // public readonly analyticsWorker?: cdk.aws_lambda.Function; // Commented out // public readonly notificationWorker?: cdk.aws_lambda.Function; // Not created // WAF WebACL public readonly apiGatewayWebAcl?: cdk.aws_wafv2.CfnWebACL; constructor(scope: Construct, id: string, props: BackendStackProps) { super(scope, id, props); // Add stack-specific tags cdk.Tags.of(this).add(\u0026#39;StackType\u0026#39;, \u0026#39;Backend\u0026#39;); cdk.Tags.of(this).add(\u0026#39;Layer\u0026#39;, \u0026#39;Application\u0026#39;); cdk.Tags.of(this).add(\u0026#39;CostCenter\u0026#39;, `Backend-${this.config.environment}`); // Create resources (see implementation below) // 1. Shared Dependencies Layer // 2. SQS Queues and DLQs // 3. API Gateway // 4. Lambda Functions // 5. Worker Lambdas // 6. WAF Web ACL // 7. Export outputs } } 2. API Gateway Configuration private createAPIGateway(): cdk.aws_apigateway.RestApi { const cachingEnabled = this.config.apiGateway.caching.enabled; const compressionEnabled = this.config.apiGateway.compression; const api = new cdk.aws_apigateway.RestApi(this, \u0026#39;EveryoneCookAPI\u0026#39;, { restApiName: `EveryoneCook-API-${this.config.environment}`, description: `Everyone Cook REST API - ${this.config.environment}`, // Compression for responses \u0026gt;1KB minCompressionSize: compressionEnabled ? cdk.Size.kibibytes(1) : undefined, deployOptions: { stageName: \u0026#39;api\u0026#39;, // Caching configuration (production only) cachingEnabled: cachingEnabled, cacheClusterEnabled: cachingEnabled, cacheClusterSize: cachingEnabled ? this.config.apiGateway.caching.cacheSize : undefined, cacheTtl: cachingEnabled ? cdk.Duration.seconds(this.config.apiGateway.caching.ttl) : undefined, cacheDataEncrypted: cachingEnabled, // Throttling settings throttlingRateLimit: this.config.apiGateway.throttling.rateLimit, throttlingBurstLimit: this.config.apiGateway.throttling.burstLimit, // X-Ray Tracing - Disabled (CloudWatch Logs sufficient) tracingEnabled: false, // Logging configuration loggingLevel: cdk.aws_apigateway.MethodLoggingLevel.INFO, dataTraceEnabled: this.config.environment !== \u0026#39;prod\u0026#39;, metricsEnabled: true, // Access logging accessLogDestination: new cdk.aws_apigateway.LogGroupLogDestination( new cdk.aws_logs.LogGroup(this, \u0026#39;APIGatewayAccessLogs\u0026#39;, { logGroupName: `/aws/apigateway/everyonecook-${this.config.environment}`, retention: this.config.cloudwatch.logRetentionDays, }) ), }, // CORS configuration defaultCorsPreflightOptions: { allowOrigins: [ `https://${this.config.domains.frontend}`, `https://www.${this.config.domains.frontend}`, ...(this.config.environment !== \u0026#39;prod\u0026#39; ? [\u0026#39;http://localhost:3000\u0026#39;] : []), ], allowMethods: [\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;, \u0026#39;PUT\u0026#39;, \u0026#39;DELETE\u0026#39;, \u0026#39;PATCH\u0026#39;, \u0026#39;OPTIONS\u0026#39;], allowHeaders: [ \u0026#39;Content-Type\u0026#39;, \u0026#39;Authorization\u0026#39;, \u0026#39;X-Amz-Date\u0026#39;, \u0026#39;X-Api-Key\u0026#39;, \u0026#39;X-Amz-Security-Token\u0026#39;, \u0026#39;X-Correlation-Id\u0026#39;, \u0026#39;Cache-Control\u0026#39;, \u0026#39;Accept-Encoding\u0026#39;, ], allowCredentials: false, maxAge: cdk.Duration.hours(1), }, // Endpoint configuration endpointConfiguration: { types: [cdk.aws_apigateway.EndpointType.REGIONAL], }, // Binary media types binaryMediaTypes: [\u0026#39;image/*\u0026#39;, \u0026#39;application/octet-stream\u0026#39;], }); // Add Gateway Responses with CORS headers const corsHeaders = { \u0026#39;gatewayresponse.header.Access-Control-Allow-Origin\u0026#39;: \u0026#34;\u0026#39;*\u0026#39;\u0026#34;, \u0026#39;gatewayresponse.header.Access-Control-Allow-Headers\u0026#39;: \u0026#34;\u0026#39;Content-Type,Authorization,...\u0026#39;\u0026#34;, \u0026#39;gatewayresponse.header.Access-Control-Allow-Methods\u0026#39;: \u0026#34;\u0026#39;GET,POST,PUT,DELETE,PATCH,OPTIONS\u0026#39;\u0026#34;, }; api.addGatewayResponse(\u0026#39;Unauthorized\u0026#39;, { type: cdk.aws_apigateway.ResponseType.UNAUTHORIZED, statusCode: \u0026#39;401\u0026#39;, responseHeaders: corsHeaders, }); return api; } 3. SQS Queue Configuration private createAIQueue(): cdk.aws_sqs.Queue { const queue = new cdk.aws_sqs.Queue(this, \u0026#39;AIQueue\u0026#39;, { queueName: `everyonecook-${this.config.environment}-ai-queue`, visibilityTimeout: cdk.Duration.seconds(120), // 2 minutes for AI processing retentionPeriod: cdk.Duration.days(4), deadLetterQueue: { queue: this.aiDLQ, maxReceiveCount: 3, }, encryption: cdk.aws_sqs.QueueEncryption.KMS_MANAGED, }); // CloudWatch alarm for queue depth if (this.config.cloudwatch.alarms.enabled) { new cdk.aws_cloudwatch.Alarm(this, \u0026#39;AIQueueDepthAlarm\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-AI-Queue-Depth`, metric: queue.metricApproximateNumberOfMessagesVisible(), threshold: 100, evaluationPeriods: 2, }); } return queue; } 4. Lambda Function Configuration private createAuthUserLambda(props: BackendStackProps): cdk.aws_lambda.Function { const logGroup = new cdk.aws_logs.LogGroup(this, \u0026#39;AuthUserLogGroup\u0026#39;, { logGroupName: `/aws/lambda/everyonecook-${this.config.environment}-auth-user`, retention: this.config.cloudwatch.logRetentionDays, }); const authUserFunction = new cdk.aws_lambda.Function(this, \u0026#39;AuthUserFunction\u0026#39;, { functionName: `everyonecook-${this.config.environment}-auth-user`, runtime: cdk.aws_lambda.Runtime.NODEJS_20_X, handler: \u0026#39;services/auth-module/index.handler\u0026#39;, code: this.createLambdaCode(\u0026#39;services/auth-module/deployment\u0026#39;), layers: [this.sharedLayer.layer], memorySize: 512, timeout: cdk.Duration.seconds(30), tracing: cdk.aws_lambda.Tracing.DISABLED, environment: { DYNAMODB_TABLE: props.dynamoTable.tableName, USER_POOL_ID: props.userPool.userPoolId, USER_POOL_CLIENT_ID: props.userPoolClient.userPoolClientId, CONTENT_BUCKET: props.contentBucket.bucketName, LOG_LEVEL: this.config.environment === \u0026#39;prod\u0026#39; ? \u0026#39;INFO\u0026#39; : \u0026#39;DEBUG\u0026#39;, }, logGroup: logGroup, }); // Grant permissions props.dynamoTable.grantReadWriteData(authUserFunction); props.contentBucket.grantReadWrite(authUserFunction); props.userPool.grant(authUserFunction, \u0026#39;cognito-idp:AdminGetUser\u0026#39;, \u0026#39;cognito-idp:ListUsers\u0026#39;); return authUserFunction; } 5. WAF Web ACL Configuration private createApiGatewayWebAcl(): cdk.aws_wafv2.CfnWebACL { const webAcl = new cdk.aws_wafv2.CfnWebACL(this, \u0026#39;ApiGatewayWebACL\u0026#39;, { name: `EveryoneCook-API-WAF-${this.config.environment}`, scope: \u0026#39;REGIONAL\u0026#39;, defaultAction: { allow: {} }, visibilityConfig: { sampledRequestsEnabled: true, cloudWatchMetricsEnabled: true, metricName: `EveryoneCook-API-WAF-${this.config.environment}`, }, rules: [ // Rule 1: Rate Limiting { name: \u0026#39;RateLimitRule\u0026#39;, priority: 0, statement: { rateBasedStatement: { limit: 2000, // 2000 requests per 5 minutes aggregateKeyType: \u0026#39;IP\u0026#39;, }, }, action: { block: {} }, visibilityConfig: { sampledRequestsEnabled: true, cloudWatchMetricsEnabled: true, metricName: \u0026#39;RateLimitRule\u0026#39;, }, }, // Rule 2-5: AWS Managed Rules (SQL injection, XSS, etc.) // ... see full implementation ], }); return webAcl; } Key Configuration Details 1. Shared Dependencies Layer The Backend Stack uses a Lambda Layer to share common dependencies across all Lambda functions:\n// Create Shared Dependencies Layer this.sharedLayer = new SharedDependenciesLayer(this, \u0026#39;SharedDependenciesLayer\u0026#39;); // Benefits: // - 90% reduction in deployment size (8MB → 200KB per Lambda) // - Faster deployments // - Consistent dependency versions // - Lower storage costs // Dependencies included: // - AWS SDK v3 clients (DynamoDB, Lambda, Cognito, S3, SQS, Bedrock) // - uuid, jsonwebtoken, jwks-rsa 2. API Gateway Custom Domain The stack creates a custom domain for API Gateway with ACM certificate:\n// Custom domain configuration const domainName = this.config.domains.api; // api.everyonecook.cloud // Create ACM certificate in ap-southeast-1 (Regional endpoint) const certificate = new acm.Certificate(this, \u0026#39;ApiGatewayCertificate\u0026#39;, { domainName: \u0026#39;*.everyonecook.cloud\u0026#39;, validation: acm.CertificateValidation.fromDns(hostedZone), }); // Create API Gateway DomainName const apiDomainName = new cdk.aws_apigateway.DomainName(this, \u0026#39;ApiDomain\u0026#39;, { domainName: this.config.domains.api, certificate: certificate, endpointType: cdk.aws_apigateway.EndpointType.REGIONAL, securityPolicy: cdk.aws_apigateway.SecurityPolicy.TLS_1_2, }); // Create Route 53 A record (Alias) new cdk.aws_route53.ARecord(this, \u0026#39;ApiAliasRecord\u0026#39;, { zone: hostedZone, recordName: this.config.domains.api, target: cdk.aws_route53.RecordTarget.fromAlias( new cdk.aws_route53_targets.ApiGatewayDomain(apiDomainName) ), }); Environments:\nDev: api-dev.everyonecook.cloud Staging: api-staging.everyonecook.cloud Prod: api.everyonecook.cloud 3. Request Validation The stack implements three levels of request validation:\n// 1. Body Validator - Validate request body only this.bodyValidator = new cdk.aws_apigateway.RequestValidator(this, \u0026#39;BodyValidator\u0026#39;, { restApi: api, validateRequestBody: true, validateRequestParameters: false, }); // 2. Params Validator - Validate query strings and headers only this.paramsValidator = new cdk.aws_apigateway.RequestValidator(this, \u0026#39;ParamsValidator\u0026#39;, { restApi: api, validateRequestBody: false, validateRequestParameters: true, }); // 3. Full Validator - Validate both body and parameters this.fullValidator = new cdk.aws_apigateway.RequestValidator(this, \u0026#39;FullValidator\u0026#39;, { restApi: api, validateRequestBody: true, validateRequestParameters: true, }); // Benefits: // - Early rejection of invalid requests (before Lambda invocation) // - Cost optimization: No Lambda charges for invalid requests // - Security: Prevents malformed requests // - Performance: Faster error responses 4. Resource Naming Convention All resources follow a consistent naming pattern:\n// Lambda function format: everyonecook-{env}-{function} functionName: `everyonecook-${this.config.environment}-auth-user` // SQS queue format: everyonecook-{env}-{queue} queueName: `everyonecook-${this.config.environment}-ai-queue` // API Gateway format: EveryoneCook-API-{env} restApiName: `EveryoneCook-API-${this.config.environment}` // WAF format: EveryoneCook-API-WAF-{env} name: `EveryoneCook-API-WAF-${this.config.environment}` Example:\nStack name: EveryoneCook-dev-Backend API: EveryoneCook-API-dev Lambda: everyonecook-dev-auth-user Queue: everyonecook-dev-ai-queue 5. Resource Tags Every resource is tagged for cost tracking and management:\n{ Stack: \u0026#39;EveryoneCook-dev-Backend\u0026#39;, Environment: \u0026#39;dev\u0026#39;, StackType: \u0026#39;Backend\u0026#39;, Layer: \u0026#39;Application\u0026#39;, CostCenter: \u0026#39;Backend-dev\u0026#39;, Component: \u0026#39;API\u0026#39; | \u0026#39;EventProcessing\u0026#39; | \u0026#39;Security\u0026#39;, Module: \u0026#39;AuthUser\u0026#39; | \u0026#39;Social\u0026#39; | \u0026#39;RecipeAI\u0026#39; | \u0026#39;Admin\u0026#39; | \u0026#39;Upload\u0026#39;, Purpose: \u0026#39;REST-API\u0026#39; | \u0026#39;RequestRouting\u0026#39; | \u0026#39;AI-Processing\u0026#39;, Project: \u0026#39;EveryoneCook\u0026#39; } Stack Outputs After deployment, the stack exports the following values:\nOutput Name Value Usage ApiUrl https://api.everyonecook.cloud Frontend API endpoint ApiId abc123xyz API Gateway REST API ID ApiStage api API Gateway stage name ApiDomainName api.everyonecook.cloud Custom domain name AIQueueUrl https://sqs.ap-southeast-1... AI Queue URL for sending messages ImageQueueUrl https://sqs.ap-southeast-1... Image Queue URL WafWebAclArn arn:aws:wafv2:... WAF Web ACL ARN Deployment Steps Step 1: Review Configuration Navigate to the infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Verify the Development environment configuration in config/environment.ts:\ndev: { environment: \u0026#39;dev\u0026#39;, account: \u0026#39;YOUR_AWS_ACCOUNT_ID\u0026#39;, region: \u0026#39;ap-southeast-1\u0026#39;, domains: { frontend: \u0026#39;dev.everyonecook.cloud\u0026#39;, api: \u0026#39;api-dev.everyonecook.cloud\u0026#39;, cdn: \u0026#39;cdn-dev.everyonecook.cloud\u0026#39;, }, apiGateway: { caching: { enabled: false, // Disabled in dev (enabled in prod) cacheSize: \u0026#39;0.5\u0026#39;, // 0.5GB cache (prod only) ttl: 300, // 5 minutes (prod only) }, compression: true, // Enabled in all environments throttling: { rateLimit: 10000, burstLimit: 5000, }, }, cloudwatch: { logRetentionDays: 7, // Dev: 7 days, Staging: 30 days, Prod: 90 days alarms: { enabled: true, }, }, // ... other configs } For Staging/Production: Update the --context environment= parameter in deployment commands.\nStep 2: Prepare Lambda Deployment Packages Before deploying, prepare the Lambda deployment packages for 8 Lambda functions + 1 Layer:\n# 1. Prepare Shared Layer FIRST (required by all Lambdas) cd D:\\Project_AWS\\everyonecook\\layers\\shared-dependencies .\\prepare-layer.ps1 # 2. Prepare Business Lambda Functions (6 functions) cd D:\\Project_AWS\\everyonecook\\services\\api-router .\\prepare-deployment-layer.ps1 # or prepare-deployment.ps1 cd D:\\Project_AWS\\everyonecook\\services\\auth-module .\\prepare-deployment-layer.ps1 cd D:\\Project_AWS\\everyonecook\\services\\social-module .\\prepare-deployment-layer.ps1 cd D:\\Project_AWS\\everyonecook\\services\\recipe-module .\\prepare-deployment-layer.ps1 cd D:\\Project_AWS\\everyonecook\\services\\admin-module .\\prepare-deployment-layer.ps1 cd D:\\Project_AWS\\everyonecook\\services\\upload-module .\\prepare-deployment-layer.ps1 # 3. Prepare Worker Lambda Functions (2 workers) cd D:\\Project_AWS\\everyonecook\\services\\ai-module .\\prepare-deployment.ps1 # AI Worker uses prepare-deployment.ps1 cd D:\\Project_AWS\\everyonecook\\services\\image-worker .\\prepare-deployment-layer.ps1 Important Notes:\nEach service must have a deployment/ folder after running prepare script Shared Layer must be built FIRST as all Lambdas depend on it Check for prepare-deployment.ps1 or prepare-deployment-layer.ps1 in each service folder Total deployment size: ~8MB → ~200KB per Lambda (thanks to Shared Layer) Step 3: Synthesize CloudFormation Template Generate the CloudFormation template to review changes:\n# Return to infrastructure directory cd D:\\Project_AWS\\everyonecook\\infrastructure # Synthesize template npx cdk synth EveryoneCook-dev-Backend --context environment=dev Expected output shows the CloudFormation template with all resources.\nStep 4: Deploy Backend Stack Deploy the Backend stack to AWS:\n# Deploy Backend Stack only npx cdk deploy EveryoneCook-dev-Backend --context environment=dev # Or deploy with approval npx cdk deploy EveryoneCook-dev-Backend --context environment=dev --require-approval never Expected output:\n✨ Synthesis time: 5.23s EveryoneCook-dev-Backend: deploying... [0%] start: Publishing abc123:current_account-current_region [33%] success: Published abc123:current_account-current_region [33%] start: Publishing def456:current_account-current_region [66%] success: Published def456:current_account-current_region [66%] start: Publishing EveryoneCook-dev-Backend [100%] success: Published EveryoneCook-dev-Backend EveryoneCook-dev-Backend: creating CloudFormation changeset... EveryoneCook-dev-Backend ✨ Deployment time: 420.15s Outputs: EveryoneCook-dev-Backend.ApiUrl = https://api-dev.everyonecook.cloud EveryoneCook-dev-Backend.ApiId = abc123xyz EveryoneCook-dev-Backend.ApiStage = api EveryoneCook-dev-Backend.ApiDomainName = api-dev.everyonecook.cloud EveryoneCook-dev-Backend.AIQueueUrl = https://sqs.ap-southeast-1.amazonaws.com/123456789/everyonecook-dev-ai-queue EveryoneCook-dev-Backend.ImageQueueUrl = https://sqs.ap-southeast-1.amazonaws.com/123456789/everyonecook-dev-image-queue EveryoneCook-dev-Backend.WafWebAclArn = arn:aws:wafv2:ap-southeast-1:123456789:regional/webacl/EveryoneCook-API-WAF-dev/... Stack ARN: arn:aws:cloudformation:ap-southeast-1:123456789:stack/EveryoneCook-dev-Backend/... ✨ Total time: 425.38s Deployment time: ~7 minutes (includes certificate validation)\nStep 5: Verify Deployment on AWS Console 5.1: Verify API Gateway Navigate to API Gateway Console Select region: ap-southeast-1 Click on EveryoneCook-API-dev API Gateway dashboard showing API name, stage, custom domain, caching status and throttling settings\nClick on Stages → api Verify stage settings: Cache Settings: Enabled (prod) / Disabled (dev) Cache capacity: 0.5 GB (prod only) Default TTL: 300 seconds (prod only) Throttling: 10000 requests/sec Burst: 5000 requests/sec Stage settings showing caching and throttling configuration\nClick on Custom domain names Verify custom domain: Domain name: api-dev.everyonecook.cloud Certificate: ACM certificate (Regional) Base path mapping: / → api stage Custom domain configuration with ACM certificate\n5.2: Verify Lambda Functions Navigate to Lambda Console Select region: ap-southeast-1 Verify all 8 Lambda functions exist: Function Name Runtime Memory Timeout Layer Source Code everyonecook-dev-api-router Node 20.x 512MB 30s SharedDependenciesLayer services/api-router everyonecook-dev-auth-user Node 20.x 512MB 30s SharedDependenciesLayer services/auth-module everyonecook-dev-social Node 20.x 512MB 30s SharedDependenciesLayer services/social-module everyonecook-dev-recipe-ai Node 20.x 512MB 30s SharedDependenciesLayer services/recipe-module everyonecook-dev-admin Node 20.x 512MB 30s SharedDependenciesLayer services/admin-module everyonecook-dev-upload Node 20.x 512MB 30s SharedDependenciesLayer services/upload-module everyonecook-dev-ai-worker Node 20.x 1024MB 60s SharedDependenciesLayer services/ai-module/workers everyonecook-dev-image-worker Node 20.x 512MB 60s SharedDependenciesLayer services/image-worker Lambda functions list showing all 8 functions with runtime and configuration\nClick on everyonecook-dev-api-router Verify configuration: Environment variables: DYNAMODB_TABLE, USER_POOL_ID, etc. Layers: SharedDependenciesLayer Triggers: API Gateway (Proxy integration) API Router function showing environment variables, layers, and API Gateway trigger\nClick on Monitoring tab Verify CloudWatch Logs integration: Log group: /aws/lambda/everyonecook-dev-api-router Retention: Based on environment config Lambda monitoring dashboard showing CloudWatch Logs and metrics\n5.3: Verify SQS Queues Navigate to SQS Console Select region: ap-southeast-1 Verify 4 active queues exist (2 main + 2 DLQs): Note: Only AI and Image queues are actively used. Analytics and Notification queues exist in code but are not deployed.\nQueue Name Type Visibility Timeout Retention DLQ Worker Status everyonecook-dev-ai-queue Main 2 minutes 4 days everyonecook-dev-ai-dlq Active everyonecook-dev-ai-dlq DLQ 5 minutes 14 days - - everyonecook-dev-image-queue Main 60 seconds 4 days everyonecook-dev-image-dlq Active everyonecook-dev-image-dlq DLQ 5 minutes 14 days - - SQS queues list showing 4 active queues: ai-queue, ai-dlq, image-queue, image-dlq\nClick on everyonecook-dev-ai-queue Verify queue configuration: Visibility timeout: 2 minutes Message retention: 4 days Dead-letter queue: everyonecook-dev-ai-dlq Maximum receives: 3 Encryption: KMS managed AI Queue configuration showing visibility timeout, retention, DLQ, and encryption settings\nClick on Lambda triggers tab Verify Lambda trigger: Function: everyonecook-dev-ai-worker Batch size: 1 Batch window: 0 seconds AI Queue Lambda trigger showing ai-worker function with batch configuration\n5.4: Verify WAF Web ACL Navigate to WAF \u0026amp; Shield Console Select region: ap-southeast-1 (Regional) Click on Web ACLs Click on EveryoneCook-API-WAF-dev WAF Web ACL dashboard for EveryoneCook API protection\nClick on Rules tab Verify all 5 rules exist: Priority Rule Name Type Action Status 0 RateLimitRule Rate-based Block Enabled 1 AWSManagedRulesSQLi Managed Block Enabled 2 AWSManagedRulesKnownBadInputs Managed Block Enabled 3 AWSManagedRulesCoreRuleSet Managed Block Enabled 4 RequestSizeLimit Size constraint Block Enabled 5.5: Verify CloudWatch Alarms Navigate to CloudWatch Console Select region: ap-southeast-1 Filter by: EveryoneCook-dev-Backend CloudWatch alarms for Backend Stack: Queue depth, Lambda errors/duration, WAF blocks\n5.6: Verify Route 53 DNS Record Navigate to Route 53 Console Click on Hosted zones Click on everyonecook.cloud Verify A record exists: Name: api-dev.everyonecook.cloud Type: A (Alias) Target: API Gateway domain name Routing policy: Simple Route 53 A record (Alias) pointing to API Gateway custom domain\nStep 6: Test API Endpoint Test the custom domain endpoint:\n# Test API Gateway health endpoint (if exists) curl https://api-dev.everyonecook.cloud/health # Or test with browser start https://api-dev.everyonecook.cloud Expected response (if health endpoint exists):\n{ \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, \u0026#34;environment\u0026#34;: \u0026#34;dev\u0026#34;, \u0026#34;timestamp\u0026#34;: \u0026#34;2024-01-15T10:30:00Z\u0026#34; } Environment Differences This guide uses Development (dev) environment as the example. Here are the key differences across environments:\nDomain Names Environment API Domain Frontend Domain Dev api-dev.everyonecook.cloud dev.everyonecook.cloud Staging api-staging.everyonecook.cloud staging.everyonecook.cloud Prod api.everyonecook.cloud everyonecook.cloud Resource Naming Resource Type Dev Staging Prod Stack Name EveryoneCook-dev-Backend EveryoneCook-staging-Backend EveryoneCook-prod-Backend API Gateway EveryoneCook-API-dev EveryoneCook-API-staging EveryoneCook-API-prod Lambda everyonecook-dev-auth-user everyonecook-staging-auth-user everyonecook-prod-auth-user SQS Queue everyonecook-dev-ai-queue everyonecook-staging-ai-queue everyonecook-prod-ai-queue WAF EveryoneCook-API-WAF-dev EveryoneCook-API-WAF-staging EveryoneCook-API-WAF-prod Configuration Differences Setting Dev Staging Production API Caching Disabled Disabled Enabled (0.5GB) Data Trace Logging Enabled Enabled Disabled Log Retention 7 days 30 days 90 days CloudWatch Removal DESTROY DESTROY RETAIN WAF Rate Limit 2000 req/5min 2000 req/5min 5000 req/5min Lambda Log Level DEBUG INFO INFO CORS Localhost Allowed Not allowed Not allowed Deployment Commands # Development npx cdk deploy EveryoneCook-dev-Backend --context environment=dev # Staging npx cdk deploy EveryoneCook-staging-Backend --context environment=staging # Production (requires approval) npx cdk deploy EveryoneCook-prod-Backend --context environment=prod --require-approval broadening Environment-Specific Considerations Development CORS allows http://localhost:3000 for local frontend testing Data trace logging enabled for debugging Lower log retention (7 days) to reduce costs Resources deleted on stack removal (RemovalPolicy.DESTROY) Staging Production-like configuration for pre-release testing Separate domain to avoid production interference Same security rules as production Resources deleted on stack removal Production API Gateway caching enabled (0.5GB, 5-min TTL) Data trace logging disabled (cost optimization) 90-day log retention for compliance Resources retained on stack removal (RemovalPolicy.RETAIN) Stricter WAF rate limits No localhost CORS Cost Analysis Monthly Cost Breakdown (Dev Environment) Service Configuration Monthly Cost API Gateway 1M requests, caching disabled ~$3.50 Lambda (6 functions) 512MB, 1M invocations, 200ms avg ~$8.40 Lambda (2 workers) 512-1024MB, 10K invocations ~$0.42 SQS (2 queues) 10K messages/month ~$0.03 WAF Web ACL 1 ACL + 5 rules + 1M requests ~$10.60 CloudWatch Logs 5GB ingestion, 30-day retention ~$2.50 CloudWatch Alarms 10 alarms ~$1.00 Total Backend Stack ~$26.45/month Production Cost Estimate Service Configuration Monthly Cost API Gateway 10M requests, caching enabled (0.5GB) ~$50.00 Lambda (6 functions) 512MB, 10M invocations, 200ms avg ~$84.00 Lambda (2 workers) 512-1024MB, 100K invocations ~$4.20 SQS (2 queues) 100K messages/month ~$0.25 WAF Web ACL 1 ACL + 5 rules + 10M requests ~$16.00 CloudWatch Logs 20GB ingestion, 90-day retention ~$10.00 CloudWatch Alarms 15 alarms ~$1.50 Total Backend Stack ~$165.95/month Next Steps After deploying the Backend Stack:\nDeploy Frontend Stack (Phase 5) - Next.js application on CloudFront Deploy Observability Stack (Phase 6) - CloudWatch dashboards and alarms Test API Integration - Verify all endpoints work correctly Load Testing - Test performance and scaling Security Audit - Review WAF rules and access controls References Infrastructure Code Backend Stack: infrastructure/lib/stacks/backend-stack.ts (2965 lines) Shared Layer Construct: infrastructure/lib/constructs/shared-layer.ts Lambda Function Source Code (6 Business Functions) API Router: services/api-router/ - Request routing \u0026amp; JWT validation Auth User Module: services/auth-module/ - Authentication \u0026amp; user profiles Social Module: services/social-module/ - Posts, comments, friends, notifications Recipe AI Module: services/recipe-module/ - Recipe CRUD, AI generation, search Admin Module: services/admin-module/ - Content moderation, user management Upload Module: services/upload-module/ - S3 presigned URLs, file uploads Worker Lambda Source Code (2 Active Workers) AI Worker: services/ai-module/workers/ - Bedrock Claude 3 Haiku integration Image Worker: services/image-worker/ - Image optimization (resize, compress) Shared Dependencies Shared Layer: layers/shared-dependencies/ - AWS SDK v3, uuid, jsonwebtoken, jwks-rsa Other Services (Not in Backend Stack) WebSocket Module: services/websocket-module/ - Real-time communication (separate stack) Shared Utilities: services/shared/ - Common utilities across services Summary The Backend Stack is the largest and most complex stack in the EveryoneCook infrastructure. It consolidates:\nAPI Gateway with custom domain (caching in prod only) 6 Lambda functions for business logic 2 active SQS queues for async processing (4 total with DLQs) 2 worker Lambda functions (AI Worker, Image Worker) WAF Web ACL for security (5 protection rules) CloudWatch monitoring and alarms Actually Deployed: 8 Lambda functions, 4 SQS queues (2 active with workers), 1 WAF Web ACL, CloudWatch alarms\nDevelopment Environment Checklist Prepare all Lambda deployment packages (8 functions + 1 layer) Review dev environment configuration Verify caching is disabled (prod only) Test each Lambda function independently Monitor CloudWatch alarms Verify WAF rules don\u0026rsquo;t block legitimate traffic Test localhost CORS (dev only) For Staging/Production Deployment Review Environment Differences Enable API Gateway caching (prod only) Disable data trace logging (prod only) Set appropriate log retention (90 days for prod) Update WAF rate limits (higher for prod) Remove localhost from CORS Use --require-approval broadening for production Deployment Order: DNS → Certificate → Core → Auth → Backend → Frontend → Observability\nEnvironments: This guide demonstrates dev deployment. Repeat for staging and prod with appropriate configurations.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.06-configure-api-lambda/","title":"Configure API &amp; Lambda","tags":[],"description":"","content":"Overview After deploying infrastructure, you need to configure API Gateway routes and Lambda functions to handle business logic.\nAPI Architecture API Gateway (api.everyonecook.cloud) ↓ API Router Lambda (entry point) ↓ ┌─────────┬─────────┬─────────┬─────────┬─────────┐ │ Auth │ Social │ Recipe │ Admin │ Upload │ │ Module │ Module │ AI │ Module │ Module │ └─────────┴─────────┴─────────┴─────────┴─────────┘ ↓ ↓ ↓ ↓ ↓ DynamoDB DynamoDB Bedrock DynamoDB S3 Step 1: Review API Routes API Router Structure:\n// services/api-router/routes/index.ts export const routes = { // Auth routes \u0026#39;POST /auth/register\u0026#39;: \u0026#39;auth-module\u0026#39;, \u0026#39;POST /auth/login\u0026#39;: \u0026#39;auth-module\u0026#39;, \u0026#39;GET /auth/profile\u0026#39;: \u0026#39;auth-module\u0026#39;, \u0026#39;PUT /auth/profile\u0026#39;: \u0026#39;auth-module\u0026#39;, // Social routes \u0026#39;GET /social/posts\u0026#39;: \u0026#39;social-module\u0026#39;, \u0026#39;POST /social/posts\u0026#39;: \u0026#39;social-module\u0026#39;, \u0026#39;GET /social/posts/:id\u0026#39;: \u0026#39;social-module\u0026#39;, \u0026#39;POST /social/posts/:id/like\u0026#39;: \u0026#39;social-module\u0026#39;, // Recipe routes \u0026#39;GET /recipes\u0026#39;: \u0026#39;recipe-module\u0026#39;, \u0026#39;POST /recipes\u0026#39;: \u0026#39;recipe-module\u0026#39;, \u0026#39;POST /ai/generate-recipe\u0026#39;: \u0026#39;recipe-module\u0026#39;, \u0026#39;POST /ai/search\u0026#39;: \u0026#39;recipe-module\u0026#39;, // Admin routes \u0026#39;GET /admin/users\u0026#39;: \u0026#39;admin-module\u0026#39;, \u0026#39;POST /admin/users/:id/ban\u0026#39;: \u0026#39;admin-module\u0026#39;, // Upload routes \u0026#39;POST /upload/presigned-url\u0026#39;: \u0026#39;upload-module\u0026#39;, \u0026#39;POST /upload/complete\u0026#39;: \u0026#39;upload-module\u0026#39; }; Step 2: Configure Lambda Modules 1. Auth Module\ncd services/auth-module # Review configuration cat package.json cat tsconfig.json # Check environment variables needed cat index.ts | grep process.env Environment Variables:\nTABLE_NAME: DynamoDB table name USER_POOL_ID: Cognito User Pool ID REGION: AWS region 2. Social Module\ncd services/social-module # Review handlers ls handlers/ # - posts.handler.ts # - comments.handler.ts # - reactions.handler.ts # - friends.handler.ts 3. Recipe/AI Module\ncd services/recipe-module # Check AI configuration cat services/ai.service.ts Environment Variables:\nBEDROCK_MODEL_ID: Claude 3.5 Sonnet v2 BEDROCK_REGION: us-east-1 OPENSEARCH_ENDPOINT: OpenSearch domain (if enabled) 4. Admin Module\ncd services/admin-module # Review admin operations ls handlers/ 5. Upload Module\ncd services/upload-module # Check S3 configuration cat services/s3.service.ts Environment Variables:\nCONTENT_BUCKET: S3 content bucket name CLOUDFRONT_DOMAIN: CloudFront domain CLOUDFRONT_KEY_PAIR_ID: For signed URLs Step 3: Configure Lambda Layers Shared Dependencies:\ncd services/shared # Review shared code ls -la # - repositories/ # - business-logic/ # - utils/ # - types/ Lambda Layer Structure:\nshared/ ├── repositories/ │ ├── user.repository.ts │ ├── post.repository.ts │ └── recipe.repository.ts ├── business-logic/ │ ├── auth.logic.ts │ └── validation.logic.ts └── utils/ ├── dynamodb.utils.ts └── response.utils.ts Step 4: Set Lambda Environment Variables 1. Get Stack Outputs\n# Get DynamoDB table name TABLE_NAME=$(aws cloudformation describe-stacks \\ --stack-name EveryoneCook-dev-Core \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`DynamoDBTableName`].OutputValue\u0026#39; \\ --output text) # Get User Pool ID USER_POOL_ID=$(aws cloudformation describe-stacks \\ --stack-name EveryoneCook-dev-Auth \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue\u0026#39; \\ --output text) # Get Content Bucket CONTENT_BUCKET=$(aws cloudformation describe-stacks \\ --stack-name EveryoneCook-dev-Core \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ContentBucketName`].OutputValue\u0026#39; \\ --output text) echo \u0026#34;TABLE_NAME=$TABLE_NAME\u0026#34; echo \u0026#34;USER_POOL_ID=$USER_POOL_ID\u0026#34; echo \u0026#34;CONTENT_BUCKET=$CONTENT_BUCKET\u0026#34; 2. Update Lambda Environment Variables\nLambda environment variables được set tự động bởi CDK stack, nhưng bạn có thể verify:\n# Check Auth Module environment variables aws lambda get-function-configuration \\ --function-name EveryoneCook-dev-AuthModule \\ --query \u0026#39;Environment.Variables\u0026#39; # Should show: # { # \u0026#34;TABLE_NAME\u0026#34;: \u0026#34;EveryoneCook-dev\u0026#34;, # \u0026#34;USER_POOL_ID\u0026#34;: \u0026#34;us-east-1_ABC123\u0026#34;, # \u0026#34;REGION\u0026#34;: \u0026#34;us-east-1\u0026#34; # } Step 5: Configure API Gateway 1. Review API Gateway Configuration\n# Get API Gateway ID API_ID=$(aws cloudformation describe-stacks \\ --stack-name EveryoneCook-dev-Backend \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiId`].OutputValue\u0026#39; \\ --output text) # Get API details aws apigateway get-rest-api --rest-api-id $API_ID 2. Check Cognito Authorizer\n# List authorizers aws apigateway get-authorizers --rest-api-id $API_ID # Should show Cognito User Pool authorizer 3. Verify Custom Domain\n# Check custom domain mapping aws apigateway get-domain-name --domain-name api.everyonecook.cloud # Should show: # - Domain name: api.everyonecook.cloud # - Certificate ARN # - Regional domain name Step 6: Configure SQS Queues 1. List All Queues\n# List SQS queues aws sqs list-queues | grep EveryoneCook-dev # Should show 12 queues (6 main + 6 DLQ) 2. Configure Queue Permissions\nPermissions được set tự động bởi CDK, verify:\n# Get AI Queue URL AI_QUEUE_URL=$(aws sqs list-queues \\ --queue-name-prefix EveryoneCook-dev-AIQueue \\ | jq -r \u0026#39;.QueueUrls[0]\u0026#39;) # Check queue attributes aws sqs get-queue-attributes \\ --queue-url $AI_QUEUE_URL \\ --attribute-names All Step 7: Configure Lambda Triggers Cognito Lambda Triggers:\n# Check User Pool triggers aws cognito-idp describe-user-pool \\ --user-pool-id $USER_POOL_ID \\ --query \u0026#39;UserPool.LambdaConfig\u0026#39; # Should show 5 triggers: # - PreSignUp # - PostConfirmation # - PreAuthentication # - PostAuthentication # - CustomMessage Step 8: Test Lambda Functions Locally 1. Test Auth Module\ncd services/auth-module # Run tests npm test # Test specific handler npm run test:unit -- handlers/profile.test.ts 2. Test API Router\ncd services/api-router # Test routing logic npm test # Test with sample event node -e \u0026#34; const handler = require(\u0026#39;./dist/index\u0026#39;).handler; const event = { httpMethod: \u0026#39;GET\u0026#39;, path: \u0026#39;/health\u0026#39;, headers: {} }; handler(event).then(console.log); \u0026#34; Step 9: Verify IAM Permissions 1. Check Lambda Execution Roles\n# List Lambda functions aws lambda list-functions \\ --query \u0026#39;Functions[?contains(FunctionName, `EveryoneCook-dev`)].FunctionName\u0026#39; # Check role for Auth Module aws lambda get-function \\ --function-name EveryoneCook-dev-AuthModule \\ --query \u0026#39;Configuration.Role\u0026#39; 2. Verify DynamoDB Permissions\n# Get role name ROLE_NAME=$(aws lambda get-function \\ --function-name EveryoneCook-dev-AuthModule \\ --query \u0026#39;Configuration.Role\u0026#39; \\ --output text | cut -d\u0026#39;/\u0026#39; -f2) # List attached policies aws iam list-attached-role-policies --role-name $ROLE_NAME # Should include DynamoDB access policy Configuration Checklist API routes reviewed and understood Lambda modules structure reviewed Environment variables verified Lambda layers configured API Gateway custom domain working Cognito authorizer configured SQS queues created and accessible Lambda triggers attached to Cognito IAM permissions verified Local tests passing Next Steps Once configuration is complete, proceed to Deploy Backend Services to deploy your Lambda code.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.6-week6/","title":"Week 6 Worklog","tags":[],"description":"","content":"Week 6 Objectives Master IAM, AWS Organizations, and Service Control Policies (SCPs). Learn encryption with KMS, ACM, and Secrets Manager. Understand S3 security, VPC networking, CloudFront, and DR strategies. Tasks for the Week Day Task Start Date Completion Date Reference Material 2 IAM, Account Security \u0026amp; AWS Organizations 10/16/2025 10/16/2025 Reference Document 3 Encryption, KMS, ACM \u0026amp; Secrets Manager 10/17/2025 10/17/2025 cont 4 S3 Storage, Security, Lifecycle \u0026amp; Replication 10/18/2025 10/18/2025 cont 5 VPC \u0026amp; Networking Security (SG, NACL, VPN, DX) 10/19/2025 10/19/2025 cont 6 CloudFront/GA, DR \u0026amp; Backup/Migration 10/20/2025 10/20/2025 cont Week 6 Achievements IAM – Identity and Access Management Key Points:\nRoot account: setup only, never shared IAM Users: represent people/services; IAM Groups organize users Policies (JSON): define permissions; follow Least Privilege Access methods: Console (password + MFA), CLI/SDK (Access Keys) IAM Roles: grant permissions to AWS services (EC2, Lambda, etc.) Security Tools \u0026amp; Best Practices:\nCredentials Report: lists all users and their credentials status Access Advisor: shows last-used permissions Best practices: no shared users/keys, enforce MFA, use groups, use roles, audit regularly AWS Organizations Key Points:\nManage multiple AWS accounts centrally Management account: full access; Member accounts: controlled accounts Consolidated billing: shared cost savings (RI, Savings Plans) OUs group accounts for management Service Control Policies (SCP):\nSCP limits maximum permissions; does not grant access Action allowed only if IAM Allow + SCP Allow Applies to OUs and member accounts (not management account) Encryption, KMS, ACM \u0026amp; Secrets Manager Encryption Basics:\nEncryption in transit → HTTPS/TLS prevents eavesdropping Encryption at rest → data is encrypted before being stored AWS KMS:\nCentral service for managing encryption keys Supports symmetric (AES-256) \u0026amp; asymmetric keys (RSA/ECC) Key types: AWS-Owned, AWS-Managed, Customer-Managed, Imported Keys Key Policies control access → required for using the key Multi-Region Keys: same logical key replicated across regions Copying snapshots across regions → must re-encrypt with a key in the target region ACM (AWS Certificate Manager):\nIssues and manages TLS/SSL certificates Free public certificates, automatic renewal Integrates with ALB, CloudFront, API Gateway Cannot export ACM public certificates to EC2 Secrets Manager:\nSecure storage for secrets (passwords, API keys) Secrets encrypted using KMS Supports automatic rotation (integrated with RDS/Aurora) Multi-Region replication for HA/DR S3 Storage, Security, Lifecycle \u0026amp; Replication S3 Basics:\nStores objects in buckets; bucket is regional Very high durability (11 nines) Security via IAM policies, bucket policies, ACLs Storage Classes:\nStandard, Standard-IA, One-Zone-IA Glacier tiers: Instant, Flexible, Deep Archive Intelligent-Tiering automatically moves data based on access Lifecycle Rules:\nTransition actions → move objects to cheaper storage Expiration actions → delete old objects/versions Replication:\nRequires versioning on both buckets CRR = cross-region; SRR = same-region Only new objects replicate (old ones use batch replication) Delete markers optional; no replication chaining S3 Security:\nEncryption options: SSE-S3, SSE-KMS, SSE-C, Client-Side Enforce HTTPS using aws:SecureTransport Object Lock (WORM) \u0026amp; Glacier Vault Lock for compliance VPC \u0026amp; Networking Security VPC Core:\nVPC = private network; CIDR must not overlap Subnets are AZ-specific; public = IGW, private = NAT Gateway Route tables define traffic flow NAT Gateway → outbound Internet for private subnets Bastion Host → SSH into private EC2 instances Security Controls:\nSecurity Groups: instance-level, stateful, allow-only NACLs: subnet-level, stateless, allow \u0026amp; deny, ordered rules VPC Flow Logs → capture traffic for analysis Connectivity:\nVPC Peering: private connection between two VPCs (non-transitive) Endpoints: Gateway Endpoint → S3, DynamoDB (free) Interface Endpoint → PrivateLink (paid), ENI-based Site-to-Site VPN: IPsec tunnel On-Prem ↔ AWS CloudHub: connect multiple branch sites via AWS Direct Connect: dedicated physical link; optional encryption via VPN Threat Detection:\nGuardDuty: ML-based threat detection using CloudTrail, Flow Logs, DNS AWS Shield Standard/Advanced: DDoS protection CloudFront, Global Accelerator, DR \u0026amp; Migration CloudFront (CDN):\nCaches content at edge locations using Anycast IP Works with S3, ALB, EC2, custom origins Supports geo-restrictions, cache invalidation Global Accelerator:\nSpeeds up TCP/UDP apps using AWS backbone network Provides two global Anycast IPs Improves latency and failover across regions Disaster Recovery (DR):\nRPO = acceptable data loss; RTO = acceptable downtime DR strategies: Backup \u0026amp; Restore Pilot Light Warm Standby Multi-Region Active/Active More resilience = higher cost Backup \u0026amp; Migration:\nAWS Backup: centralized backup, cross-account/region, Vault Lock (WORM) Snowball: offline large-scale data transfer DMS/SMS: migrate databases \u0026amp; servers to AWS Application Discovery: analyze on-prem systems before migration "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/6-self-evaluation/","title":"Self-Assessment","tags":[],"description":"","content":"Throughout my internship at Amazon Web Services Vietnam Co., Ltd. from September 8, 2025 to November 12, 2025, I gained valuable hands-on experience that bridged the gap between academic learning and real-world application. I was involved in exploring AWS cloud technologies and collaborating with team members to develop a practical project, which significantly enhanced my capabilities in software development, cloud architecture, technical documentation, and team collaboration.\nRegarding my professional attitude, I consistently aimed to deliver quality work, followed organizational guidelines, and maintained positive interactions with colleagues to foster a productive working environment.\nTo provide an honest reflection of my internship experience, I assess myself according to the following criteria:\nNo. Criteria Description Good Fair Average 1 Professional knowledge \u0026amp; skills Comprehension of the domain, practical application of knowledge, tool proficiency, and output quality ☐ ☑ ☐ 2 Ability to learn Capacity to acquire new knowledge and adapt to learning requirements efficiently ☐ ☑ ☐ 3 Proactiveness Self-motivation in pursuing tasks and taking action without constant supervision ☑ ☐ ☐ 4 Sense of responsibility Commitment to meeting deadlines and maintaining work standards ☑ ☐ ☐ 5 Discipline Compliance with schedules, guidelines, and established workflows ☐ ☑ ☐ 6 Progressive mindset Openness to constructive criticism and dedication to self-improvement ☐ ☑ ☐ 7 Communication Effectiveness in articulating ideas and providing clear work updates ☐ ☑ ☐ 8 Teamwork Ability to collaborate productively and contribute to team objectives ☑ ☐ ☐ 9 Professional conduct Maintaining respect for colleagues, stakeholders, and workplace norms ☑ ☐ ☐ 10 Problem-solving skills Capability to analyze challenges, develop solutions, and think creatively ☐ ☑ ☐ 11 Contribution to project/team Overall impact, innovative input, and acknowledgment from team members ☐ ☑ ☐ 12 Overall Comprehensive assessment of the entire internship experience ☐ ☑ ☐ Areas for Improvement Develop stronger self-discipline and ensure full adherence to company policies and professional standards Enhance analytical and critical thinking abilities when approaching complex problems Improve verbal and written communication skills for more effective collaboration in professional settings Build greater confidence in presenting ideas and handling challenging situations independently "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.6-frontend-stack/","title":"5.4.6 Frontend Stack","tags":[],"description":"","content":" Frontend Stack - AWS Amplify Hosting Overview The Frontend Stack handles Next.js 15 application deployment using AWS Amplify. Unlike other stacks managed by CDK, the Frontend is deployed through Amplify Console with GitLab integration for automatic deployment.\nDeployment Method: AWS Amplify Console (not a CDK stack)\n⚠️ Important Note: Frontend deployment is performed separately through Amplify Console. See details at 5.10 Deploy to Amplify.\nKey Responsibilities Host Next.js 15 SSR application Automatic deployment from GitLab repository Custom domain configuration with Route 53 Automatic SSL certificate via ACM Global CDN distribution Environment variables management What This Stack Includes Next.js Application:\nFramework: Next.js 15 with React 18 Rendering: Standalone output mode (SSR) Styling: Tailwind CSS + Flowbite components State Management: React Context API Authentication: AWS Amplify Auth (Cognito integration) AWS Amplify Features:\nAutomatic build and deploy from Git Server-side rendering (SSR) support Custom domain with HTTPS CDN caching and compression Environment variables injection GitLab CI/CD integration Architecture ┌─────────────────────────────────────────────────────────────────┐ │ GitLab Repository │ │ (everyonecook/frontend) │ │ │ │ Push to main/dev branch │ └──────────────────────────┬──────────────────────────────────────┘ │ Webhook Trigger ▼ ┌─────────────────────────────────────────────────────────────────┐ │ AWS Amplify (Hosting + CI/CD) │ │ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Build Pipeline (Auto-triggered) │ │ │ │ 1. Clone repository from GitLab │ │ │ │ 2. npm install (with legacy peer deps) │ │ │ │ 3. Inject environment variables → .env.production │ │ │ │ 4. npm run build (Next.js standalone build) │ │ │ │ 5. Deploy to Amplify CDN │ │ │ └──────────────────────────────────────────────────────────┘ │ │ │ │ ┌──────────────────────────────────────────────────────────┐ │ │ │ Hosting Configuration │ │ │ │ • CDN Distribution (CloudFront) │ │ │ │ • SSR Lambda@Edge functions │ │ │ │ • Custom domain: dev.everyonecook.cloud │ │ │ │ • SSL Certificate (ACM - auto-provisioned) │ │ │ │ • Custom headers (security) │ │ │ │ • Custom rewrites (Next.js routing) │ │ │ └──────────────────────────────────────────────────────────┘ │ └──────────────────────────┬──────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────────┐ │ Route 53 (DNS) │ │ dev.everyonecook.cloud → A Record → Amplify CDN │ │ www.dev.everyonecook.cloud → CNAME → Amplify CDN │ └─────────────────────────────────────────────────────────────────┘ │ ▼ ┌─────────────────────────────────────────────────────────────────┐ │ End Users (Global) │ │ Access via: https://dev.everyonecook.cloud │ └─────────────────────────────────────────────────────────────────┘ Frontend Configuration File Structure frontend/ ├── amplify.yml # Amplify build configuration ├── next.config.js # Next.js configuration ├── package.json # Dependencies \u0026amp; scripts ├── .env.example # Environment variables template ├── app/ # Next.js App Router │ ├── layout.tsx # Root layout │ ├── page.tsx # Home page │ ├── auth/ # Authentication pages │ ├── profile/ # User profile │ ├── recipes/ # Recipe pages │ └── ... ├── components/ # Reusable React components ├── contexts/ # React Context providers ├── hooks/ # Custom React hooks ├── lib/ # Utility functions ├── services/ # API service layer └── types/ # TypeScript definitions 1. Amplify Build Configuration File: amplify.yml (root directory)\n⚠️ Important: Amplify uses the amplify.yml file at the repository root, not in the frontend/ folder.\nversion: 1 applications: - frontend: phases: preBuild: commands: - export HUSKY=0 - npm install --legacy-peer-deps --ignore-scripts build: commands: - echo \u0026#34;=== Creating .env.production from Amplify env vars ===\u0026#34; - rm -f .env.production - env | grep -e NEXT_PUBLIC_ \u0026gt; .env.production || true - echo \u0026#34;=== .env.production content ===\u0026#34; - cat .env.production - echo \u0026#34;=== Building frontend ===\u0026#34; - npm run build artifacts: baseDirectory: .next files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* - .next/cache/**/* appRoot: frontend Additional Configuration in frontend/amplify.yml:\nThe frontend/amplify.yml file contains additional security headers and custom rewrites (can be merged into root amplify.yml if needed):\ncustomHeaders: - pattern: \u0026#39;**/*\u0026#39; headers: - key: \u0026#39;Strict-Transport-Security\u0026#39; value: \u0026#39;max-age=31536000; includeSubDomains\u0026#39; - key: \u0026#39;X-Content-Type-Options\u0026#39; value: \u0026#39;nosniff\u0026#39; - key: \u0026#39;X-Frame-Options\u0026#39; value: \u0026#39;DENY\u0026#39; - key: \u0026#39;X-XSS-Protection\u0026#39; value: \u0026#39;1; mode=block\u0026#39; customRules: # Handle dynamic routes [id] - rewrite non-file requests to Next.js - source: \u0026#39;\u0026lt;/^[^.]+$|\\.(?!(css|gif|ico|jpg|jpeg|js|json|png|txt|svg|woff|woff2|ttf|map|webp|avif)$)([^.]+$)/\u0026gt;\u0026#39; target: /index.html status: \u0026#39;200\u0026#39; # Preserve static assets - source: \u0026#39;/_next/\u0026lt;*\u0026gt;\u0026#39; target: \u0026#39;/_next/\u0026lt;*\u0026gt;\u0026#39; status: \u0026#39;200\u0026#39; - source: \u0026#39;/api/\u0026lt;*\u0026gt;\u0026#39; target: \u0026#39;/api/\u0026lt;*\u0026gt;\u0026#39; status: \u0026#39;200\u0026#39; Key Points:\nappRoot: frontend: Source code in the frontend/ directory Build artifacts: .next directory (Next.js standalone build) Root amplify.yml: Build configuration only Frontend amplify.yml: Includes security headers + custom rewrites Recommendation: Merge customHeaders and customRules into root amplify.yml for centralized configuration 2. Next.js Configuration File: frontend/next.config.js\n/** @type {import(\u0026#39;next\u0026#39;).NextConfig} */ const nextConfig = { reactStrictMode: true, // Output mode for Amplify SSR deployment output: \u0026#39;standalone\u0026#39;, // Performance optimizations poweredByHeader: false, compress: true, trailingSlash: false, // Image optimization images: { remotePatterns: [ { protocol: \u0026#39;https\u0026#39;, hostname: \u0026#39;cdn-dev.everyonecook.cloud\u0026#39;, pathname: \u0026#39;/**\u0026#39;, }, ], formats: [\u0026#39;image/avif\u0026#39;, \u0026#39;image/webp\u0026#39;], deviceSizes: [640, 750, 828, 1080, 1200, 1920, 2048, 3840], }, // Optimize bundle experimental: { optimizePackageImports: [\u0026#39;react-icons\u0026#39;, \u0026#39;flowbite-react\u0026#39;, \u0026#39;aws-amplify\u0026#39;], optimizeCss: true, }, // Environment variables (fallback values) env: { NEXT_PUBLIC_API_URL: process.env.NEXT_PUBLIC_API_URL || \u0026#39;https://api-dev.everyonecook.cloud\u0026#39;, NEXT_PUBLIC_CDN_URL: process.env.NEXT_PUBLIC_CDN_URL || \u0026#39;https://cdn-dev.everyonecook.cloud\u0026#39;, NEXT_PUBLIC_COGNITO_USER_POOL_ID: process.env.NEXT_PUBLIC_COGNITO_USER_POOL_ID, NEXT_PUBLIC_COGNITO_CLIENT_ID: process.env.NEXT_PUBLIC_COGNITO_CLIENT_ID, NEXT_PUBLIC_COGNITO_REGION: process.env.NEXT_PUBLIC_COGNITO_REGION || \u0026#39;ap-southeast-1\u0026#39;, }, }; module.exports = nextConfig; Key Points:\noutput: 'standalone': Optimized build for Amplify Image optimization: Support for AVIF, WebP formats CDN integration: Load images from CloudFront CDN Environment variables: Injected from Amplify Console 3. Dependencies File: frontend/package.json\n{ \u0026#34;name\u0026#34;: \u0026#34;everyonecook-frontend\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;scripts\u0026#34;: { \u0026#34;dev\u0026#34;: \u0026#34;next dev --turbo\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;next build\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;next start\u0026#34; }, \u0026#34;dependencies\u0026#34;: { \u0026#34;next\u0026#34;: \u0026#34;^15.0.0\u0026#34;, \u0026#34;react\u0026#34;: \u0026#34;^18.3.0\u0026#34;, \u0026#34;react-dom\u0026#34;: \u0026#34;^18.3.0\u0026#34;, \u0026#34;aws-amplify\u0026#34;: \u0026#34;^6.15.8\u0026#34;, \u0026#34;@aws-amplify/auth\u0026#34;: \u0026#34;^6.17.0\u0026#34;, \u0026#34;axios\u0026#34;: \u0026#34;^1.13.2\u0026#34;, \u0026#34;flowbite-react\u0026#34;: \u0026#34;^0.7.0\u0026#34;, \u0026#34;react-icons\u0026#34;: \u0026#34;^5.0.1\u0026#34; }, \u0026#34;devDependencies\u0026#34;: { \u0026#34;typescript\u0026#34;: \u0026#34;^5.3.0\u0026#34;, \u0026#34;tailwindcss\u0026#34;: \u0026#34;^3.4.18\u0026#34;, \u0026#34;autoprefixer\u0026#34;: \u0026#34;^10.4.22\u0026#34; } } Key Dependencies:\nNext.js 15: Latest SSR framework AWS Amplify: Authentication \u0026amp; API integration Flowbite React: UI component library Tailwind CSS: Utility-first CSS framework 4. Environment Variables File: frontend/.env.example\n# API Configuration NEXT_PUBLIC_API_URL=https://api-dev.everyonecook.cloud # CDN Configuration NEXT_PUBLIC_CDN_URL=https://cdn-dev.everyonecook.cloud # AWS Cognito Configuration NEXT_PUBLIC_COGNITO_USER_POOL_ID=ap-southeast-1_XXXXXXXXX NEXT_PUBLIC_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxx NEXT_PUBLIC_COGNITO_REGION=ap-southeast-1 # Environment NEXT_PUBLIC_ENV=development Important: These variables must be configured in Amplify Console \u0026gt; Environment Variables.\nDeployment Configuration Domain Configuration Environment Frontend Domain Backend API CDN Dev dev.everyonecook.cloud api-dev.everyonecook.cloud cdn-dev.everyonecook.cloud Staging staging.everyonecook.cloud api-staging.everyonecook.cloud cdn-staging.everyonecook.cloud Prod everyonecook.cloud api.everyonecook.cloud cdn.everyonecook.cloud Amplify Configuration Build Settings:\nNode.js version: 18.x (auto-detected) Build timeout: 15 minutes Build image: Amazon Linux 2023 Cache: node_modules + .next/cache Deployment Settings:\nAuto-deploy: Enabled (on Git push) Branch: main (prod), dev (development) Build mode: Server-side rendering (SSR) Integration with Other Stacks Dependencies Frontend requires outputs from:\nDNS Stack (Phase 1):\nRoute 53 Hosted Zone ID Domain name configuration Certificate Stack (Phase 1.5):\nACM Certificate cho custom domain (CloudFront - us-east-1) Amplify sẽ tự động provision certificate Auth Stack (Phase 3):\nCOGNITO_USER_POOL_ID: User Pool ID COGNITO_CLIENT_ID: App Client ID COGNITO_REGION: AWS Region Backend Stack (Phase 4):\nAPI_URL: API Gateway custom domain API endpoints configuration Core Stack (Phase 2):\nCDN_URL: CloudFront distribution domain S3 bucket for image uploads Cross-Stack References Frontend uses environment variables to connect with backend:\n// services/api.ts const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL; // From Backend Stack const CDN_URL = process.env.NEXT_PUBLIC_CDN_URL; // From Core Stack // lib/auth.ts const cognitoConfig = { userPoolId: process.env.NEXT_PUBLIC_COGNITO_USER_POOL_ID, // From Auth Stack userPoolClientId: process.env.NEXT_PUBLIC_COGNITO_CLIENT_ID, // From Auth Stack region: process.env.NEXT_PUBLIC_COGNITO_REGION, }; Deployment Process Prerequisites Before deploying the frontend, ensure the following are completed:\n✅ DNS Stack deployed (Route 53 Hosted Zone) ✅ Core Stack deployed (S3 + CloudFront CDN) ✅ Auth Stack deployed (Cognito User Pool) ✅ Backend Stack deployed (API Gateway + Lambda) ✅ GitLab repository configured ✅ AWS Amplify connected to GitLab Deployment Steps Frontend is deployed through Amplify Console, NOT through CDK.\nFor deployment details, see: 5.10 Deploy to Amplify\nSummary of steps:\nCreate Amplify App via AWS Console Connect GitLab repository (everyonecook) Configure build settings (amplify.yml) Set environment variables (Cognito, API, CDN URLs) Configure custom domain (dev.everyonecook.cloud) Deploy automatically on Git push ⚠️ Note: After successful deployment, you need to:\n✅ Verify DNS records in Route 53 ✅ Test SSL certificate ✅ Verify custom domain is working ✅ Test authentication flow with Cognito Verification 1. Check Amplify Console 📸 Screenshot Required: AWS Console \u0026gt; Amplify \u0026gt; App Overview\nVerify:\nBuild status: Success Deployment status: Live Custom domain: Active SSL certificate: Issued Screenshot: Amplify Console showing successful deployment\n2. Check Route 53 DNS 📸 Screenshot Required: AWS Console \u0026gt; Route 53 \u0026gt; Hosted Zone\nVerify DNS records:\ndev.everyonecook.cloud A → Amplify CDN www.dev.everyonecook.cloud CNAME → Amplify CDN Screenshot: Route 53 showing Amplify DNS records\n3. Test Frontend Application Access URL:\n# Via custom domain https://dev.everyonecook.cloud # Via Amplify default domain https://main.d1234567890.amplifyapp.com Test Features:\nHomepage loads successfully HTTPS certificate valid User registration works Login with Cognito API calls to backend Images load from CDN 📸 Screenshot Required: Browser showing frontend homepage with DevTools Network tab\nScreenshot: Frontend homepage loaded successfully\n4. Verify Environment Variables 📸 Screenshot Required: Amplify Console \u0026gt; Environment Variables\nVerify all required variables:\nNEXT_PUBLIC_API_URL=https://api-dev.everyonecook.cloud NEXT_PUBLIC_CDN_URL=https://cdn-dev.everyonecook.cloud NEXT_PUBLIC_COGNITO_USER_POOL_ID=ap-southeast-1_XXXXXXXXX NEXT_PUBLIC_COGNITO_CLIENT_ID=xxxxxxxxxxxxxxxxxxxxx NEXT_PUBLIC_COGNITO_REGION=ap-southeast-1 Screenshot: Amplify environment variables configured\nBest Practices 1. Environment Management ✅ Use separate Amplify apps for dev/staging/prod ✅ Configure environment variables in Amplify Console ⚠️ DO NOT commit .env.production to Git ✅ Use .env.example to document required variables 2. Build Optimization ✅ Enable caching: node_modules + .next/cache ✅ Use output: 'standalone' for smaller bundle ✅ Optimize images: AVIF, WebP formats ✅ Enable gzip compression 3. Security ✅ Set security headers (HSTS, CSP, X-Frame-Options) ✅ Use HTTPS only (enforce via Amplify) ✅ Validate environment variables at build time ⚠️ Do not expose sensitive data in client code 4. Monitoring ✅ Monitor build logs in Amplify Console ✅ Set up build notifications (email, Slack) ✅ Check CloudWatch metrics for CDN ✅ Monitor error rates and performance Summary Frontend Stack configuration highlights:\n✅ Next.js 15 SSR application\n✅ AWS Amplify hosting with automatic deployment\n✅ GitLab CI/CD integration\n✅ Custom domain with Route 53 + ACM\n✅ Environment variables management\n✅ Security headers and optimization\n🔗 Next Step: Deploy to Amplify (5.10) - Detailed deployment process\nReference AWS Amplify Documentation: https://docs.aws.amazon.com/amplify/ Next.js Deployment: https://nextjs.org/docs/deployment Frontend Source: everyonecook/frontend/ Build Config: everyonecook/frontend/amplify.yml "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.07-deploy-backend/","title":"Deploy Backend Services","tags":[],"description":"","content":"Overview After deploying infrastructure with CDK, you need to deploy Lambda code to AWS. The EveryoneCook project provides an automated deployment script to build, package, and deploy all Lambda functions.\nBackend Architecture Lambda Modules (7 functions):\napi-router - API Gateway routing với JWT validation auth-user - Authentication \u0026amp; User Management social - Posts, Comments, Reactions, Friends, Notifications recipe-ai - Recipes \u0026amp; AI Features (Bedrock) ai-worker - Async AI processing worker admin - Admin Dashboard \u0026amp; Content Moderation upload - File Upload với S3 Presigned URLs Lambda Layer:\nshared-dependencies - Shared npm packages (aws-sdk, uuid, etc.) Cognito Triggers (Auth Stack):\nPre-Signup, Post-Confirmation, Post-Authentication, Pre-Authentication, Custom Message Deployment Process 1. Build Lambda Layer (shared dependencies) 2. Build TypeScript modules → JavaScript 3. Validate dist folders (check for issues) 4. Prepare deployment packages 5. Deploy via CDK hoặc Direct Lambda Update 6. Verify deployments 7. Check CloudWatch logs Option A: Full Deployment (Recommended - First Time) Full deployment uses CDK to deploy the entire infrastructure and Lambda code.\nStep 1: Navigate to Project # Navigate to everyonecook root cd D:\\Project_AWS\\everyonecook Step 2: Run Full Deployment Script # Full deployment for dev environment .\\deploy\\deploy-backend.ps1 -Environment dev # Or short form (default is dev) .\\deploy\\deploy-backend.ps1 Script will perform:\nSTEP 0: Building Lambda Layer\nClean previous builds Install production dependencies vào layers/shared-dependencies/nodejs/ Layer size: ~15-20 MB STEP 1: Building Lambda modules\nBuild auth triggers (Pre-Signup, Post-Confirmation, etc.) Build tất cả 7 Lambda modules Clean dist and tsconfig.tsbuildinfo to force fresh compile Compile TypeScript → JavaScript STEP 2: Validating dist folders\nCheck dist folder exists Detect node_modules in dist (common issue) Check dist size (should be \u0026lt; 10 MB) Verify index.js exists Auto-repair if issues detected STEP 3: Preparing deployment packages\nClean previous artifacts Copy dist contents → deployment folder Add build-info.json (timestamp, git commit) STEP 4: Deploy with CDK\nSynth CloudFormation templates Deploy EveryoneCook-dev-Backend stack Update Lambda functions Update Lambda Layer Update API Gateway Sample output:\n======================================== Backend Deployment - dev With Lambda Layers ======================================== STEP 0: Building Lambda Layer... Installing layer dependencies... Layer built: 18.45 MB STEP 1: Building Lambda modules... Building auth triggers... OK Building api-router... OK Building auth-module... OK Building social-module... OK Building ai-module... OK Building admin-module... OK Building upload-module... OK STEP 2: Validating dist folders... api-router... OK (125 files, 1.2 MB) auth-module... OK (156 files, 1.5 MB) social-module... OK (189 files, 1.8 MB) ai-module... OK (142 files, 1.3 MB) admin-module... OK (98 files, 0.9 MB) upload-module... OK (45 files, 0.4 MB) STEP 3: Preparing deployment packages... Preparing api-router... Done Preparing auth-module... Done Preparing social-module... Done Preparing ai-module... Done Preparing admin-module... Done Preparing upload-module... Done STEP 4: Deploying with CDK... Synthesizing CloudFormation templates... EveryoneCook-dev-Backend Deploying... ✅ Lambda Layer updated ✅ API Router function updated ✅ Auth User function updated ✅ Social function updated ✅ Recipe AI function updated ✅ AI Worker updated ✅ Admin function updated ✅ Upload function updated Outputs: ApiUrl = https://xinq7xh300.execute-api.ap-southeast-1.amazonaws.com/v1/ ApiCustomDomain = https://api-dev.everyonecook.cloud ======================================== FULL DEPLOYMENT SUCCESSFUL! ======================================== Step 3: Verify Deployment # List all Lambda functions aws lambda list-functions ` --query \u0026#39;Functions[?contains(FunctionName, `everyonecook-dev`)].{Name:FunctionName,Runtime:Runtime,Updated:LastModified}\u0026#39; ` --output table # Expected output: # -------------------------------------------------------- # | ListFunctions | # +------------------------------------------------------+ # | Name | Runtime | Updated | # +------------------------------------------------------+ # | everyonecook-dev-api-router | nodejs20.x | ... | # | everyonecook-dev-auth-user | nodejs20.x | ... | # | everyonecook-dev-social | nodejs20.x | ... | # | everyonecook-dev-recipe-ai | nodejs20.x | ... | # | everyonecook-dev-ai-worker | nodejs20.x | ... | # | everyonecook-dev-admin | nodejs20.x | ... | # | everyonecook-dev-upload | nodejs20.x | ... | # +------------------------------------------------------+ Option B: Fast Deployment (Lambda Code Only) If you only change Lambda code (no infrastructure changes), use fast deployment.\nStep 1: Lambda Only Deploy # Fast deploy - only update Lambda code .\\deploy\\deploy-backend.ps1 -Environment dev -LambdaOnly # Or use dedicated script .\\deploy\\force-update-lambdas.ps1 -Environment dev Faster deployment process:\nSTEP 0: Build Layer (hoặc skip) STEP 1: Build modules STEP 2: Validate dist STEP 3: Prepare packages STEP 4: Upload to Lambda (Fast Deploy) - Create ZIP files - Upload directly via aws lambda update-function-code - Update Layer ARN if changed - Skip CDK (faster) Time:\nFull Deploy (CDK): ~5-8 minutes Lambda Only: ~2-3 minutes Step 2: Skip Options (Advanced) # Skip layer build (use existing layer) .\\deploy\\deploy-backend.ps1 -Environment dev -SkipLayer # Skip module build (use existing dist) .\\deploy\\deploy-backend.ps1 -Environment dev -SkipBuild # Combine options .\\deploy\\deploy-backend.ps1 -Environment dev -LambdaOnly -SkipLayer Step 4: Verify Lambda Functions 1. Check Function Configuration # Get API Router details aws lambda get-function ` --function-name everyonecook-dev-api-router ` --query \u0026#39;Configuration.{Runtime:Runtime,Handler:Handler,Timeout:Timeout,Memory:MemorySize,Layer:Layers[0].Arn}\u0026#39; # Expected output: # { # \u0026#34;Runtime\u0026#34;: \u0026#34;nodejs20.x\u0026#34;, # \u0026#34;Handler\u0026#34;: \u0026#34;services/api-router/dist/handlers/index.handler\u0026#34;, # \u0026#34;Timeout\u0026#34;: 30, # \u0026#34;Memory\u0026#34;: 512, # \u0026#34;Layer\u0026#34;: \u0026#34;arn:aws:lambda:ap-southeast-1:...:layer:everyonecook-shared-deps-dev:X\u0026#34; # } 2. Verify Code SHA256 (Code đã update) # Check code hash aws lambda get-function ` --function-name everyonecook-dev-api-router ` --query \u0026#39;Configuration.CodeSha256\u0026#39; # SHA256 will change each time code is updated 3. Check Environment Variables # Get environment variables aws lambda get-function-configuration ` --function-name everyonecook-dev-auth-user ` --query \u0026#39;Environment.Variables\u0026#39; # Expected: # { # \u0026#34;TABLE_NAME\u0026#34;: \u0026#34;EveryoneCook-dev\u0026#34;, # \u0026#34;REGION\u0026#34;: \u0026#34;ap-southeast-1\u0026#34;, # \u0026#34;USER_POOL_ID\u0026#34;: \u0026#34;ap-southeast-1_PKoL34PF0\u0026#34;, # ... # } Step 5: Test Lambda Functions 1. Test API Router (Health Check) # Invoke API Router với test event aws lambda invoke ` --function-name everyonecook-dev-api-router ` --payload \u0026#39;{\u0026#34;httpMethod\u0026#34;:\u0026#34;GET\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/health\u0026#34;,\u0026#34;headers\u0026#34;:{}}\u0026#39; ` response.json # Check response Get-Content response.json | ConvertFrom-Json # Expected: # { # \u0026#34;statusCode\u0026#34;: 200, # \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;status\\\u0026#34;:\\\u0026#34;healthy\\\u0026#34;,\\\u0026#34;timestamp\\\u0026#34;:\\\u0026#34;...\\\u0026#34;}\u0026#34; # } 2. Warm Up Functions (Avoid Cold Start) # Warm up all functions $functions = @( \u0026#34;everyonecook-dev-api-router\u0026#34;, \u0026#34;everyonecook-dev-auth-user\u0026#34;, \u0026#34;everyonecook-dev-social\u0026#34;, \u0026#34;everyonecook-dev-recipe-ai\u0026#34;, \u0026#34;everyonecook-dev-admin\u0026#34;, \u0026#34;everyonecook-dev-upload\u0026#34; ) foreach ($func in $functions) { Write-Host \u0026#34;Warming up $func...\u0026#34; -ForegroundColor Cyan aws lambda invoke ` --function-name $func ` --payload \u0026#39;{\u0026#34;warmup\u0026#34;:true}\u0026#39; ` out.json | Out-Null } Write-Host \u0026#34;All functions warmed up!\u0026#34; -ForegroundColor Green Step 6: Check CloudWatch Logs 1. Tail Logs Real-time # Tail API Router logs aws logs tail /aws/lambda/everyonecook-dev-api-router --follow # View last 10 minutes aws logs tail /aws/lambda/everyonecook-dev-api-router --since 10m 2. Search for Errors # Search for errors in last hour $oneHourAgo = [DateTimeOffset]::Now.AddHours(-1).ToUnixTimeMilliseconds() aws logs filter-log-events ` --log-group-name /aws/lambda/everyonecook-dev-api-router ` --start-time $oneHourAgo ` --filter-pattern \u0026#34;ERROR\u0026#34; 3. Check All Lambda Logs # List all log groups aws logs describe-log-groups ` --log-group-name-prefix /aws/lambda/everyonecook-dev ` --query \u0026#39;logGroups[].logGroupName\u0026#39; Step 7: Verify API Gateway Integration 1. Get API Endpoint # Get API URL from CloudFormation $apiUrl = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Backend ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiCustomDomain`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;API Endpoint: $apiUrl\u0026#34; # Output: https://api-dev.everyonecook.cloud 2. Test Health Endpoint # Test via API Gateway (real endpoint) $response = Invoke-RestMethod -Uri \u0026#34;$apiUrl/health\u0026#34; -Method Get $response | ConvertTo-Json # Expected: # { # \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, # \u0026#34;timestamp\u0026#34;: \u0026#34;2025-12-09T...\u0026#34;, # \u0026#34;service\u0026#34;: \u0026#34;EveryoneCook API\u0026#34;, # \u0026#34;environment\u0026#34;: \u0026#34;dev\u0026#34; # } 3. Verify API Gateway Deployment # Get API ID $apiId = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Backend ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiId`].OutputValue\u0026#39; ` --output text # List deployments aws apigateway get-deployments --rest-api-id $apiId # Get latest deployment aws apigateway get-deployment ` --rest-api-id $apiId ` --deployment-id (aws apigateway get-deployments ` --rest-api-id $apiId ` --query \u0026#39;items[0].id\u0026#39; ` --output text) Step 8: Verify Cognito Triggers Cognito triggers were deployed with Auth Stack. Verify:\n# List Cognito User Pool triggers $userPoolId = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Auth ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`UserPoolId`].OutputValue\u0026#39; ` --output text aws cognito-idp describe-user-pool ` --user-pool-id $userPoolId ` --query \u0026#39;UserPool.LambdaConfig\u0026#39; # Expected: # { # \u0026#34;PreSignUp\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PreSignup\u0026#34;, # \u0026#34;PostConfirmation\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PostConfirmation\u0026#34;, # \u0026#34;PostAuthentication\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PostAuthentication\u0026#34;, # \u0026#34;PreAuthentication\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-PreAuthentication\u0026#34;, # \u0026#34;CustomMessage\u0026#34;: \u0026#34;arn:aws:lambda:...:function:EveryoneCook-dev-CustomMessage\u0026#34; # } Step 9: Verify SQS Workers 1. Check AI Worker # Get AI Worker function aws lambda get-function --function-name everyonecook-dev-ai-worker # Check event source mapping (SQS trigger) aws lambda list-event-source-mappings ` --function-name everyonecook-dev-ai-worker # Expected: Event source từ AI Queue 2. Test Worker với SQS Message # Get AI Queue URL $queueUrl = aws sqs list-queues ` --queue-name-prefix everyonecook-dev-ai-queue ` --query \u0026#39;QueueUrls[0]\u0026#39; ` --output text # Send test message aws sqs send-message ` --queue-url $queueUrl ` --message-body \u0026#39;{\u0026#34;type\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;data\u0026#34;:\u0026#34;worker-verification\u0026#34;}\u0026#39; # Check worker logs aws logs tail /aws/lambda/everyonecook-dev-ai-worker --follow Deployment Checklist Use this checklist to verify deployment:\nBuild \u0026amp; Package Lambda Layer built successfully (~15-20 MB) All 7 modules compiled (TypeScript → JavaScript) Dist folders validated (no node_modules, \u0026lt; 10 MB) Deployment packages created with build-info.json Lambda Functions All 7 Lambda functions deployed\nRuntime: nodejs20.x\nHandler paths correct\nTimeout: 30 seconds\nMemory: 512 MB (auth, social), 1024 MB (ai)\nLambda Layer attached to all functions\nEnvironment variables configured correctly\nCode SHA256 changed (code updated)\nCognito Triggers Pre-Signup trigger deployed Post-Confirmation trigger deployed Post-Authentication trigger deployed Pre-Authentication trigger deployed Custom Message trigger deployed API Gateway API Gateway deployed Custom domain configured: api-dev.everyonecook.cloud Health endpoint responding: GET /health CORS configured correctly Workers \u0026amp; Queues AI Worker deployed Event source mapping configured (SQS → Lambda) SQS queues created (ai-queue, image-queue, analytics-queue, notification-queue) Worker can process test messages Verification All functions invoked successfully No errors in CloudWatch logs API Gateway returns 200 for health check Functions warmed up (no cold start) Troubleshooting Issue 1: Build Failed - TypeScript Compilation Error # Check TypeScript errors cd services/auth-module npx tsc --noEmit # Fix errors và rebuild npm run build Issue 2: Dist Folder Too Large # Check for node_modules in dist Get-ChildItem -Path services/*/dist/node_modules -Recurse # Script will auto-remove, or manual: Remove-Item services/auth-module/dist/node_modules -Recurse -Force # Rebuild cd services/auth-module npm run build Issue 3: Lambda Update Failed # Check function state aws lambda get-function ` --function-name everyonecook-dev-auth-user ` --query \u0026#39;Configuration.{State:State,StateReason:StateReason}\u0026#39; # If state is \u0026#34;Failed\u0026#34;, check logs aws logs tail /aws/lambda/everyonecook-dev-auth-user --since 10m Issue 4: Function Timeout # Increase timeout (via CDK or AWS CLI) aws lambda update-function-configuration ` --function-name everyonecook-dev-auth-user ` --timeout 60 # Or update in backend-stack.ts and redeploy Issue 5: Out of Memory # Increase memory aws lambda update-function-configuration ` --function-name everyonecook-dev-recipe-ai ` --memory-size 1024 # AI functions need 1024 MB for Bedrock calls Issue 6: Layer Not Attached # Get layer ARN $layerArn = aws lambda list-layer-versions ` --layer-name everyonecook-shared-deps-dev ` --query \u0026#39;LayerVersions[0].LayerVersionArn\u0026#39; ` --output text # Attach layer manually aws lambda update-function-configuration ` --function-name everyonecook-dev-auth-user ` --layers $layerArn Issue 7: Environment Variables Missing # Check current env vars aws lambda get-function-configuration ` --function-name everyonecook-dev-auth-user ` --query \u0026#39;Environment.Variables\u0026#39; # Update manually (or via CDK) aws lambda update-function-configuration ` --function-name everyonecook-dev-auth-user ` --environment \u0026#34;Variables={TABLE_NAME=EveryoneCook-dev,REGION=ap-southeast-1}\u0026#34; Performance Monitoring 1. Lambda Metrics (CloudWatch) # Get invocation count (last 1 hour) $startTime = (Get-Date).AddHours(-1).ToString(\u0026#34;yyyy-MM-ddTHH:mm:ss\u0026#34;) $endTime = (Get-Date).ToString(\u0026#34;yyyy-MM-ddTHH:mm:ss\u0026#34;) aws cloudwatch get-metric-statistics ` --namespace AWS/Lambda ` --metric-name Invocations ` --dimensions Name=FunctionName,Value=everyonecook-dev-api-router ` --start-time $startTime ` --end-time $endTime ` --period 300 ` --statistics Sum 2. Error Rate # Get error count aws cloudwatch get-metric-statistics ` --namespace AWS/Lambda ` --metric-name Errors ` --dimensions Name=FunctionName,Value=everyonecook-dev-api-router ` --start-time $startTime ` --end-time $endTime ` --period 300 ` --statistics Sum 3. Duration (Average \u0026amp; P99) # Get average duration aws cloudwatch get-metric-statistics ` --namespace AWS/Lambda ` --metric-name Duration ` --dimensions Name=FunctionName,Value=everyonecook-dev-api-router ` --start-time $startTime ` --end-time $endTime ` --period 300 ` --statistics Average,Maximum 4. Concurrent Executions # Check concurrent executions aws cloudwatch get-metric-statistics ` --namespace AWS/Lambda ` --metric-name ConcurrentExecutions ` --dimensions Name=FunctionName,Value=everyonecook-dev-api-router ` --start-time $startTime ` --end-time $endTime ` --period 300 ` --statistics Maximum Best Practices 1. Deployment Strategy Development:\n# Fast iteration - Lambda Only .\\deploy\\deploy-backend.ps1 -LambdaOnly Staging/Production:\n# Full deployment with CDK .\\deploy\\deploy-backend.ps1 -Environment prod # Verify thoroughly before proceeding 2. Rollback Strategy # Get previous version aws lambda list-versions-by-function ` --function-name everyonecook-dev-auth-user # Rollback to version X aws lambda update-alias ` --function-name everyonecook-dev-auth-user ` --name LIVE ` --function-version X 3. Blue-Green Deployment # Deploy to new version .\\deploy\\deploy-backend.ps1 -Environment dev # Test new version # If OK, traffic shift complete # If issues, rollback alias 4. Monitoring Alerts # Create CloudWatch alarm for errors aws cloudwatch put-metric-alarm ` --alarm-name everyonecook-dev-api-router-errors ` --alarm-description \u0026#34;Alert on Lambda errors\u0026#34; ` --metric-name Errors ` --namespace AWS/Lambda ` --statistic Sum ` --period 300 ` --evaluation-periods 1 ` --threshold 10 ` --comparison-operator GreaterThanThreshold ` --dimensions Name=FunctionName,Value=everyonecook-dev-api-router Performance Benchmarks Expected Deployment Times:\nOperation Time Notes Build Layer 30-60s npm install production deps Build Modules 20-40s TypeScript compilation (7 modules) Validate \u0026amp; Package 10-20s ZIP creation CDK Deploy 3-5 min CloudFormation update Lambda Only 1-2 min Direct function update Expected Lambda Performance:\nFunction Cold Start Warm Memory Timeout api-router 800-1200ms 50-100ms 512 MB 30s auth-user 600-900ms 80-150ms 512 MB 30s social 700-1000ms 100-200ms 512 MB 30s recipe-ai 1500-2500ms 200-500ms 1024 MB 60s ai-worker 2000-3000ms 300-800ms 1024 MB 300s admin 600-800ms 100-150ms 512 MB 30s upload 400-600ms 50-80ms 256 MB 15s Advanced: CI/CD Integration To automate deployment in GitLab CI/CD:\n# .gitlab-ci.yml deploy-backend: stage: deploy script: - cd everyonecook - .\\deploy\\deploy-backend.ps1 -Environment $CI_ENVIRONMENT_NAME -LambdaOnly only: - main environment: name: production Summary In this lab, you have:\n✅ Deploy Lambda Functions: 7 modules + 5 Cognito triggers\n✅ Deploy Lambda Layer: Shared dependencies\n✅ Configure API Gateway: Custom domain integration\n✅ Setup SQS Workers: Async processing\n✅ Verify Deployment: Health checks, logs, metrics\n✅ Performance Tuning: Warm up functions, optimize cold start\nKey Achievements:\nAutomated deployment với PowerShell script Full CDK deployment hoặc fast Lambda-only update Comprehensive validation và error handling CloudWatch monitoring và alerting Production-ready Lambda configuration Next Steps Backend deployed successfully! Next steps:\n✅ Test Endpoints: Verify tất cả API endpoints → 5.08 - Test Endpoints 📝 Version Control: Push code to GitLab → 5.09 - Push to GitLab 🚀 Deploy Frontend: Next.js application 🔍 Monitor: CloudWatch dashboards và alerts Proceed to: 5.08 - Test Endpoints End-to-End\n# Test get posts aws lambda invoke \\ --function-name EveryoneCook-dev-SocialModule \\ --payload \u0026#39;{ \u0026#34;httpMethod\u0026#34;:\u0026#34;GET\u0026#34;, \u0026#34;path\u0026#34;:\u0026#34;/social/posts\u0026#34;, \u0026#34;headers\u0026#34;:{\u0026#34;Authorization\u0026#34;:\u0026#34;Bearer test-token\u0026#34;}, \u0026#34;requestContext\u0026#34;:{\u0026#34;authorizer\u0026#34;:{\u0026#34;claims\u0026#34;:{\u0026#34;sub\u0026#34;:\u0026#34;test-user-id\u0026#34;,\u0026#34;username\u0026#34;:\u0026#34;testuser\u0026#34;}}} }\u0026#39; \\ response.json cat response.json Step 5: Check CloudWatch Logs 1. View Recent Logs\n# Tail Auth Module logs aws logs tail /aws/lambda/EveryoneCook-dev-AuthModule --follow # Or view last 10 minutes aws logs tail /aws/lambda/EveryoneCook-dev-AuthModule --since 10m 2. Search for Errors\n# Search for errors in last hour aws logs filter-log-events \\ --log-group-name /aws/lambda/EveryoneCook-dev-AuthModule \\ --start-time $(date -d \u0026#39;1 hour ago\u0026#39; +%s)000 \\ --filter-pattern \u0026#34;ERROR\u0026#34; 3. Check Lambda Insights\n# Get Lambda metrics aws cloudwatch get-metric-statistics \\ --namespace AWS/Lambda \\ --metric-name Invocations \\ --dimensions Name=FunctionName,Value=EveryoneCook-dev-AuthModule \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum Screenshot: CloudWatch Logs showing Lambda execution\nStep 6: Deploy Lambda Triggers Lambda triggers đã được deploy với Auth Stack, verify:\n# Check Post-Confirmation trigger aws lambda get-function \\ --function-name EveryoneCook-dev-PostConfirmationTrigger # Test trigger (will be invoked automatically on user confirmation) Step 7: Deploy Search Sync Worker 1. Deploy Worker\n# Worker được deploy với Backend Stack # Verify deployment aws lambda get-function \\ --function-name EveryoneCook-dev-SearchSyncWorker 2. Test Worker with SQS\n# Get SearchIndex queue URL QUEUE_URL=$(aws sqs list-queues \\ --queue-name-prefix EveryoneCook-dev-SearchIndexQueue \\ | jq -r \u0026#39;.QueueUrls[0]\u0026#39;) # Send test message aws sqs send-message \\ --queue-url $QUEUE_URL \\ --message-body \u0026#39;{ \u0026#34;eventName\u0026#34;: \u0026#34;INSERT\u0026#34;, \u0026#34;tableName\u0026#34;: \u0026#34;recipes\u0026#34;, \u0026#34;keys\u0026#34;: {\u0026#34;PK\u0026#34;: \u0026#34;USER#testuser\u0026#34;, \u0026#34;SK\u0026#34;: \u0026#34;RECIPE#test-123\u0026#34;}, \u0026#34;newImage\u0026#34;: {\u0026#34;title\u0026#34;: \u0026#34;Test Recipe\u0026#34;, \u0026#34;cuisine\u0026#34;: \u0026#34;Vietnamese\u0026#34;} }\u0026#39; # Check worker logs aws logs tail /aws/lambda/EveryoneCook-dev-SearchSyncWorker --follow Step 8: Update API Gateway API Gateway tự động update khi deploy Backend Stack, verify:\n# Get API Gateway deployment API_ID=$(aws cloudformation describe-stacks \\ --stack-name EveryoneCook-dev-Backend \\ --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiId`].OutputValue\u0026#39; \\ --output text) # List deployments aws apigateway get-deployments --rest-api-id $API_ID # Get latest deployment aws apigateway get-deployment \\ --rest-api-id $API_ID \\ --deployment-id $(aws apigateway get-deployments \\ --rest-api-id $API_ID \\ --query \u0026#39;items[0].id\u0026#39; \\ --output text) Step 9: Warm Up Lambda Functions Tránh cold start cho requests đầu tiên:\n# Invoke all functions once for func in APIRouter AuthModule SocialModule RecipeAIModule AdminModule UploadModule SearchSyncWorker; do echo \u0026#34;Warming up $func...\u0026#34; aws lambda invoke \\ --function-name EveryoneCook-dev-$func \\ --payload \u0026#39;{\u0026#34;warmup\u0026#34;:true}\u0026#39; \\ /dev/null done Step 10: Verify End-to-End 1. Test Health Endpoint\n# Test via API Gateway curl https://api.everyonecook.cloud/health # Should return: {\u0026#34;status\u0026#34;:\u0026#34;healthy\u0026#34;,\u0026#34;timestamp\u0026#34;:\u0026#34;...\u0026#34;} 2. Test with Postman\nImport Postman collection:\n{ \u0026#34;info\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;EveryoneCook API\u0026#34;, \u0026#34;schema\u0026#34;: \u0026#34;https://schema.getpostman.com/json/collection/v2.1.0/collection.json\u0026#34; }, \u0026#34;item\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;Health Check\u0026#34;, \u0026#34;request\u0026#34;: { \u0026#34;method\u0026#34;: \u0026#34;GET\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.everyonecook.cloud/health\u0026#34; } } ] } Deployment Checklist Preparation script completed successfully All Lambda functions updated Function status: Active Test invocations successful CloudWatch logs showing executions No errors in logs Lambda triggers working Search Sync Worker processing messages API Gateway updated Health endpoint responding Functions warmed up Troubleshooting Issue: Lambda update fails\n# Check function state aws lambda get-function \\ --function-name EveryoneCook-dev-AuthModule \\ --query \u0026#39;Configuration.State\u0026#39; # If state is \u0026#34;Failed\u0026#34;, check StateReasonCode aws lambda get-function \\ --function-name EveryoneCook-dev-AuthModule \\ --query \u0026#39;Configuration.StateReasonCode\u0026#39; Issue: Function timeout\n# Increase timeout aws lambda update-function-configuration \\ --function-name EveryoneCook-dev-AuthModule \\ --timeout 30 Issue: Out of memory\n# Increase memory aws lambda update-function-configuration \\ --function-name EveryoneCook-dev-AuthModule \\ --memory-size 512 Issue: Environment variables missing\n# Update environment variables aws lambda update-function-configuration \\ --function-name EveryoneCook-dev-AuthModule \\ --environment Variables={TABLE_NAME=EveryoneCook-dev,REGION=us-east-1} Performance Monitoring Check Lambda metrics:\n# Invocations aws cloudwatch get-metric-statistics \\ --namespace AWS/Lambda \\ --metric-name Invocations \\ --dimensions Name=FunctionName,Value=EveryoneCook-dev-AuthModule \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum # Errors aws cloudwatch get-metric-statistics \\ --namespace AWS/Lambda \\ --metric-name Errors \\ --dimensions Name=FunctionName,Value=EveryoneCook-dev-AuthModule \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Sum # Duration aws cloudwatch get-metric-statistics \\ --namespace AWS/Lambda \\ --metric-name Duration \\ --dimensions Name=FunctionName,Value=EveryoneCook-dev-AuthModule \\ --start-time $(date -u -d \u0026#39;1 hour ago\u0026#39; +%Y-%m-%dT%H:%M:%S) \\ --end-time $(date -u +%Y-%m-%dT%H:%M:%S) \\ --period 300 \\ --statistics Average,Maximum Next Steps Once backend is deployed and verified, proceed to Test Endpoints End-to-End to test the complete application flow.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.7-week7/","title":"Week 7 Worklog","tags":[],"description":"","content":"Week 7 Objectives: Complete hands-on labs with VPC, EC2, Lambda, and Slack automation. Practice IAM user/policy/role management and tag-based access control. Learn KMS encryption, CloudTrail logging, and Athena log analysis. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Lab22 – VPC + EC2 + Lambda + Slack Automation 10/16/2025 10/16/2025 Module 05 – Lab22 3 Lab28 – IAM User/Policy/Role + Switch Role + Tag-based EC2 Access 10/17/2025 10/17/2025 Module 05 – Lab28 4 Lab30 – IAM Restriction (User Limits) 10/18/2025 10/18/2025 Module 05 – Lab30 5 Lab33 – KMS + CloudTrail + Athena 10/19/2025 10/19/2025 Module 05 – Lab33 6 Lab44 + Lab48 – Advanced IAM + EC2/S3 Access 10/20/2025 10/20/2025 Module 05 _ Lab44 \u0026amp; 48 Week 7 Achievements Gained a clear understanding of AWS and cloud computing. Learned core AWS service groups (Compute, Storage, Networking, Database, Security). Completed hands-on labs with IAM, EC2, S3, VPC, KMS, CloudTrail, Lambda, and Athena. Built practical skills in automation, access control, encryption, and log analysis. Improved knowledge of AWS best practices for security and resource management. VPC + EC2 + Lambda + Slack Automation Create VPC, SG, EC2 Configure Slack Webhook Create IAM Role for Lambda Lambda functions to Start/Stop EC2 Test \u0026amp; Cleanup IAM User/Policy/Role + Switch Role + Tag-based EC2 Access Create IAM User Create Custom IAM Policy Create IAM Role Switch Role Control EC2 access using Tags Cleanup IAM Restriction (User Limits) Create Restriction Policy Create Limited IAM User Permission Testing Cleanup KMS + CloudTrail + Athena Create KMS Key Create S3 Bucket \u0026amp; upload encrypted data Enable CloudTrail logging to S3 Query CloudTrail logs with Athena Cleanup Advanced IAM + EC2/S3 Access Create IAM Group/User + Admin Role Configure Switch Role (IP \u0026amp; Time restrictions) Create EC2 instance + S3 bucket IAM User Access Key testing Use IAM Role for EC2 to access S3 Cleanup "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/7-feedback/","title":"Sharing and Feedback","tags":[],"description":"","content":"Overall Evaluation 1. Working Environment\nThe atmosphere at the workplace was welcoming and supportive throughout my internship. Team members from FCJ were always approachable and ready to assist whenever I faced challenges, even beyond regular working hours. The office space was well-organized and conducive to productivity. One suggestion I have is to organize more informal gatherings or team-building events to help strengthen interpersonal connections among team members.\n2. Support from Mentor / Team Admin\nMy mentor provided thorough and patient guidance, taking time to explain concepts clearly whenever I had questions. I was always encouraged to voice my uncertainties without hesitation. The administrative team was equally helpful, ensuring all necessary paperwork and resources were readily available. What I valued most was my mentor\u0026rsquo;s approach of letting me attempt problem-solving independently before offering solutions, which greatly enhanced my learning experience.\n3. Relevance of Work to Academic Major\nThe assignments I received were closely related to my university coursework, while also exposing me to unfamiliar topics and technologies. This combination allowed me to reinforce my existing knowledge while simultaneously developing new practical competencies that will be valuable in my career.\n4. Learning \u0026amp; Skill Development Opportunities\nThroughout the internship, I acquired numerous new abilities including proficiency with project management tools, effective teamwork strategies, and professional communication practices in a corporate setting. My mentor generously shared insights from their professional journey, which provided me with valuable perspective for planning my future career direction.\n5. Company Culture \u0026amp; Team Spirit\nThe organizational culture was remarkably positive—characterized by mutual respect, dedication to quality work, and a pleasant atmosphere. During high-pressure periods with tight deadlines, everyone collaborated seamlessly regardless of their role or seniority. This inclusive environment made me feel like a valued contributor to the team, despite being an intern.\n6. Internship Policies / Benefits\nThe company offered a reasonable internship stipend along with flexibility in working hours when circumstances required it. Additionally, the opportunity to participate in internal training programs was an excellent benefit that enhanced my professional development.\nAdditional Questions What did you find most satisfying during your internship?\nThe opportunity to deepen my understanding of cloud technologies and the enthusiastic support I received from the entire team made this experience truly rewarding.\nWhat do you think the company should improve for future interns?\nOverall, I found the program to be well-structured. If I had to mention one area, it would be the office access registration process—due to high demand, securing a spot in the office can sometimes be competitive.\nIf recommending to a friend, would you suggest they intern here? Why or why not?\nAbsolutely. This internship provides genuine exposure to a professional corporate environment, meaningful interactions with industry professionals, and access to various activities and events that reinforce learning and expand knowledge.\nSuggestions \u0026amp; Expectations Do you have any suggestions to improve the internship experience?\nMy internship experience was excellent overall, and I have no significant suggestions for improvement.\nWould you like to continue this program in the future?\nYes, I would be interested in continuing with the program, provided it does not conflict with my academic schedule.\nAny other comments (free sharing):\nI am grateful for this opportunity and the valuable experiences gained during my time with the First Cloud Journey program.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.04-configure-stacks/5.4.7-observability-stack/","title":"5.4.7 Observability Stack","tags":[],"description":"","content":" Observability Stack - Monitoring \u0026amp; Alerting Overview The Observability Stack is the Phase 7 monitoring layer of the EveryoneCook infrastructure. It provides comprehensive monitoring, alerting, and visualization for all deployed stacks through CloudWatch dashboards, alarms, and SNS notifications.\nDeployment Order: This stack MUST be deployed LAST, after all other stacks (DNS, Certificate, Core, Auth, Backend, Frontend) are deployed.\n⚠️ Environment Note: This guide focuses on Development (dev) environment deployment. For staging/production deployments, alarm thresholds and monitoring intervals may be different.\nKey Responsibilities Create CloudWatch Dashboards for all stack layers Configure CloudWatch Alarms for critical metrics Setup SNS Topic for alarm notifications Create Composite Alarm for overall system health Monitor API Gateway, Lambda, DynamoDB, S3, CloudFront, and Cognito Track cost and billing metrics What This Stack Includes CloudWatch Dashboards (4 dashboards):\nCore Dashboard: DynamoDB, S3, CloudFront metrics Auth Dashboard: Cognito authentication metrics Backend Dashboard: API Gateway, Lambda, SQS metrics Overview Dashboard: Aggregated system health view CloudWatch Alarms (15+ alarms):\nAPI Gateway: 5XX errors, 4XX errors, latency Lambda: Error rate, throttles, duration DynamoDB: Read/write throttles, latency S3: 4XX/5XX errors SQS: DLQ messages, queue age Cost: Daily spending warnings Notification System:\nSNS Topic for alarm notifications Email subscriptions for alerts Composite alarm for system health Architecture ┌──────────────────────────────────────────────────────────────────────┐ │ Observability Stack (Phase 7 - Dev Environment) │ │ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ SNS Topic (Alarm Notifications) │ │ │ │ ├─ Topic Name: EveryoneCook-dev-Alarms │ │ │ │ ├─ Email Subscription: team@everyonecook.cloud │ │ │ │ └─ Protocol: Email (requires confirmation) │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ (Alarm Actions) │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ CloudWatch Alarms (15+ alarms) │ │ │ │ │ │ │ │ API Gateway Alarms: │ │ │ │ ├─ 5XX Error Rate \u0026gt; 5% (Critical) │ │ │ │ ├─ 4XX Error Rate \u0026gt; 20% (Warning) │ │ │ │ └─ P99 Latency \u0026gt; 3s (Warning) │ │ │ │ │ │ │ │ Lambda Alarms: │ │ │ │ ├─ Error Rate \u0026gt; 5% (Critical) │ │ │ │ ├─ Throttles \u0026gt; 10 (Critical) │ │ │ │ └─ P99 Duration \u0026gt; 10s (Warning) │ │ │ │ │ │ │ │ DynamoDB Alarms: │ │ │ │ ├─ Read Throttles \u0026gt; 10 (Critical) │ │ │ │ ├─ Write Throttles \u0026gt; 10 (Critical) │ │ │ │ └─ P99 Latency \u0026gt; 100ms (Warning) │ │ │ │ │ │ │ │ S3 Alarms: │ │ │ │ ├─ 4XX Error Rate \u0026gt; 5% (Warning) │ │ │ │ └─ 5XX Errors \u0026gt; 0 (Critical) │ │ │ │ │ │ │ │ SQS Alarms: │ │ │ │ ├─ DLQ Messages \u0026gt; 0 (Critical) │ │ │ │ └─ Message Age \u0026gt; 5 minutes (Warning) │ │ │ │ │ │ │ │ Cost Alarms: │ │ │ │ ├─ Daily Cost \u0026gt; $50 (Warning) │ │ │ │ └─ Daily Cost \u0026gt; $100 (Critical) │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ │ ▼ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ Composite Alarm (System Health) │ │ │ │ ├─ Name: EveryoneCook-dev-SystemHealth │ │ │ │ ├─ Triggers: ANY critical alarm fires │ │ │ │ └─ Action: Send SNS notification │ │ │ └─────────────────────────────────────────────────────────────────┘ │ │ │ │ ┌─────────────────────────────────────────────────────────────────┐ │ │ │ CloudWatch Dashboards (4 dashboards) │ │ │ │ │ │ │ │ 1. Core Dashboard (EveryoneCook-dev-Core): │ │ │ │ ├─ DynamoDB: Read/Write capacity, throttles, latency │ │ │ │ ├─ S3: Requests, errors, bytes transferred │ │ │ │ └─ CloudFront: Requests, error rates, bytes downloaded │ │ │ │ │ │ │ │ 2. Auth Dashboard (EveryoneCook-dev-Auth): │ │ │ │ ├─ Cognito: Sign-ups, sign-ins │ │ │ │ └─ Cognito: Failed authentications │ │ │ │ │ │ │ │ 3. Backend Dashboard (EveryoneCook-dev-Backend): │ │ │ │ ├─ API Gateway: Requests, latency (P50/P95/P99) │ │ │ │ ├─ API Gateway: 4XX/5XX errors │ │ │ │ ├─ Lambda: Invocations, duration, errors, throttles │ │ │ │ └─ SQS: Messages sent, visible, oldest age │ │ │ │ │ │ │ │ 4. Overview Dashboard (EveryoneCook-dev-Overview): │ │ │ │ ├─ System Health: Environment info, region │ │ │ │ ├─ Key Metrics: API requests, latency, Lambda stats │ │ │ │ ├─ Error Trends: API 5XX, Lambda errors (last hour) │ │ │ │ ├─ Cost Tracking: Estimated daily cost, 7-day trend │ │ │ │ └─ Alarm Status: Composite alarm widget │ │ │ └─────────────────────────────────────────────────────────────────┘ │ └──────────────────────────────────────────────────────────────────────┘ │ │ Monitors ▼ ┌──────────────────┴───────────────────┐ ▼ ▼ ▼ Core Stack Auth Stack Backend Stack (DynamoDB, (Cognito) (API Gateway, S3, CDN) Lambda, SQS) Stack Configuration File Structure infrastructure/lib/stacks/ └── observability-stack.ts # Observability Stack implementation (1175 lines) Code Implementation Highlights File: infrastructure/lib/stacks/observability-stack.ts\n1. SNS Topic for Alarms /** * Create SNS Topic for CloudWatch Alarms * Task 7.4.2 - Step 1 */ private createAlarmTopic(): sns.Topic { const topic = new sns.Topic(this, \u0026#39;AlarmTopic\u0026#39;, { topicName: `EveryoneCook-${this.config.environment}-Alarms`, displayName: \u0026#39;Everyone Cook CloudWatch Alarms\u0026#39;, }); // Add email subscription for alarm notifications topic.addSubscription( new sns_subscriptions.EmailSubscription(this.config.contact.email) ); return topic; } Configuration: Email subscription requires confirmation via AWS SNS.\n2. API Gateway Alarms // API Gateway: High 5XX Error Rate (Critical) const api5xxAlarm = new cloudwatch.Alarm(this, \u0026#39;API-5XX-Critical\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-API-5XX-Critical`, alarmDescription: \u0026#39;API Gateway 5XX error rate \u0026gt; 5% in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/ApiGateway\u0026#39;, metricName: \u0026#39;5XXError\u0026#39;, dimensionsMap: { ApiName: apiName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 5, evaluationPeriods: 2, comparisonOperator: cloudwatch.ComparisonOperator.GREATER_THAN_THRESHOLD, treatMissingData: cloudwatch.TreatMissingData.NOT_BREACHING, }); api5xxAlarm.addAlarmAction(alarmAction); // API Gateway: High Latency (Warning) const apiLatencyAlarm = new cloudwatch.Alarm(this, \u0026#39;API-Latency-High\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-API-Latency-High`, alarmDescription: \u0026#39;API Gateway P99 latency \u0026gt; 3s in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/ApiGateway\u0026#39;, metricName: \u0026#39;Latency\u0026#39;, dimensionsMap: { ApiName: apiName }, statistic: \u0026#39;p99\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 3000, // 3 seconds in milliseconds evaluationPeriods: 2, comparisonOperator: cloudwatch.ComparisonOperator.GREATER_THAN_THRESHOLD, }); 3. Lambda Alarms // Lambda: High Error Rate (Critical) const lambdaErrorAlarm = new cloudwatch.Alarm(this, \u0026#39;Lambda-Error-Rate\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-Lambda-Error-Rate`, alarmDescription: \u0026#39;Lambda error rate \u0026gt; 5% in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/Lambda\u0026#39;, metricName: \u0026#39;Errors\u0026#39;, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 5, evaluationPeriods: 2, comparisonOperator: cloudwatch.ComparisonOperator.GREATER_THAN_THRESHOLD, }); // Lambda: Throttles (Critical) const lambdaThrottleAlarm = new cloudwatch.Alarm(this, \u0026#39;Lambda-Throttle\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-Lambda-Throttle`, alarmDescription: \u0026#39;Lambda throttles \u0026gt; 10 in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/Lambda\u0026#39;, metricName: \u0026#39;Throttles\u0026#39;, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 10, evaluationPeriods: 1, }); 4. DynamoDB Alarms // DynamoDB: Read Throttles (Critical) const dynamoReadThrottleAlarm = new cloudwatch.Alarm(this, \u0026#39;DynamoDB-Read-Throttle\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-DynamoDB-Read-Throttle`, alarmDescription: \u0026#39;DynamoDB read throttles \u0026gt; 10 in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;ReadThrottleEvents\u0026#39;, dimensionsMap: { TableName: dynamoTableName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 10, evaluationPeriods: 2, }); // DynamoDB: High Latency (Warning) const dynamoLatencyAlarm = new cloudwatch.Alarm(this, \u0026#39;DynamoDB-Latency-High\u0026#39;, { alarmName: `EveryoneCook-${this.config.environment}-DynamoDB-Latency-High`, alarmDescription: \u0026#39;DynamoDB P99 latency \u0026gt; 100ms in 5 minutes\u0026#39;, metric: new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;SuccessfulRequestLatency\u0026#39;, dimensionsMap: { TableName: dynamoTableName, Operation: \u0026#39;Query\u0026#39;, }, statistic: \u0026#39;p99\u0026#39;, period: cdk.Duration.minutes(5), }), threshold: 100, // 100ms evaluationPeriods: 3, }); 5. Composite Alarm /** * Create Composite Alarm for overall system health * Task 7.4.2 - Step 2 */ private createCompositeAlarm(alarms: cloudwatch.IAlarm[]): cloudwatch.CompositeAlarm { // Filter critical alarms only const criticalAlarms = alarms.filter( (alarm) =\u0026gt; alarm.alarmName.includes(\u0026#39;Critical\u0026#39;) || alarm.alarmName.includes(\u0026#39;Throttle\u0026#39;) ); const compositeAlarm = new cloudwatch.CompositeAlarm(this, \u0026#39;SystemHealth\u0026#39;, { compositeAlarmName: `EveryoneCook-${this.config.environment}-SystemHealth`, alarmDescription: \u0026#39;Overall system health - triggers if any critical alarm fires\u0026#39;, alarmRule: cloudwatch.AlarmRule.anyOf( ...criticalAlarms.map((alarm) =\u0026gt; cloudwatch.AlarmRule.fromAlarm(alarm, cloudwatch.AlarmState.ALARM) ) ), }); compositeAlarm.addAlarmAction(new cloudwatch_actions.SnsAction(this.alarmTopic)); return compositeAlarm; } 6. Core Dashboard /** * Create Core Dashboard (DynamoDB, S3, CloudFront) */ private createCoreDashboard(props: ObservabilityStackProps): cloudwatch.Dashboard { const dashboard = new cloudwatch.Dashboard(this, \u0026#39;CoreDashboard\u0026#39;, { dashboardName: `EveryoneCook-${this.config.environment}-Core`, }); // DynamoDB Metrics dashboard.addWidgets( new cloudwatch.GraphWidget({ title: \u0026#39;DynamoDB - Read/Write Capacity\u0026#39;, left: [ new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;ConsumedReadCapacityUnits\u0026#39;, dimensionsMap: { TableName: dynamoTableName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;ConsumedWriteCapacityUnits\u0026#39;, dimensionsMap: { TableName: dynamoTableName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), ], width: 12, }), new cloudwatch.GraphWidget({ title: \u0026#39;DynamoDB - Throttles\u0026#39;, left: [ new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;ReadThrottleEvents\u0026#39;, dimensionsMap: { TableName: dynamoTableName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), new cloudwatch.Metric({ namespace: \u0026#39;AWS/DynamoDB\u0026#39;, metricName: \u0026#39;WriteThrottleEvents\u0026#39;, dimensionsMap: { TableName: dynamoTableName }, statistic: \u0026#39;Sum\u0026#39;, period: cdk.Duration.minutes(5), }), ], width: 12, }) ); // S3 and CloudFront metrics... return dashboard; } 7. Overview Dashboard /** * Create Overview Dashboard (Aggregated view) */ private createOverviewDashboard(props: ObservabilityStackProps): cloudwatch.Dashboard { const dashboard = new cloudwatch.Dashboard(this, \u0026#39;OverviewDashboard\u0026#39;, { dashboardName: `EveryoneCook-${this.config.environment}-Overview`, }); // System Health Header dashboard.addWidgets( new cloudwatch.TextWidget({ markdown: `# Everyone Cook - System Overview\\n\\n**Environment:** ${this.config.environment}\\n\\n**Region:** ${this.region}`, width: 24, height: 2, }) ); // Key Metrics: API, Lambda, DynamoDB, S3 // Cost Tracking // Alarm Status Widget return dashboard; } Deployment Guide Prerequisites Before deploying the Observability Stack, ensure:\nAll other stacks deployed:\nDNS Stack (Phase 1) Certificate Stack (Phase 1.5) Core Stack (Phase 2) Auth Stack (Phase 3) Backend Stack (Phase 4) Frontend Stack (Phase 6 - Amplify) Stack exports available:\naws cloudformation list-exports --region ap-southeast-1 Expected exports:\nEveryoneCook-dev-Core-TableName EveryoneCook-dev-Core-ContentBucketName EveryoneCook-dev-Core-DistributionId EveryoneCook-dev-Auth-UserPoolId EveryoneCook-dev-Backend-ApiName Email configured:\nValid email in infrastructure/config/dev.ts Email will receive SNS subscription confirmation Step 1: Review Configuration File: infrastructure/config/dev.ts\nexport const devConfig: EnvironmentConfig = { environment: \u0026#39;dev\u0026#39;, region: \u0026#39;ap-southeast-1\u0026#39;, // Email for alarm notifications contact: { email: \u0026#39;your-email@example.com\u0026#39;, // ⚠️ Update this phone: \u0026#39;+1234567890\u0026#39;, }, // Monitoring settings (already configured) monitoring: { enableDetailedMonitoring: true, retainLogs: true, logRetentionDays: 7, enableXRay: false, // Disabled for dev to save costs }, }; ⚠️ Important: Update the email address to receive alarm notifications.\nStep 2: Synthesize CloudFormation Template Navigate to infrastructure directory:\ncd D:\\Project_AWS\\everyonecook\\infrastructure Synthesize the Observability Stack:\nnpm run synth Expected Output (1175 lines):\n✨ Synthesis time: 3.5s Resources: [+] AWS::SNS::Topic AlarmTopic [+] AWS::SNS::Subscription AlarmTopic/EmailSubscription [+] AWS::CloudWatch::Alarm API-5XX-Critical [+] AWS::CloudWatch::Alarm API-4XX-Warning [+] AWS::CloudWatch::Alarm API-Latency-High [+] AWS::CloudWatch::Alarm Lambda-Error-Rate [+] AWS::CloudWatch::Alarm Lambda-Throttle [+] AWS::CloudWatch::Alarm Lambda-Duration-High [+] AWS::CloudWatch::Alarm DynamoDB-Read-Throttle [+] AWS::CloudWatch::Alarm DynamoDB-Write-Throttle [+] AWS::CloudWatch::Alarm DynamoDB-Latency-High [+] AWS::CloudWatch::Alarm S3-4XX-Warning [+] AWS::CloudWatch::Alarm S3-5XX-Critical [+] AWS::CloudWatch::Alarm SQS-DLQ-Messages [+] AWS::CloudWatch::Alarm SQS-Queue-Age [+] AWS::CloudWatch::Alarm Cost-Warning [+] AWS::CloudWatch::Alarm Cost-Critical [+] AWS::CloudWatch::CompositeAlarm SystemHealth [+] AWS::CloudWatch::Dashboard CoreDashboard [+] AWS::CloudWatch::Dashboard AuthDashboard [+] AWS::CloudWatch::Dashboard BackendDashboard [+] AWS::CloudWatch::Dashboard OverviewDashboard Outputs: - AlarmTopicArn - CompositeAlarmName - CoreDashboardName - AuthDashboardName - BackendDashboardName - OverviewDashboardName Screenshot: CDK synth output showing all Observability Stack resources\nStep 3: Review Generated Template Open the generated CloudFormation template:\ncode infrastructure/cdk.out/EveryoneCook-dev-Observability.template.json Screenshot: Generated CloudFormation template showing SNS Topic, 15+ Alarms, Composite Alarm, and 4 Dashboards\nStep 4: Deploy Observability Stack Deploy using CDK:\nnpx cdk deploy EveryoneCook-dev-Observability --require-approval never Expected Deployment Time: 2-3 minutes\nDeployment Output:\nEveryoneCook-dev-Observability: deploying... EveryoneCook-dev-Observability: creating CloudFormation changeset... EveryoneCook-dev-Observability Outputs: EveryoneCook-dev-Observability.AlarmTopicArn = arn:aws:sns:ap-southeast-1:123456789012:EveryoneCook-dev-Alarms EveryoneCook-dev-Observability.CompositeAlarmName = EveryoneCook-dev-SystemHealth EveryoneCook-dev-Observability.CoreDashboardName = EveryoneCook-dev-Core EveryoneCook-dev-Observability.AuthDashboardName = EveryoneCook-dev-Auth EveryoneCook-dev-Observability.BackendDashboardName = EveryoneCook-dev-Backend EveryoneCook-dev-Observability.OverviewDashboardName = EveryoneCook-dev-Overview Stack ARN: arn:aws:cloudformation:ap-southeast-1:123456789012:stack/EveryoneCook-dev-Observability/... ✨ Deployment time: 2m 15s Verification Step 1: Verify CloudFormation Stack Navigate to CloudFormation Console:\nAWS Console → CloudFormation → Stacks Verify Stack:\nStack Name: EveryoneCook-dev-Observability Status: CREATE_COMPLETE ✅ Resources: 24 resources created Screenshot: CloudFormation stack with CREATE_COMPLETE status and 24 resources\nScreenshot: CloudFormation Outputs tab showing all 6 outputs\nStep 2: Verify CloudWatch Alarms Navigate to CloudWatch Console → Alarms:\nAWS Console → CloudWatch → All alarms Verify Alarms Created (15+ alarms):\nAlarm Name Type Metric Threshold Status EveryoneCook-dev-API-5XX-Critical Critical API 5XX Errors \u0026gt; 5 OK EveryoneCook-dev-API-4XX-Warning Warning API 4XX Errors \u0026gt; 20 OK EveryoneCook-dev-API-Latency-High Warning API P99 Latency \u0026gt; 3000ms OK EveryoneCook-dev-Lambda-Error-Rate Critical Lambda Errors \u0026gt; 5 OK EveryoneCook-dev-Lambda-Throttle Critical Lambda Throttles \u0026gt; 10 OK EveryoneCook-dev-Lambda-Duration-High Warning Lambda P99 Duration \u0026gt; 10000ms OK EveryoneCook-dev-DynamoDB-Read-Throttle Critical DynamoDB Read Throttles \u0026gt; 10 OK EveryoneCook-dev-DynamoDB-Write-Throttle Critical DynamoDB Write Throttles \u0026gt; 10 OK EveryoneCook-dev-DynamoDB-Latency-High Warning DynamoDB P99 Latency \u0026gt; 100ms OK EveryoneCook-dev-S3-4XX-Warning Warning S3 4XX Errors \u0026gt; 5% OK EveryoneCook-dev-S3-5XX-Critical Critical S3 5XX Errors \u0026gt; 0 OK EveryoneCook-dev-SQS-DLQ-Messages Critical SQS DLQ Messages \u0026gt; 0 OK EveryoneCook-dev-SQS-Queue-Age Warning SQS Message Age \u0026gt; 300s OK EveryoneCook-dev-Cost-Warning Warning Daily Cost \u0026gt; $50 OK EveryoneCook-dev-Cost-Critical Critical Daily Cost \u0026gt; $100 OK Verify Composite Alarm:\nName: EveryoneCook-dev-SystemHealth Type: Composite Rule: ANY critical alarm → ALARM Status: OK ✅ Screenshot: CloudWatch Alarms console showing all 15+ alarms with OK status\nScreenshot: Composite alarm details for system health monitoring\nStep 3: Verify CloudWatch Dashboards Navigate to CloudWatch Console → Dashboards:\nAWS Console → CloudWatch → Dashboards Verify Dashboards Created (5 dashboards):\n1. Core Dashboard (EveryoneCook-dev-Core) Open the dashboard and verify widgets:\nDynamoDB Widgets:\nRead/Write Capacity graph Throttles graph Latency (P99) graph Table Size metric S3 Widgets:\nRequests graph Errors (4XX/5XX) graph CloudFront Widgets:\nRequests graph Error Rate (4XX/5XX) graph Bytes Downloaded graph Screenshot: Core Dashboard showing DynamoDB, S3, and CloudFront metrics\n2. Auth Dashboard (EveryoneCook-dev-Auth) Cognito Widgets:\nSign-ups graph Sign-ins graph Failed Authentications graph Screenshot: Auth Dashboard showing Cognito authentication metrics\n3. Backend Dashboard (EveryoneCook-dev-Backend) API Gateway Widgets:\nRequests graph Latency (P50/P95/P99) graph 4XX Errors graph 5XX Errors graph Lambda Widgets:\nInvocations graph Duration (P99) graph Errors graph Throttles graph SQS Widgets:\nMessages Sent graph Messages Visible graph Oldest Message Age graph Screenshot: Backend Dashboard showing API Gateway, Lambda, and SQS metrics\n4. Overview Dashboard (EveryoneCook-dev-Overview) System Health Section:\nHeader with environment info Region information Key Metrics:\nAPI Requests (5m) - Single value widget API P99 Latency - Single value widget Lambda Invocations (5m) - Single value widget Lambda Errors (5m) - Single value widget DynamoDB Read/Write Throttles - Single value widgets S3 Requests and Errors - Single value widgets Trends:\nError Rates graph (API 5XX, Lambda Errors) Cost Tracking:\nEstimated Daily Cost - Single value widget Cost Trend (7 days) - Graph widget Alarm Status:\nComposite Alarm widget showing system health Screenshot: Overview Dashboard with system health, key metrics, error trends, and cost tracking\nCost Breakdown Monthly Costs (Development) Service Resource Quantity Unit Cost Total CloudWatch Alarms Standard alarms 15 $0.10/alarm $1.50 CloudWatch Alarms Composite alarm 1 $0.50/alarm $0.50 CloudWatch Dashboards Dashboards (\u0026gt;3) 1 $3.00/dashboard $3.00 CloudWatch Metrics Standard resolution Included Free $0.00 SNS Email notifications \u0026lt;1000 Free tier $0.00 CloudWatch Logs 7-day retention ~5 GB $0.50/GB $2.50 Total $7.50/month Free Tier Benefits:\nFirst 3 dashboards: Free First 10 alarms: Free (covered) First 1M API requests to CloudWatch: Free SNS email (first 1000): Free Next Steps After deploying the Observability Stack:\nConfirm Email Subscription: Check inbox and confirm SNS subscription\nReview Dashboards: Familiarize yourself with all 4 dashboards\nTest Alarms: Trigger a test alarm to verify notifications\nMonitor Costs: Check daily cost tracking in Overview Dashboard\n⏭️ Deploy Frontend: Continue to 5.10 Deploy to Amplify\n⏭️ Test End-to-End: Test complete application flow and monitor metrics\n📊 Review Metrics: After 24 hours, review all dashboards for baseline metrics\nSummary You have successfully deployed the Observability Stack with:\n1 SNS Topic for alarm notifications\n15+ CloudWatch Alarms for critical metrics\n1 Composite Alarm for overall system health\n4 CloudWatch Dashboards for monitoring\nEmail Notifications configured and confirmed\nKey Achievements:\nComplete visibility into system health Proactive alerting for critical issues Cost tracking and optimization Centralized monitoring dashboards Total Resources: 24 CloudFormation resources\nDeployment Time: ~2-3 minutes\nMonthly Cost: ~$7.50 (dev environment)\n🎉 Congratulations! You have completed all infrastructure stack deployments. Your EveryoneCook platform now has comprehensive monitoring and observability.\nNext: 5.10 Deploy to Amplify to deploy the Next.js frontend application.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.08-test-endpoints/","title":"Test Endpoints End-to-End","tags":[],"description":"","content":"Overview After successfully deploying the backend, you need to test all API endpoints to ensure the system works correctly end-to-end. This workshop provides detailed instructions on how to test each module of the EveryoneCook system.\nAPI Architecture The EveryoneCook project uses the API Router Pattern with the following components:\nAPI Gateway: REST API với custom domain api-dev.everyonecook.cloud API Router Lambda: Routing requests tới các module Lambda 5 Module Lambda: auth-user-lambda: Authentication \u0026amp; User Management social-lambda: Posts, Comments, Reactions, Friends, Notifications recipe-ai-lambda: Recipes \u0026amp; AI Features admin-lambda: Admin Dashboard \u0026amp; Content Moderation upload-lambda: File Upload với S3 Presigned URLs 4 SQS Queues: Async processing (AI, Image, Analytics, Notifications) WAF: Web Application Firewall protecting API Test Flow 1. Get API Endpoint 2. Test Health Check (Public) 3. Test User Registration \u0026amp; Verification 4. Test User Login \u0026amp; Get JWT Token 5. Test Profile Management 6. Test Social Features (Posts, Friends, Notifications) 7. Test Recipe Management 8. Test AI Features (Recipe Generation, Translation) 9. Test File Upload (S3 + CloudFront) 10. Test Admin Features (if you have admin role) Step 1: Get API Endpoint 1. Get API URL from CloudFormation Outputs\n# Get API endpoint from Backend Stack $API_ENDPOINT = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Backend ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`ApiCustomDomain`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;API Endpoint: $API_ENDPOINT\u0026#34; # Output: https://api-dev.everyonecook.cloud 2. Or get from outputs.json file\n# Read from infrastructure/outputs.json cd D:\\Project_AWS\\everyonecook\\infrastructure $outputs = Get-Content outputs.json | ConvertFrom-Json $API_ENDPOINT = $outputs.\u0026#39;EveryoneCook-dev-Backend\u0026#39;.ApiCustomDomain Write-Host \u0026#34;API Endpoint: $API_ENDPOINT\u0026#34; 3. Setup environment variables\n# Set API endpoint for PowerShell session $API_ENDPOINT = \u0026#34;https://api-dev.everyonecook.cloud\u0026#34; $HEADERS_JSON = @{\u0026#34;Content-Type\u0026#34;=\u0026#34;application/json\u0026#34;} Write-Host \u0026#34;Environment configured:\u0026#34; Write-Host \u0026#34; API Endpoint: $API_ENDPOINT\u0026#34; Step 2: Test Health Check (Public) Health check endpoint does not require authentication.\n1. Test with PowerShell\n# Test health endpoint $response = Invoke-RestMethod -Uri \u0026#34;$API_ENDPOINT/health\u0026#34; -Method Get $response | ConvertTo-Json # Expected Output: # { # \u0026#34;status\u0026#34;: \u0026#34;healthy\u0026#34;, # \u0026#34;timestamp\u0026#34;: \u0026#34;2025-12-09T10:30:00.000Z\u0026#34;, # \u0026#34;service\u0026#34;: \u0026#34;EveryoneCook API\u0026#34;, # \u0026#34;environment\u0026#34;: \u0026#34;dev\u0026#34; # } 2. Test with curl (if you have WSL or Git Bash)\ncurl -X GET \u0026#34;$API_ENDPOINT/health\u0026#34; | jq 3. Verify API Router is working\n# Check API Router Lambda logs aws logs tail /aws/lambda/everyonecook-dev-api-router --follow ✅ Expected Result: Status 200, response JSON có \u0026quot;status\u0026quot;: \u0026quot;healthy\u0026quot;\nStep 3: Test User Registration 1. Get User Pool Client ID\n# Get Cognito User Pool Client ID $CLIENT_ID = aws cloudformation describe-stacks ` --stack-name EveryoneCook-dev-Auth ` --query \u0026#39;Stacks[0].Outputs[?OutputKey==`UserPoolClientId`].OutputValue\u0026#39; ` --output text Write-Host \u0026#34;User Pool Client ID: $CLIENT_ID\u0026#34; 2. Register new User\n# Register user with Cognito (not through API - directly with Cognito) $username = \u0026#34;testuser_$(Get-Random -Maximum 9999)\u0026#34; $email = \u0026#34;test_$username@example.com\u0026#34; $password = \u0026#34;TestPassword123!\u0026#34; aws cognito-idp sign-up ` --client-id $CLIENT_ID ` --username $username ` --password $password ` --user-attributes ` Name=email,Value=$email ` Name=given_name,Value=\u0026#34;Test User\u0026#34; Write-Host \u0026#34;User registered: $username\u0026#34; Write-Host \u0026#34;Email: $email\u0026#34; Write-Host \u0026#34;Password: $password\u0026#34; 3. Verify Pre-Signup Trigger (Lambda Cognito Trigger)\n# Check logs của Pre-Signup trigger aws logs tail /aws/lambda/EveryoneCook-dev-PreSignup --since 5m ✅ Expected:\nCognito returns success message Pre-Signup trigger logs have no errors Step 4: Verify Email \u0026amp; Confirm User 1. Get Confirmation Code\n# In dev environment, you can get code from email or use admin command # Option 1: Check email (if using real email) # Option 2: Admin confirm (for testing) aws cognito-idp admin-confirm-sign-up ` --user-pool-id ap-southeast-1_PKoL34PF0 ` --username $username Write-Host \u0026#34;User confirmed: $username\u0026#34; 2. Verify Post-Confirmation Trigger\nPost-Confirmation trigger will automatically create user profile in DynamoDB.\n# Check DynamoDB - User profile is created automatically aws dynamodb get-item ` --table-name EveryoneCook-dev ` --key \u0026#34;{\\\u0026#34;PK\\\u0026#34;:{\\\u0026#34;S\\\u0026#34;:\\\u0026#34;USER#$username\\\u0026#34;},\\\u0026#34;SK\\\u0026#34;:{\\\u0026#34;S\\\u0026#34;:\\\u0026#34;PROFILE\\\u0026#34;}}\u0026#34; # Expected: User profile với các fields: # - userId (Cognito sub ID) # - email # - fullName # - createdAt # - updatedAt 3. Check Post-Confirmation Lambda logs\naws logs tail /aws/lambda/EveryoneCook-dev-PostConfirmation --since 5m ✅ Expected: User profile is created in DynamoDB table\nStep 5: Test User Login \u0026amp; Get JWT Token 1. Login to get JWT tokens\n# Sign in with Cognito $authResult = aws cognito-idp initiate-auth ` --client-id $CLIENT_ID ` --auth-flow USER_PASSWORD_AUTH ` --auth-parameters USERNAME=$username,PASSWORD=$password ` | ConvertFrom-Json # Extract tokens $ID_TOKEN = $authResult.AuthenticationResult.IdToken $ACCESS_TOKEN = $authResult.AuthenticationResult.AccessToken $REFRESH_TOKEN = $authResult.AuthenticationResult.RefreshToken Write-Host \u0026#34;Login successful!\u0026#34; Write-Host \u0026#34;ID Token length: $($ID_TOKEN.Length)\u0026#34; 2. Verify Post-Authentication Trigger\nPost-Authentication trigger updates lastLoginAt in DynamoDB.\n# Check lastLoginAt updated aws dynamodb get-item ` --table-name EveryoneCook-dev ` --key \u0026#34;{\\\u0026#34;PK\\\u0026#34;:{\\\u0026#34;S\\\u0026#34;:\\\u0026#34;USER#$username\\\u0026#34;},\\\u0026#34;SK\\\u0026#34;:{\\\u0026#34;S\\\u0026#34;:\\\u0026#34;PROFILE\\\u0026#34;}}\u0026#34; ` --projection-expression \u0026#34;lastLoginAt\u0026#34; 3. Setup Authorization Header\n# Create headers with JWT token $HEADERS_AUTH = @{ \u0026#34;Content-Type\u0026#34; = \u0026#34;application/json\u0026#34; \u0026#34;Authorization\u0026#34; = \u0026#34;Bearer $ID_TOKEN\u0026#34; } ✅ Expected: Login successful, received JWT tokens\nStep 6: Test Profile Management Endpoint: /users/me, /users/profile\n1. Get Current User Profile\n# GET /users/me $response = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/me\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $response | ConvertTo-Json -Depth 5 # Expected Response: # { # \u0026#34;userId\u0026#34;: \u0026#34;...\u0026#34;, # \u0026#34;username\u0026#34;: \u0026#34;testuser_1234\u0026#34;, # \u0026#34;email\u0026#34;: \u0026#34;test_testuser_1234@example.com\u0026#34;, # \u0026#34;fullName\u0026#34;: \u0026#34;Test User\u0026#34;, # \u0026#34;birthday\u0026#34;: null, # \u0026#34;gender\u0026#34;: null, # \u0026#34;country\u0026#34;: null, # \u0026#34;createdAt\u0026#34;: \u0026#34;2025-12-09T10:30:00.000Z\u0026#34;, # \u0026#34;lastLoginAt\u0026#34;: \u0026#34;2025-12-09T11:00:00.000Z\u0026#34; # } 2. Update Profile (Onboarding)\n# PUT /users/profile - Complete onboarding $profileUpdate = @{ birthday = \u0026#34;1990-01-01\u0026#34; gender = \u0026#34;male\u0026#34; country = \u0026#34;Vietnam\u0026#34; bio = \u0026#34;Test user for EveryoneCook platform\u0026#34; } | ConvertTo-Json $response = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/profile\u0026#34; ` -Method Put ` -Headers $HEADERS_AUTH ` -Body $profileUpdate $response | ConvertTo-Json 3. Get Privacy Settings\n# GET /users/profile/privacy $privacy = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/profile/privacy\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $privacy | ConvertTo-Json 4. Update Privacy Settings\n# PUT /users/profile/privacy $privacyUpdate = @{ profileVisibility = \u0026#34;public\u0026#34; showEmail = $false showBirthday = $false allowFriendRequests = $true } | ConvertTo-Json Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/profile/privacy\u0026#34; ` -Method Put ` -Headers $HEADERS_AUTH ` -Body $privacyUpdate ✅ Expected: Profile is updated successfully in DynamoDB\nStep 7: Test Social Features - Posts Endpoints: /posts, /posts/{postId}\n1. Create Post\n# POST /posts $newPost = @{ content = \u0026#34;My first post on EveryoneCook! Testing the platform 🍳\u0026#34; visibility = \u0026#34;public\u0026#34; type = \u0026#34;text\u0026#34; } | ConvertTo-Json $postResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $newPost $POST_ID = $postResponse.postId Write-Host \u0026#34;Created Post ID: $POST_ID\u0026#34; $postResponse | ConvertTo-Json 2. Get All Posts (Feed)\n# GET /posts - Get all posts $posts = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts?limit=10\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH Write-Host \u0026#34;Found $($posts.items.Count) posts\u0026#34; $posts.items | ConvertTo-Json -Depth 3 3. Get Specific Post\n# GET /posts/{postId} $post = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts/$POST_ID\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $post | ConvertTo-Json 4. Like Post\n# POST /posts/{postId}/like Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts/$POST_ID/like\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH Write-Host \u0026#34;Post liked successfully\u0026#34; 5. Add Comment\n# POST /posts/{postId}/comments $comment = @{ content = \u0026#34;Great post! 👍\u0026#34; } | ConvertTo-Json $commentResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts/$POST_ID/comments\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $comment $COMMENT_ID = $commentResponse.commentId Write-Host \u0026#34;Comment ID: $COMMENT_ID\u0026#34; 6. Get Post Comments\n# GET /posts/{postId}/comments $comments = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/posts/$POST_ID/comments\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $comments | ConvertTo-Json -Depth 3 ✅ Expected: Posts, likes, comments are saved in DynamoDB\nStep 8: Test Social Features - Friends Endpoints: /friends/*\n1. Search Users\n# GET /users/search?q=test $users = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/search?q=test\u0026amp;limit=10\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $users | ConvertTo-Json 2. Send Friend Request (requires 2 users)\n# POST /friends/{userId}/request # Assuming you have USER_ID of another user $TARGET_USER_ID = \u0026#34;another-user-id\u0026#34; Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/friends/$TARGET_USER_ID/request\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH Write-Host \u0026#34;Friend request sent\u0026#34; 3. Get Friend Requests\n# GET /friends/requests $requests = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/friends/requests\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $requests | ConvertTo-Json ✅ Expected: Friend requests are created with status \u0026ldquo;pending\u0026rdquo;\nStep 9: Test Recipe Management Endpoints: /recipes, /recipes/{recipeId}\n1. Create Recipe\n# POST /recipes $newRecipe = @{ title = \u0026#34;Phở Bò Hà Nội\u0026#34; description = \u0026#34;Traditional Vietnamese beef noodle soup\u0026#34; ingredients = @( @{ name = \u0026#34;beef bones\u0026#34;; amount = \u0026#34;2\u0026#34;; unit = \u0026#34;kg\u0026#34; } @{ name = \u0026#34;rice noodles\u0026#34;; amount = \u0026#34;500\u0026#34;; unit = \u0026#34;g\u0026#34; } @{ name = \u0026#34;ginger\u0026#34;; amount = \u0026#34;1\u0026#34;; unit = \u0026#34;piece\u0026#34; } @{ name = \u0026#34;star anise\u0026#34;; amount = \u0026#34;3\u0026#34;; unit = \u0026#34;pieces\u0026#34; } ) instructions = @( \u0026#34;Boil beef bones for 2-3 hours to make broth\u0026#34; \u0026#34;Add spices (ginger, star anise, cinnamon) and simmer\u0026#34; \u0026#34;Prepare rice noodles separately\u0026#34; \u0026#34;Serve noodles with broth and garnish with herbs\u0026#34; ) cuisine = \u0026#34;Vietnamese\u0026#34; difficulty = \u0026#34;medium\u0026#34; prepTime = 30 cookTime = 180 servings = 4 } | ConvertTo-Json -Depth 5 $recipeResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/recipes\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $newRecipe $RECIPE_ID = $recipeResponse.recipeId Write-Host \u0026#34;Created Recipe ID: $RECIPE_ID\u0026#34; $recipeResponse | ConvertTo-Json -Depth 5 2. Get User\u0026rsquo;s Recipes\n# GET /users/{userId}/recipes $userId = $authResult.AuthenticationResult.AccessToken | ForEach-Object { [System.Text.Encoding]::UTF8.GetString([System.Convert]::FromBase64String(($_.Split(\u0026#39;.\u0026#39;)[1]))) } | ConvertFrom-Json | Select-Object -ExpandProperty sub $recipes = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/users/$userId/recipes\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $recipes | ConvertTo-Json -Depth 3 3. Search Recipes\n# POST /recipes/search $searchQuery = @{ query = \u0026#34;phở\u0026#34; filters = @{ cuisine = \u0026#34;Vietnamese\u0026#34; difficulty = \u0026#34;medium\u0026#34; } limit = 10 } | ConvertTo-Json $searchResults = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/recipes/search\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $searchQuery $searchResults | ConvertTo-Json -Depth 3 ✅ Expected: Recipes are saved in DynamoDB with proper structure\nStep 10: Test AI Features (Bedrock) Endpoints: /recipes/generate-ai, /ai/nutrition, /dictionary/{ingredient}\n1. Generate Recipe with AI\n# POST /recipes/generate-ai $aiRequest = @{ ingredients = @(\u0026#34;chicken\u0026#34;, \u0026#34;rice\u0026#34;, \u0026#34;vegetables\u0026#34;, \u0026#34;fish sauce\u0026#34;) cuisine = \u0026#34;Vietnamese\u0026#34; dietaryRestrictions = @(\u0026#34;gluten-free\u0026#34;) servings = 4 difficulty = \u0026#34;medium\u0026#34; } | ConvertTo-Json Write-Host \u0026#34;Generating recipe with AI... (takes 5-10 seconds)\u0026#34; $aiRecipe = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/recipes/generate-ai\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $aiRequest $aiRecipe | ConvertTo-Json -Depth 5 # Expected: AI-generated recipe with Vietnamese ingredient names # Uses Amazon Bedrock Claude model 2. Get Nutrition Analysis\n# POST /ai/nutrition $nutritionRequest = @{ ingredients = @( @{ name = \u0026#34;chicken breast\u0026#34;; amount = \u0026#34;200\u0026#34;; unit = \u0026#34;g\u0026#34; } @{ name = \u0026#34;rice\u0026#34;; amount = \u0026#34;100\u0026#34;; unit = \u0026#34;g\u0026#34; } ) } | ConvertTo-Json $nutrition = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/ai/nutrition\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $nutritionRequest $nutrition | ConvertTo-Json 3. Translate Ingredient (Vietnamese Dictionary)\n# GET /dictionary/{ingredient} $translation = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/dictionary/tomato\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH Write-Host \u0026#34;Translation: $($translation.vietnamese)\u0026#34; # Expected: { \u0026#34;ingredient\u0026#34;: \u0026#34;tomato\u0026#34;, \u0026#34;vietnamese\u0026#34;: \u0026#34;cà chua\u0026#34; } ✅ Expected:\nAI recipe generation takes 5-10 seconds Response has Vietnamese ingredient names Bedrock Lambda is invoked Step 11: Test File Upload (S3 + CloudFront) Endpoint: /upload/presigned-url\n1. Request Presigned URL\n# POST /upload/presigned-url $uploadRequest = @{ fileType = \u0026#34;avatar\u0026#34; fileName = \u0026#34;test-avatar.jpg\u0026#34; contentType = \u0026#34;image/jpeg\u0026#34; fileSize = 1024000 # 1MB } | ConvertTo-Json $uploadResponse = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/upload/presigned-url\u0026#34; ` -Method Post ` -Headers $HEADERS_AUTH ` -Body $uploadRequest $PRESIGNED_URL = $uploadResponse.url $UPLOAD_KEY = $uploadResponse.key Write-Host \u0026#34;Presigned URL: $PRESIGNED_URL\u0026#34; Write-Host \u0026#34;Upload Key: $UPLOAD_KEY\u0026#34; 2. Upload File to S3\n# Create test image file $testImage = \u0026#34;D:\\test-avatar.jpg\u0026#34; # (Create test image file or use existing file) # Upload file using presigned URL Invoke-RestMethod ` -Uri $PRESIGNED_URL ` -Method Put ` -InFile $testImage ` -ContentType \u0026#34;image/jpeg\u0026#34; Write-Host \u0026#34;File uploaded to S3 successfully\u0026#34; 3. Access via CloudFront CDN\n# Get CloudFront distribution domain $CDN_DOMAIN = \u0026#34;d2shrpzup69rju.cloudfront.net\u0026#34; # From outputs.json # Access file via CloudFront $fileUrl = \u0026#34;https://$CDN_DOMAIN/$UPLOAD_KEY\u0026#34; Invoke-WebRequest -Uri $fileUrl -Method Head # Check caching headers # First request: X-Cache: Miss from cloudfront # Second request: X-Cache: Hit from cloudfront ✅ Expected: File is uploaded to S3 and served via CloudFront\nStep 12: Test Admin Features (Requires Admin Role) Endpoints: /admin/*\n1. Get System Stats\n# GET /admin/stats $stats = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/admin/stats\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $stats | ConvertTo-Json # Expected (if you have admin role): # { # \u0026#34;totalUsers\u0026#34;: 123, # \u0026#34;totalPosts\u0026#34;: 456, # \u0026#34;totalRecipes\u0026#34;: 789, # \u0026#34;activeUsers\u0026#34;: 45 # } 2. Get All Users\n# GET /admin/users $allUsers = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/admin/users?limit=20\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $allUsers | ConvertTo-Json 3. Get Reported Posts\n# GET /admin/posts/reported $reportedPosts = Invoke-RestMethod ` -Uri \u0026#34;$API_ENDPOINT/admin/posts/reported\u0026#34; ` -Method Get ` -Headers $HEADERS_AUTH $reportedPosts | ConvertTo-Json ⚠️ Note: Admin endpoints require user to have \u0026ldquo;Admins\u0026rdquo; group in Cognito User Pool\nStep 13: Verify Async Processing (SQS Queues) 1. Check SQS Queues\n# List all queues aws sqs list-queues --queue-name-prefix everyonecook-dev # Get AI Queue attributes $AI_QUEUE_URL = \u0026#34;https://sqs.ap-southeast-1.amazonaws.com/616580903213/everyonecook-dev-ai-queue\u0026#34; aws sqs get-queue-attributes ` --queue-url $AI_QUEUE_URL ` --attribute-names ApproximateNumberOfMessages,ApproximateNumberOfMessagesNotVisible 2. Monitor Worker Lambdas\n# Check Image Processing Worker logs aws logs tail /aws/lambda/everyonecook-dev-image-worker --follow # Check AI Worker logs (for recipe generation) aws logs tail /aws/lambda/everyonecook-dev-ai-worker --follow ✅ Expected: Messages are processed by worker Lambdas\nTesting Checklist Use this checklist to track progress:\nPublic Endpoints GET /health - Health check responds GET /status - Status check responds Authentication \u0026amp; User Management User registration với Cognito works Email verification/confirmation works User login successful, nhận JWT tokens GET /users/me - Get current user profile PUT /users/profile - Update profile GET /users/profile/privacy - Get privacy settings PUT /users/profile/privacy - Update privacy settings Social Features POST /posts - Create post GET /posts - Get posts feed GET /posts/{postId} - Get specific post POST /posts/{postId}/like - Like post POST /posts/{postId}/comments - Add comment GET /posts/{postId}/comments - Get comments POST /friends/{userId}/request - Send friend request GET /friends/requests - Get friend requests GET /notifications - Get notifications Recipe Management POST /recipes - Create recipe GET /recipes - Get all recipes GET /recipes/{recipeId} - Get specific recipe POST /recipes/search - Search recipes AI Features POST /recipes/generate-ai - AI recipe generation (Bedrock) POST /ai/nutrition - Nutrition analysis GET /dictionary/{ingredient} - Ingredient translation File Upload POST /upload/presigned-url - Get presigned URL Upload file to S3 using presigned URL Access file via CloudFront CDN Verify CloudFront caching (Miss → Hit) Admin Features (if admin) GET /admin/stats - Get system stats GET /admin/users - List all users GET /admin/posts/reported - Get reported content Infrastructure All Lambda functions execute without errors SQS queues process messages correctly CloudWatch logs show proper execution DynamoDB items created correctly WAF rules protecting API Gateway Performance Benchmarks Expected Response Times:\nEndpoint Expected Time Notes GET /health \u0026lt; 50ms Direct response POST /auth/login \u0026lt; 200ms Cognito validation GET /users/me \u0026lt; 100ms DynamoDB single query POST /posts \u0026lt; 300ms DynamoDB write + notifications GET /posts \u0026lt; 500ms DynamoDB query with pagination POST /recipes/generate-ai 5-10 seconds Bedrock AI generation POST /upload/presigned-url \u0026lt; 100ms S3 presigned URL generation POST /recipes/search \u0026lt; 200ms DynamoDB GSI query Troubleshooting Common Issues 1. 401 Unauthorized # Verify JWT token is not expired $ID_TOKEN = \u0026#34;your-token-here\u0026#34; $parts = $ID_TOKEN.Split(\u0026#39;.\u0026#39;) $payload = [System.Text.Encoding]::UTF8.GetString( [System.Convert]::FromBase64String($parts[1]) ) | ConvertFrom-Json $exp = [DateTimeOffset]::FromUnixTimeSeconds($payload.exp).DateTime Write-Host \u0026#34;Token expires at: $exp\u0026#34; # If expired, login again 2. 403 Forbidden (WAF Block) # Check WAF logs aws wafv2 get-web-acl ` --name EveryoneCook-API-WAF-dev ` --scope REGIONAL ` --region ap-southeast-1 # Check if IP blocked 3. 500 Internal Server Error # Check Lambda function logs aws logs tail /aws/lambda/everyonecook-dev-api-router --follow aws logs tail /aws/lambda/everyonecook-dev-social --follow # Check DynamoDB table aws dynamodb describe-table --table-name EveryoneCook-dev 4. Slow AI Recipe Generation # Check Bedrock model availability aws bedrock list-foundation-models --region us-east-1 # Check AI Queue aws sqs get-queue-attributes ` --queue-url $AI_QUEUE_URL ` --attribute-names All Next Steps After successfully testing all endpoints:\n✅ Verify Infrastructure: All AWS resources are working correctly 📊 Monitor CloudWatch: Check metrics and logs 🔒 Security Review: Verify WAF rules and Cognito auth 📝 Document API: Update API documentation if needed 🚀 Deploy Frontend: Proceed to frontend deployment 📦 Version Control: Commit code and push to GitLab (next step) Proceed to: 5.09 - Push to GitLab\n2. Confirm User\n# Confirm user with code aws cognito-idp confirm-sign-up \\ --client-id $CLIENT_ID \\ --username testuser \\ --confirmation-code 123456 3. Verify Post-Confirmation Trigger\n# Check if user profile was created in DynamoDB aws dynamodb get-item \\ --table-name EveryoneCook-dev \\ --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;USER#testuser\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PROFILE\u0026#34;}}\u0026#39; # Should return user profile with: # - PK: USER#testuser # - SK: PROFILE # - userId: cognito-sub-id # - email: test@example.com # - fullName: Test User # - birthday: null # - gender: null # - country: null Step 5: Test User Login 1. Sign In\n# Sign in to get tokens TOKENS=$(aws cognito-idp initiate-auth \\ --client-id $CLIENT_ID \\ --auth-flow USER_PASSWORD_AUTH \\ --auth-parameters USERNAME=testuser,PASSWORD=TestPassword123!) # Extract tokens ACCESS_TOKEN=$(echo $TOKENS | jq -r \u0026#39;.AuthenticationResult.AccessToken\u0026#39;) ID_TOKEN=$(echo $TOKENS | jq -r \u0026#39;.AuthenticationResult.IdToken\u0026#39;) REFRESH_TOKEN=$(echo $TOKENS | jq -r \u0026#39;.AuthenticationResult.RefreshToken\u0026#39;) echo \u0026#34;ID Token: $ID_TOKEN\u0026#34; 2. Verify Post-Authentication Trigger\n# Check if lastLoginAt was updated aws dynamodb get-item \\ --table-name EveryoneCook-dev \\ --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;USER#testuser\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PROFILE\u0026#34;}}\u0026#39; \\ --projection-expression \u0026#34;lastLoginAt\u0026#34; Step 6: Test Profile Management 1. Get Profile\n# Get user profile curl -X GET \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/auth/profile # Expected: User profile data 2. Update Profile\n# Update profile (onboarding) curl -X PUT \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;birthday\u0026#34;: \u0026#34;1990-01-01\u0026#34;, \u0026#34;gender\u0026#34;: \u0026#34;male\u0026#34;, \u0026#34;country\u0026#34;: \u0026#34;US\u0026#34; }\u0026#39; \\ $API_ENDPOINT/auth/profile # Expected: Updated profile 3. Verify Update in DynamoDB\n# Check updated profile aws dynamodb get-item \\ --table-name EveryoneCook-dev \\ --key \u0026#39;{\u0026#34;PK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;USER#testuser\u0026#34;},\u0026#34;SK\u0026#34;:{\u0026#34;S\u0026#34;:\u0026#34;PROFILE\u0026#34;}}\u0026#39; # Should show birthday, gender, country updated Step 7: Test Social Features 1. Create Post\n# Create a post POST_RESPONSE=$(curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;content\u0026#34;: \u0026#34;My first post on EveryoneCook!\u0026#34;, \u0026#34;visibility\u0026#34;: \u0026#34;public\u0026#34; }\u0026#39; \\ $API_ENDPOINT/social/posts) POST_ID=$(echo $POST_RESPONSE | jq -r \u0026#39;.postId\u0026#39;) echo \u0026#34;Created post: $POST_ID\u0026#34; 2. Get Posts Feed\n# Get posts curl -X GET \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/social/posts # Expected: Array of posts including the one just created 3. Like Post\n# Like the post curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/social/posts/$POST_ID/like # Expected: Success message 4. Comment on Post\n# Add comment curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{\u0026#34;content\u0026#34;:\u0026#34;Great post!\u0026#34;}\u0026#39; \\ $API_ENDPOINT/social/posts/$POST_ID/comment # Expected: Comment created Step 8: Test Recipe Features 1. Create Recipe\n# Create a recipe RECIPE_RESPONSE=$(curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;title\u0026#34;: \u0026#34;Pho Bo (Vietnamese Beef Noodle Soup)\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Traditional Vietnamese beef noodle soup\u0026#34;, \u0026#34;ingredients\u0026#34;: [ {\u0026#34;name\u0026#34;: \u0026#34;beef bones\u0026#34;, \u0026#34;amount\u0026#34;: \u0026#34;2\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;kg\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;rice noodles\u0026#34;, \u0026#34;amount\u0026#34;: \u0026#34;500\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;g\u0026#34;}, {\u0026#34;name\u0026#34;: \u0026#34;ginger\u0026#34;, \u0026#34;amount\u0026#34;: \u0026#34;1\u0026#34;, \u0026#34;unit\u0026#34;: \u0026#34;piece\u0026#34;} ], \u0026#34;instructions\u0026#34;: [ \u0026#34;Boil beef bones for 2 hours\u0026#34;, \u0026#34;Add spices and simmer\u0026#34;, \u0026#34;Prepare noodles and serve\u0026#34; ], \u0026#34;cuisine\u0026#34;: \u0026#34;Vietnamese\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;medium\u0026#34;, \u0026#34;prepTime\u0026#34;: 30, \u0026#34;cookTime\u0026#34;: 120 }\u0026#39; \\ $API_ENDPOINT/recipes) RECIPE_ID=$(echo $RECIPE_RESPONSE | jq -r \u0026#39;.recipeId\u0026#39;) echo \u0026#34;Created recipe: $RECIPE_ID\u0026#34; 2. Get Recipes\n# Get all recipes curl -X GET \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/recipes # Expected: Array of recipes 3. Get Recipe by ID\n# Get specific recipe curl -X GET \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/recipes/$RECIPE_ID # Expected: Recipe details Step 9: Test AI Features 1. Generate Recipe with AI\n# Generate recipe using Bedrock curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;ingredients\u0026#34;: [\u0026#34;chicken\u0026#34;, \u0026#34;rice\u0026#34;, \u0026#34;vegetables\u0026#34;], \u0026#34;cuisine\u0026#34;: \u0026#34;Vietnamese\u0026#34;, \u0026#34;dietaryRestrictions\u0026#34;: [\u0026#34;gluten-free\u0026#34;], \u0026#34;servings\u0026#34;: 4 }\u0026#39; \\ $API_ENDPOINT/ai/generate-recipe # Expected: AI-generated recipe (takes 5-10 seconds) # Response includes Vietnamese ingredient names 2. Translate Ingredient\n# Translate ingredient to Vietnamese curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;ingredient\u0026#34;: \u0026#34;tomato\u0026#34;, \u0026#34;targetLanguage\u0026#34;: \u0026#34;vi\u0026#34; }\u0026#39; \\ $API_ENDPOINT/ai/translate # Expected: {\u0026#34;translation\u0026#34;: \u0026#34;cà chua\u0026#34;, \u0026#34;confidence\u0026#34;: 0.99} Step 10: Test File Upload 1. Request Pre-signed URL\n# Get pre-signed URL for avatar upload UPLOAD_RESPONSE=$(curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;fileType\u0026#34;: \u0026#34;avatar\u0026#34;, \u0026#34;fileName\u0026#34;: \u0026#34;avatar.jpg\u0026#34;, \u0026#34;contentType\u0026#34;: \u0026#34;image/jpeg\u0026#34;, \u0026#34;fileSize\u0026#34;: 1024000 }\u0026#39; \\ $API_ENDPOINT/upload/presigned-url) PRESIGNED_URL=$(echo $UPLOAD_RESPONSE | jq -r \u0026#39;.url\u0026#39;) UPLOAD_KEY=$(echo $UPLOAD_RESPONSE | jq -r \u0026#39;.key\u0026#39;) echo \u0026#34;Pre-signed URL: $PRESIGNED_URL\u0026#34; echo \u0026#34;Upload Key: $UPLOAD_KEY\u0026#34; 2. Upload File to S3\n# Create test image echo \u0026#34;Test image content\u0026#34; \u0026gt; test-avatar.jpg # Upload using pre-signed URL curl -X PUT \\ -H \u0026#34;Content-Type: image/jpeg\u0026#34; \\ --upload-file test-avatar.jpg \\ \u0026#34;$PRESIGNED_URL\u0026#34; # Expected: 200 OK 3. Mark Upload Complete\n# Notify backend that upload is complete curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#34;{\\\u0026#34;key\\\u0026#34;:\\\u0026#34;$UPLOAD_KEY\\\u0026#34;}\u0026#34; \\ $API_ENDPOINT/upload/complete # Expected: Success message 4. Access via CloudFront\n# Access file via CloudFront CDN curl -I https://cdn.everyonecook.cloud/$UPLOAD_KEY # First request: X-Cache: Miss from cloudfront # Second request: X-Cache: Hit from cloudfront Step 11: Test Search (OpenSearch) If OpenSearch is enabled:\n# Search recipes with Vietnamese query curl -X POST \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ -H \u0026#34;Content-Type: application/json\u0026#34; \\ -d \u0026#39;{ \u0026#34;query\u0026#34;: \u0026#34;phở bò\u0026#34;, \u0026#34;filters\u0026#34;: { \u0026#34;cuisine\u0026#34;: \u0026#34;Vietnamese\u0026#34;, \u0026#34;difficulty\u0026#34;: \u0026#34;medium\u0026#34; }, \u0026#34;limit\u0026#34;: 10 }\u0026#39; \\ $API_ENDPOINT/ai/search # Expected: Array of matching recipes # Vietnamese analyzer handles: \u0026#34;phở bò\u0026#34; = \u0026#34;pho bo\u0026#34; = \u0026#34;beef noodle soup\u0026#34; Step 12: Test Admin Features 1. List Users (Admin Only)\n# Get all users (requires admin role) curl -X GET \\ -H \u0026#34;Authorization: Bearer $ID_TOKEN\u0026#34; \\ $API_ENDPOINT/admin/users # Expected: Array of users or 403 Forbidden if not admin Step 13: Verify Async Processing 1. Check SQS Queue Processing\n# Send message to SearchIndex queue QUEUE_URL=$(aws sqs list-queues \\ --queue-name-prefix EveryoneCook-dev-SearchIndexQueue \\ | jq -r \u0026#39;.QueueUrls[0]\u0026#39;) aws sqs send-message \\ --queue-url $QUEUE_URL \\ --message-body \u0026#34;{ \\\u0026#34;eventName\\\u0026#34;: \\\u0026#34;INSERT\\\u0026#34;, \\\u0026#34;tableName\\\u0026#34;: \\\u0026#34;recipes\\\u0026#34;, \\\u0026#34;keys\\\u0026#34;: {\\\u0026#34;PK\\\u0026#34;: \\\u0026#34;USER#testuser\\\u0026#34;, \\\u0026#34;SK\\\u0026#34;: \\\u0026#34;RECIPE#$RECIPE_ID\\\u0026#34;}, \\\u0026#34;newImage\\\u0026#34;: { \\\u0026#34;title\\\u0026#34;: \\\u0026#34;Pho Bo\\\u0026#34;, \\\u0026#34;ingredients\\\u0026#34;: [\\\u0026#34;beef\\\u0026#34;, \\\u0026#34;noodles\\\u0026#34;], \\\u0026#34;cuisine\\\u0026#34;: \\\u0026#34;Vietnamese\\\u0026#34; } }\u0026#34; # Check worker logs aws logs tail /aws/lambda/EveryoneCook-dev-SearchSyncWorker --follow Testing Checklist Health check responds User registration works Email verification works User login successful Profile CRUD operations work Posts can be created Posts can be liked Comments can be added Recipes can be created AI recipe generation works Ingredient translation works File upload to S3 works CloudFront serves files Search works (if OpenSearch enabled) SQS queues process messages All Lambda functions execute without errors Performance Benchmarks Expected Response Times:\nHealth check: \u0026lt; 50ms User login: \u0026lt; 200ms Get profile: \u0026lt; 100ms Create post: \u0026lt; 300ms Get posts feed: \u0026lt; 500ms AI recipe generation: 5-10 seconds File upload (pre-signed URL): \u0026lt; 100ms Search query: \u0026lt; 200ms Next Steps Once all tests pass, proceed to Push to GitLab to version control your code and set up CI/CD.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.8-week8/","title":"Week 8 Worklog","tags":[],"description":"","content":"Week 8 Objectives: Understand database fundamentals: Primary Key, Foreign Key, and Normalization. Learn Indexing, Partitioning, and Execution Plans for query optimization. Compare RDBMS vs NoSQL, and OLTP vs OLAP/Data Warehouse concepts. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Basic database concepts on AWS \u0026amp; managed services 10/23/2025 10/23/2025 YouTube Video 3 Primary Key, Foreign Key \u0026amp; Normalization 10/24/2025 10/24/2025 cont 4 Indexing, Partitioning \u0026amp; Execution Plan 10/25/2025 10/25/2025 cont 5 Database Logs, Buffer Cache \u0026amp; Transactions 10/26/2025 10/26/2025 cont 6 RDBMS vs NoSQL, OLTP vs OLAP / Data Warehouse 10/27/2025 10/27/2025 cont Week 8 Achievements: Basic database concepts on AWS \u0026amp; managed services AWS manages the database infrastructure. You focus on data design \u0026amp; query optimization. Databases handle multi-user access via sessions. Must understand schema, keys, indexes, partitions, logs before using AWS DB services. Primary Key, Foreign Key \u0026amp; Normalization Primary Key (PK)\nUniquely identifies each record in a table. Cannot be duplicated or null. Ensures data integrity. Foreign Key (FK)\nA column that references the Primary Key of another table. Creates relationships between tables. Ensures referential integrity. Normalization\nOrganizes data to avoid duplication and reduce storage usage . Ensures consistency and improves data integrity. Common forms: 1NF, 2NF, 3NF (increasing levels of structure). Indexing, Partitioning \u0026amp; Execution Plan Indexing\nSpeeds up data retrieval by avoiding full table scans. Requires extra storage and increases write cost. Useful for frequently queried columns. Partitioning\nSplits large tables into smaller parts for faster queries. Queries only scan relevant partitions instead of the whole table. Improves performance and scalability. Execution Plan\nThe database\u0026rsquo;s step-by-step strategy for running a query. Shows whether indexes, scans, or joins are used. Essential for query optimization. Database Logs, Buffer Cache \u0026amp; Transactions Database Logs\nRecord all changes made to the database. Enable recovery after failures and support replication. Ensure data can be restored to a consistent state. Buffer Cache\nIn-memory area that stores frequently accessed data blocks. Reduces disk reads and improves query speed. Holds data temporarily before writing to disk. Transactions\nA set of operations that must be completed successfully as a unit. Follow ACID principles to ensure reliability. Only committed transactions are written permanently to the database. RDBMS vs NoSQL, OLTP vs OLAP / Data Warehouse RDBMS vs NoSQL\nRDBMS (Relational Databases)\nStructured tables with fixed schema. Strong consistency, supports complex queries (SQL). Scales vertically (add more power to one server). Best for transactional, structured data. NoSQL\nFlexible or schema-less data model (document, key-value, wide-column, graph). High scalability, often horizontal scaling. Optimized for performance and large datasets. Suitable for unstructured/semi-structured data. OLTP vs OLAP / Data Warehouse OLTP (Online Transaction Processing)\nHandles real-time, frequent read/write operations. Used for transactions like orders, payments, banking. Requires high consistency and fast response. OLAP (Online Analytical Processing) / Data Warehouse\nStores large amounts of historical data for analysis. Supports complex queries for reporting and business insights. Optimized for read-heavy, analytical workloads, not frequent updates. "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.09-push-gitlab/","title":"Push to GitLab","tags":[],"description":"","content":"Overview After successful testing, you will push code to GitLab for version control and prepare for CI/CD.\nStep 1: Initialize Git Repository 1. Check Git Status\n# Navigate to project root cd /path/to/everyonecook-dev # Check if Git is already initialized git status # If not initialized: git init 2. Configure Git\n# Set your name and email git config user.name \u0026#34;Your Name\u0026#34; git config user.email \u0026#34;your.email@example.com\u0026#34; # Verify configuration git config --list Step 2: Create .gitignore 1. Create .gitignore File\n# Create .gitignore cat \u0026gt; .gitignore \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; # Dependencies node_modules/ package-lock.json yarn.lock # Build outputs dist/ build/ *.js.map *.d.ts.map cdk.out/ .next/ # Environment variables .env .env.local .env.*.local # AWS *.pem *.key cloudfront-private-key.pem # Deployment packages *.zip deployment/ # Logs logs/ *.log npm-debug.log* yarn-debug.log* yarn-error.log* # IDE .vscode/ .idea/ *.swp *.swo *~ # OS .DS_Store Thumbs.db # Test coverage coverage/ .nyc_output/ # Temporary files tmp/ temp/ *.tmp # CDK cdk.context.json outputs.json # TypeScript *.tsbuildinfo EOF Step 3: Stage and Commit Files 1. Add Files to Staging\n# Add all files git add . # Check what will be committed git status 2. Create Initial Commit\n# Commit with message git commit -m \u0026#34;Initial commit: EveryoneCook infrastructure and backend\u0026#34; # Verify commit git log --oneline Screenshot: Terminal showing initial commit\nStep 4: Create GitLab Repository 1. Login to GitLab\nGo to https://gitlab.com/ and login\n2. Create New Project\nClick \u0026ldquo;New project\u0026rdquo; Choose \u0026ldquo;Create blank project\u0026rdquo; Project name: everyonecook Visibility: Private (recommended) Initialize with README: No (we already have code) Click \u0026ldquo;Create project\u0026rdquo; Screenshot: GitLab showing new project created\nGit Workflow Summary 1. Create feature branch from dev git checkout -b feature/new-feature 2. Make changes and commit git add . git commit -m \u0026#34;Description\u0026#34; 3. Push to GitLab git push -u origin feature/new-feature 4. Create merge request on GitLab feature/new-feature → dev 5. Review, test, and merge 6. Deploy to dev environment (manual trigger in GitLab CI/CD) 7. Test in dev environment 8. Merge dev → main for production 9. Deploy to production (manual trigger in GitLab CI/CD) 10. Tag release git tag -a v1.0.0 -m \u0026#34;Release\u0026#34; Best Practices Commit Messages:\nfeat: Add user authentication fix: Fix login bug docs: Update README style: Format code refactor: Refactor user service test: Add unit tests chore: Update dependencies Branch Naming:\nfeature/add-notifications bugfix/fix-login-error hotfix/critical-security-patch release/v1.0.0 Troubleshooting Issue: Authentication failed\n# Use personal access token instead of password # Generate token: GitLab → Settings → Access Tokens # Use token as password when pushing Issue: Large files rejected\n# Check file size git ls-files -z | xargs -0 du -h | sort -h # Remove large files from history git filter-branch --tree-filter \u0026#39;rm -f large-file.zip\u0026#39; HEAD Issue: Merge conflicts\n# Update your branch git checkout feature/your-feature git fetch origin git merge origin/dev # Resolve conflicts in files # Then commit git add . git commit -m \u0026#34;Resolve merge conflicts\u0026#34; git push Next Steps Once code is pushed to GitLab, proceed to Deploy to Amplify to deploy your frontend application.\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.9-week9/","title":"Week 9 Worklog","tags":[],"description":"","content":"Week 9 Objectives: Build AWS networking (VPC, EC2, RDS) and perform database migrations with DMS/SCT. Create data pipelines (S3 → Glue → Athena → QuickSight) and ETL processing with DynamoDB, DataBrew, EMR. Build Redshift data warehouse and interactive BI dashboards.Tasks to be carried out this week:\nDay Task Start Date Completion Date Reference Material 2 VPC, EC2, RDS Networking + EC2 Fleet Manager 11/06/2025 11/06/2025 Summary link 3 Database Migration (DMS/SCT) + Migration Troubleshooting 11/07/2025 11/07/2025 Summary link 4 S3 Data Pipeline: S3 → Glue → Athena → QuickSight 11/08/2025 11/08/2025 Summary link 5 DynamoDB + Cloud9, DataBrew \u0026amp; EMR ETL Processing 11/09/2025 11/09/2025 Summary link 6 Redshift Data Warehouse + Dashboards (ETL, Analytics, Visualization) 11/10/2025 11/10/2025 Summary link Week 9 Achievements Built AWS networking infrastructure (VPC, subnets, routing, SGs, EC2, RDS). Managed EC2 instances using Fleet Manager without SSH/RDP. Completed end-to-end database migrations using DMS \u0026amp; SCT. Resolved migration issues through logs and event troubleshooting. Created a data pipeline with S3, Glue, Athena, and QuickSight. Explored DynamoDB and performed backup/restore operations. Processed large datasets using Cloud9, DataBrew, and EMR. Built and analyzed a Redshift data warehouse. Created interactive BI dashboards. Networking + Compute Setup Create VPC, subnets, and route tables Create Security Groups for EC2 and RDS Launch EC2 instance Launch RDS database Use Fleet Manager to manage EC2 Database Migration SQL Server → MySQL migration Oracle → MySQL migration Schema Conversion (SCT) Create and run DMS tasks and endpoints Troubleshoot migration logs and events S3 → Glue → Athena → QuickSight Pipeline Create S3 bucket Create Glue Crawler and Data Catalog Query data using Athena Build dashboards in QuickSight NoSQL + ETL Processing Explore DynamoDB Perform backup/restore operations Set up Cloud9 Data profiling \u0026amp; cleaning with DataBrew Transform data using EMR Redshift Data Warehouse Load data into Redshift Transform data with Glue Analyze with Athena or Kinesis Build interactive dashboards "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.10-deploy-amplify/","title":"Deploy to Amplify","tags":[],"description":"","content":"Overview The final step is to deploy the Next.js 15 frontend to AWS Amplify with GitLab integration for automatic deployment when new code is pushed.\nStep 1: Prepare Frontend Code 1. Check Frontend Structure\ncd frontend # Check package.json cat package.json # Should show Next.js 15 2. Test Frontend Locally\n# Install dependencies npm install # Run development server npm run dev # Open http://localhost:3000 3. Build Frontend\n# Build for production npm run build # Test production build npm start Step 2: Create Amplify App 1. Go to AWS Amplify Console\nOpen AWS Console Search for \u0026ldquo;Amplify\u0026rdquo; Click \u0026ldquo;Get started\u0026rdquo; or \u0026ldquo;New app\u0026rdquo; 2. Connect to GitLab\nChoose \u0026ldquo;Host web app\u0026rdquo; Select \u0026ldquo;GitLab\u0026rdquo; Click \u0026ldquo;Connect branch\u0026rdquo; Authorize AWS Amplify to access GitLab Screenshot: Amplify showing GitLab connection\n3. Select Repository\nChoose repository: everyonecook Choose branch: main (or dev for development) Click \u0026ldquo;Next\u0026rdquo; Step 3: Configure Build Settings 1. App Name\nApp name: everyonecook-frontend 2. Build Settings\nAmplify auto-detects Next.js, but verify:\nversion: 1 applications: - frontend: phases: preBuild: commands: - export HUSKY=0 - npm install --legacy-peer-deps --ignore-scripts build: commands: - echo \u0026#34;=== Creating .env.production from Amplify env vars ===\u0026#34; - rm -f .env.production - env | grep -e NEXT_PUBLIC_ \u0026gt; .env.production || true - echo \u0026#34;=== .env.production content ===\u0026#34; - cat .env.production - echo \u0026#34;=== Building frontend ===\u0026#34; - npm run build artifacts: baseDirectory: .next files: - \u0026#39;**/*\u0026#39; cache: paths: - node_modules/**/* - .next/cache/**/* appRoot: frontend 3. Advanced Settings\nAdd environment variables:\nNEXT_PUBLIC_API_URL=https://api.everyonecook.cloud NEXT_PUBLIC_CDN_URL=https://cdn.everyonecook.cloud NEXT_PUBLIC_USER_POOL_ID=us-east-1_ABC123 NEXT_PUBLIC_USER_POOL_CLIENT_ID=abc123def456 NEXT_PUBLIC_REGION=us-east-1 Screenshot: Amplify environment variables configuration\nStep 4: Deploy Frontend 1. Start Deployment\nClick \u0026ldquo;Save and deploy\u0026rdquo;\nAmplify will:\nClone repository from GitLab Install dependencies Build Next.js app Deploy to CDN Provision domain 2. Monitor Deployment\nWatch deployment progress:\nProvision Build Deploy Verify 3. Wait for Completion\nDeployment takes 5-10 minutes.\nScreenshot: Amplify showing successful deployment\nStep 5: Configure Custom Domain 1. Add Custom Domain\nGo to Amplify app → Domain management Click \u0026ldquo;Add domain\u0026rdquo; Enter domain: everyonecook.cloud Amplify will auto-configure: Root domain: everyonecook.cloud WWW subdomain: www.everyonecook.cloud 2. DNS Configuration\nAmplify automatically creates DNS records in Route 53:\neveryonecook.cloud → A record → Amplify www.everyonecook.cloud → CNAME → Amplify 3. SSL Certificate\nAmplify automatically provisions SSL certificate via ACM.\n4. Wait for DNS Propagation\nTakes 5-15 minutes.\nScreenshot: Amplify showing custom domain configured\nStep 6: Verify Deployment 1. Access Frontend\n# Via Amplify domain curl -I https://main.d1234567890.amplifyapp.com # Via custom domain curl -I https://everyonecook.cloud # Should return 200 OK 2. Test Frontend Features\nOpen https://everyonecook.cloud in browser Test user registration Test login Test creating posts Test creating recipes Test AI features Screenshot: Browser showing EveryoneCook frontend live\nBest Practices Use Environment Variables: Never hardcode API URLs Enable Auto-Deploy: Automatic deployments on push Multiple Environments: Separate dev and prod Monitor Performance: Use Amplify metrics Set Up Notifications: Get alerted on build failures Use Custom Domain: Professional appearance Enable HTTPS: Always use SSL Configure Headers: Security headers for protection Next Steps Congratulations! Your application is now fully deployed:\n✅ Infrastructure on AWS ✅ Backend APIs running ✅ Frontend on Amplify ✅ Code on GitLab ✅ CI/CD configured Proceed to Cleanup when you\u0026rsquo;re done testing, or start using your application!\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.10-week10/","title":"Week 10 Worklog","tags":[],"description":"","content":"Week 10 Objectives: Test backend Lambda functions and API endpoints. Fix authentication, authorization, and DynamoDB data consistency bugs. Verify comment deletion cascade and profile data mapping. Worklog - Testing \u0026amp; Bug Fixing Phase Week 10 Week 10: Backend Testing \u0026amp; Bug Fixes Week 10 Objectives: Test backend Lambda functions và API endpoints Fix bugs authentication và authorization Verify DynamoDB operations và data consistency Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Test Auth Module - Login/Logout flow 11/13/2025 11/13/2025 services/auth-module 3 Test Ban Status API - Check user ban detection 11/14/2025 11/14/2025 useBanStatus.ts 4 Fix TODO: Delete all replies when parent comment deleted 11/15/2025 11/15/2025 comment.service.ts:434 5 Test Profile CRUD operations - snake_case/camelCase mapping 11/16/2025 11/16/2025 auth-module/index.ts 6 Test Privacy settings - Legacy boolean structure handling 11/17/2025 11/17/2025 profile.service.ts:145 Week 10 Achievements: Tested authentication flow including banned user detection Fixed comment deletion cascade issue (replies not deleted) Verified profile data mapping between API and internal models Tested privacy settings migration from legacy format Bugs Found \u0026amp; Fixed: Bug ID Description Severity Status BUG-001 Comment replies not deleted when parent comment deleted High Fixed BUG-002 Legacy privacy boolean fields not properly converted Medium Fixed BUG-003 Ban status check timeout causing login delays Medium Fixed "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/5-workshop/5.11-cleanup/","title":"Cleanup","tags":[],"description":"","content":"Overview When you complete the workshop and no longer want to continue using it, delete all resources to avoid incurring charges.\n⚠️ Warning: This process cannot be undone. All data will be permanently deleted.\nCleanup Order Must delete in reverse order of deployment:\n1. Amplify App (Frontend) 2. Observability Stack 3. Backend Stack 4. Auth Stack 5. Core Stack 6. Certificate Stack 7. DNS Stack 8. CDK Bootstrap (optional) Step 1: Delete Amplify App 1. Delete via Console\nGo to AWS Amplify Console Select your app Click \u0026ldquo;Actions\u0026rdquo; → \u0026ldquo;Delete app\u0026rdquo; Type app name to confirm Click \u0026ldquo;Delete\u0026rdquo; 2. Delete via CLI\n# Get app ID APP_ID=$(aws amplify list-apps \\ --query \u0026#39;apps[?name==`everyonecook-frontend`].appId\u0026#39; \\ --output text) # Delete app aws amplify delete-app --app-id $APP_ID Step 2: Empty S3 Buckets S3 buckets must be emptied before deletion:\n# List all EveryoneCook buckets aws s3 ls | grep everyonecook # Empty each bucket (4 buckets) aws s3 rm s3://everyonecook-content-dev-xxxxx --recursive aws s3 rm s3://everyonecook-logs-dev-xxxxx --recursive aws s3 rm s3://everyonecook-emails-dev-xxxxx --recursive aws s3 rm s3://everyonecook-cdn-logs-dev-xxxxx --recursive # Or use PowerShell script $buckets = aws s3 ls | Select-String \u0026#34;everyonecook\u0026#34; | ForEach-Object { $_.ToString().Split()[-1] } foreach ($bucket in $buckets) { Write-Host \u0026#34;Emptying bucket: $bucket\u0026#34; aws s3 rm \u0026#34;s3://$bucket\u0026#34; --recursive } Step 3: Delete CDK Stacks 1. Delete Observability Stack\ncd infrastructure # Delete Observability stack npx cdk destroy EveryoneCook-dev-Observability --context environment=dev # Type \u0026#39;y\u0026#39; to confirm 2. Delete Backend Stack\n# Delete Backend stack npx cdk destroy EveryoneCook-dev-Backend --context environment=dev # Type \u0026#39;y\u0026#39; to confirm 3. Delete Auth Stack\n# Delete Auth stack npx cdk destroy EveryoneCook-dev-Auth --context environment=dev # Type \u0026#39;y\u0026#39; to confirm 4. Delete Core Stack\n# Delete Core stack (takes 15-20 minutes due to CloudFront) npx cdk destroy EveryoneCook-dev-Core --context environment=dev # Type \u0026#39;y\u0026#39; to confirm 5. Delete Certificate Stack\n# Delete Certificate stack npx cdk destroy EveryoneCook-dev-Certificate --context environment=dev # Type \u0026#39;y\u0026#39; to confirm 6. Delete DNS Stack (Optional)\n# Delete DNS stack (only if you don\u0026#39;t need the domain) npx cdk destroy EveryoneCook-dev-DNS --context environment=dev # Type \u0026#39;y\u0026#39; to confirm Step 4: Verify All Stacks Deleted # List remaining stacks aws cloudformation list-stacks \\ --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \\ --query \u0026#39;StackSummaries[?contains(StackName, `EveryoneCook-dev`)].StackName\u0026#39; # Should return empty array Step 5: Delete CDK Bootstrap (Optional) ⚠️ Only do this if you\u0026rsquo;re done with CDK completely:\n# Delete CDK bootstrap stack aws cloudformation delete-stack --stack-name CDKToolkit # Empty and delete CDK assets bucket BUCKET_NAME=$(aws s3 ls | grep cdk | awk \u0026#39;{print $3}\u0026#39;) aws s3 rm s3://$BUCKET_NAME --recursive aws s3 rb s3://$BUCKET_NAME Step 6: Delete GitLab Repository (Optional) 1. Archive Repository\nGo to GitLab → Settings → General Scroll to \u0026ldquo;Advanced\u0026rdquo; Click \u0026ldquo;Archive project\u0026rdquo; 2. Delete Repository\nGo to GitLab → Settings → General Scroll to \u0026ldquo;Advanced\u0026rdquo; Click \u0026ldquo;Delete project\u0026rdquo; Type project name to confirm Click \u0026ldquo;Yes, delete project\u0026rdquo; Step 7: Verify Complete Cleanup 1. Check CloudFormation\naws cloudformation list-stacks \\ --stack-status-filter CREATE_COMPLETE UPDATE_COMPLETE \\ | grep EveryoneCook # Should return nothing 2. Check S3\naws s3 ls | grep everyonecook # Should return nothing 3. Check Lambda\naws lambda list-functions | grep EveryoneCook # Should return nothing 4. Check DynamoDB\naws dynamodb list-tables | grep EveryoneCook # Should return nothing 5. Check API Gateway\naws apigateway get-rest-apis | grep EveryoneCook # Should return nothing 6. Check Cognito\naws cognito-idp list-user-pools --max-results 10 | grep EveryoneCook # Should return nothing 7. Check CloudFront\naws cloudfront list-distributions | grep EveryoneCook # Should return nothing 8. Check OpenSearch\naws opensearch list-domain-names | grep everyonecook # Should return nothing 9. Check Amplify\naws amplify list-apps | grep everyonecook # Should return nothing Cost After Cleanup Immediate:\nMost resources: $0/month Route 53 Hosted Zone: $0.50/month (if kept) KMS keys: Scheduled for deletion (7-30 days), no charge during waiting period After 30 days:\nEverything: $0/month (if DNS stack also deleted) Troubleshooting Cleanup Issue: S3 bucket deletion fails\n# Force empty and delete aws s3 rb s3://bucket-name --force Issue: CloudFormation stack stuck\n# Check stack events aws cloudformation describe-stack-events \\ --stack-name EveryoneCook-dev-Core \\ --max-items 20 # If stuck, skip failed resources aws cloudformation delete-stack \\ --stack-name EveryoneCook-dev-Core \\ --retain-resources ResourceLogicalId Issue: CloudFront distribution can\u0026rsquo;t be deleted\n# Disable distribution first DIST_ID=$(aws cloudfront list-distributions \\ --query \u0026#34;DistributionList.Items[?Comment==\u0026#39;EveryoneCook-dev\u0026#39;].Id\u0026#34; \\ --output text) # Get ETag ETAG=$(aws cloudfront get-distribution --id $DIST_ID \\ --query \u0026#34;ETag\u0026#34; --output text) # Disable distribution aws cloudfront update-distribution \\ --id $DIST_ID \\ --if-match $ETAG \\ --distribution-config file://disabled-config.json # Wait 15-20 minutes, then delete aws cloudfront delete-distribution --id $DIST_ID --if-match $ETAG Issue: DynamoDB table has deletion protection\n# Disable deletion protection aws dynamodb update-table \\ --table-name EveryoneCook-dev \\ --no-deletion-protection-enabled # Then delete stack Final Verification # Check AWS billing aws ce get-cost-and-usage \\ --time-period Start=2024-01-01,End=2024-01-31 \\ --granularity MONTHLY \\ --metrics BlendedCost # Should show decreasing costs Cleanup Checklist Amplify app deleted All S3 buckets emptied and deleted Observability stack deleted Backend stack deleted Auth stack deleted Core stack deleted Certificate stack deleted DNS stack deleted (optional) CDK bootstrap deleted (optional) GitLab repository archived/deleted (optional) No remaining CloudFormation stacks No remaining Lambda functions No remaining DynamoDB tables No remaining S3 buckets No remaining CloudFront distributions No remaining Cognito user pools Billing shows $0 or minimal cost Conclusion You have completed the EveryoneCook workshop! You have learned:\nInfrastructure as Code with AWS CDK\nServerless Architecture with Lambda and API Gateway\nDynamoDB Single Table Design with username-based PK\nOpenSearch with Vietnamese analyzer\nCloudFront CDN with Origin Access Control\nCognito Authentication with Lambda triggers\nBedrock AI integration\nGitLab version control and CI/CD\nAWS Amplify frontend deployment\nCloudWatch monitoring and X-Ray tracing\nTotal deployed:\n7 CDK stacks 100+ AWS resources 6 Lambda modules + 1 worker Full-stack application CI/CD pipeline Production-ready infrastructure Thank you for completing the workshop! 🎉\n"},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.11-week11/","title":"Week 11 Worklog","tags":[],"description":"","content":"Week 11: Frontend Testing \u0026amp; Integration Week 11 Objectives: Test frontend components and user flows (comments, friends, posts). Fix UI/UX bugs and verify API integration with error handling. Test session management, token refresh, and protected route redirects. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Test Comments Service - TODO functions not implemented 11/20/2025 11/20/2025 frontend/services/comments.ts 3 Test Friend Request flow - Cancel/Accept/Reject 11/21/2025 11/21/2025 frontend/services/friends.ts 4 Test Post reactions - Like/Unlike toggle 11/22/2025 11/22/2025 frontend/services/posts.ts 5 Test Session expired handling - Token refresh 11/23/2025 11/23/2025 AuthContext.tsx 6 Test Protected Routes - Redirect logic 11/24/2025 11/24/2025 ProtectedRoute.tsx Week 11 Achievements: Implemented missing comment service functions (getComments, createComment, etc.) Fixed friend request state management issues Verified token refresh mechanism works correctly Tested protected route redirects for unauthenticated users Bugs Found \u0026amp; Fixed: Bug ID Description Severity Status BUG-004 Comments service functions return empty - TODO not implemented High Fixed BUG-005 Friend request cancel not updating UI state Medium Fixed BUG-006 Token refresh interval causing memory leak Medium Fixed BUG-007 Avatar cache not cleared on logout Low Fixed "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/1-worklog/1.12-week12/","title":"Week 12 Worklog","tags":[],"description":"","content":"Week 12: AI Module \u0026amp; End-to-End Testing Week 12 Objectives: Test AI recipe suggestion flow and Bedrock integration. Fix friend-based privacy filtering and TypeScript errors. Perform end-to-end testing for the complete application. Tasks to be carried out this week: Day Task Start Date Completion Date Reference Material 2 Test AI Suggestions - Cache matching logic 11/27/2025 11/27/2025 suggestion.handler.ts 3 Test Recipe CRUD - Create/Update/Delete 11/28/2025 11/28/2025 ai-module/index.ts 4 Fix TODO: Friend-based privacy filtering for posts 11/29/2025 11/29/2025 post.service.ts:757 5 Fix TODO: Recipe-group handler TypeScript errors 11/30/2025 11/30/2025 social-module/index.ts 6 End-to-end testing - Full user journey 12/01/2025 12/01/2025 All modules Week 12 Achievements: Verified AI cache matching logic works correctly Fixed friend-based privacy filtering for feed posts Resolved TypeScript errors in recipe-group handler Completed full end-to-end testing Bugs Found \u0026amp; Fixed: Bug ID Description Severity Status BUG-008 AI cache rejected due to servings mismatch Medium Fixed BUG-009 Friend posts not showing in feed (privacy filter bug) High Fixed BUG-010 Recipe-group handler TypeScript compilation errors Medium Fixed BUG-011 S3 image deletion not queued on post delete Low Deferred Summary of All TODOs Found in Codebase Location TODO Description Priority comment.service.ts:434 Delete all replies when parent comment deleted High post.service.ts:757 Add friend-based privacy filtering for friends posts High social-module/index.ts:26 Fix TypeScript errors in recipe-group.handler Medium moderation.service.ts:329 Queue S3 image deletion (async via SQS) Low rate-limit.ts:99 Send alert to admin team on rate limit Low frontend/services/comments.ts Implement all TODO comment functions High Testing Checklist Authentication \u0026amp; Authorization Login with valid credentials Login with invalid credentials Login with banned user Logout and session cleanup Token refresh before expiry Protected route redirect User Profile View own profile Update profile information Upload avatar Upload background Privacy settings update View other user\u0026rsquo;s profile (with privacy) Social Features Create post (quick/recipe_share) Edit post title Delete post Like/Unlike post Comment on post Delete comment Report post/comment Share post Friends Search users Send friend request Accept friend request Reject friend request Cancel sent request Remove friend Block/Unblock user AI Features Get recipe suggestions Check job status Nutrition analysis Dictionary lookup Notifications Get notifications list Mark as read Mark all as read Delete notification Notification preferences Notes Critical Bug: Comments service in frontend has TODO functions that return empty arrays - needs immediate implementation Performance: Ban status check has retry logic with 5s timeout - may cause login delays Data Consistency: Comment deletion doesn\u0026rsquo;t cascade to replies - orphan data issue Privacy: Friend-based post filtering not implemented in feed TypeScript: Recipe-group handler commented out due to compilation errors "},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/categories/","title":"Categories","tags":[],"description":"","content":""},{"uri":"https://hongthanh909.github.io/fcj-workshop-template-main/tags/","title":"Tags","tags":[],"description":"","content":""}]